{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reqirements\n",
    "* #### You need to install module future, manual importing from \\_\\_future\\_\\_ is at your convenience\n",
    "* #### For hdf data import you need pytables too which is not default installed with Anaconda\n",
    "\n",
    "### Batch execution\n",
    "* #### ```batch_animal=msaxxyy_z jupyter nbconvert Stat.ipynb --to=html --execute --ExecutePreprocessor.timeout=-1 --output=xxyy_z_report.html```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from future.utils import PY3\n",
    "import future\n",
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, os, warnings, imp, itertools\n",
    "import IPython.display as disp\n",
    "display = disp.display\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "zscore, describe = stats.mstats.zscore, stats.describe\n",
    "import datetime\n",
    "dt, td = datetime.datetime, datetime.timedelta\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ca_lib as la\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "batch_animal = environ.get('batch_animal', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basedir = '../_share/Losonczi/'\n",
    "\n",
    "# Display database folders\n",
    "display(os.listdir(basedir))\n",
    "\n",
    "# Select animal\n",
    "if batch_animal is None:\n",
    "    animal = 'msa1215_1'; FPS = 30\n",
    "    #animal = 'msa0216_4'; FPS = 8\n",
    "    #animal = 'msa0316_1'; FPS = 8\n",
    "    #animal = 'msa0316_3'; FPS = 8\n",
    "    #animal = 'msa0316ag_1'; FPS = 8\n",
    "else:\n",
    "    FPS = None\n",
    "    animal = batch_animal\n",
    "\n",
    "print ('selecting',animal)\n",
    "\n",
    "# List dir\n",
    "mydir = os.path.join(basedir,animal)\n",
    "os.listdir(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Available trials and ROIs\n",
    "data = la.load_files(mydir)\n",
    "if (FPS is not None) and (data.FPS != FPS):\n",
    "    warnings.warn('FPS indication might be wrong.')\n",
    "print (data.raw.shape, '\\n', data.trials, '\\n', data.rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Post-Learning may repeat session_num therefore an additional index,\n",
    "# day_num is created. See msa0316_1.\n",
    "# It seems though that Pre-Learning and Learning treats session_num as documented.\n",
    "display(data.experiment_traits.head())\n",
    "display(data.experiment_traits[data.experiment_traits['day_leap']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment protocol configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et = data.experiment_traits.copy()\n",
    "et = la.df_epoch(et.groupby(la.display_learning).size().to_frame(name='count'))\n",
    "#et.to_clipboard()\n",
    "disp.display(disp.HTML('<font color=\"red\">ATTENTION, </font>for later conformity we store columns in a <b>different order</b>: %s !!!'%la.sort_learning))\n",
    "display(la.df_epoch(et))\n",
    "\n",
    "et = data.experiment_traits.copy()\n",
    "etc= et.groupby(la.sort_learning[1:]).size().to_frame(name='count')\n",
    "et = la.df_epoch(et.groupby(la.sort_learning).size().to_frame(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data = data.filtered\n",
    "df_raw = data.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See how many ROIs are available for which frames\n",
    "\n",
    "avail_sum = (~data.filtered.isnull()).sum() / len(data.trials)\n",
    "plt.plot(avail_sum)\n",
    "plt.xlabel('Camera frame within experiment')\n",
    "plt.ylabel('Available ROIs on average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See which ROI is available in which trial and for how many frames\n",
    "\n",
    "avail = ((~data.filtered.isnull()).sum(axis=1)).to_frame('nFrames').unstack()\n",
    "\n",
    "print(avail.shape)\n",
    "display(avail.head())\n",
    "display(avail.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create boolean DataFrame which ROI is spiking in which camera frame\n",
    "\n",
    "# create empty structure for cumsum\n",
    "df_template = pd.DataFrame(data=0,index=data.mirow,columns=data.icol)\n",
    "df_spike = df_template.copy()\n",
    "\n",
    "# select spike data\n",
    "spikes = data.transients.loc[data.transients['in_motion_period']==False,['start_frame','stop_frame']]\n",
    "spikes['count']=1\n",
    "\n",
    "# fill in spike start and stop points (rename column to keep columns.name in df_spike)\n",
    "sp = spikes[['start_frame','count']].rename(columns={'start_frame':'frame'}).pivot(columns='frame').fillna(0)\n",
    "df_spike = df_spike.add(sp['count'], fill_value=0)\n",
    "sp = spikes[['stop_frame','count']].rename(columns={'stop_frame':'frame'}).pivot(columns='frame').fillna(0)\n",
    "df_spike = df_spike.add(-sp['count'], fill_value=0)\n",
    "\n",
    "# cumulate, conversion to int is not adviced if using NaNs\n",
    "df_spike = df_spike.cumsum(axis=1).astype(int)\n",
    "df_spike = df_spike + data.time_roi_mask\n",
    "\n",
    "print('table shape', df_spike.shape, 'active frames*ROIs', df_spike.sum().sum())\n",
    "display(df_spike.head(25))\n",
    "display(df_spike.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create boolean DataFrame whether licking happens in camera frame\n",
    "\n",
    "# Check for valid data and calculate their frame\n",
    "print('All entries', data.behavior.shape)\n",
    "df_lick = data.behavior[data.behavior.loc[:,'stop_time']>data.behavior.loc[:,'start_time']].copy()\n",
    "print('Valid licks', df_lick.shape)\n",
    "df_lick['frame'] = (data.FPS*(df_lick['start_time']+df_lick['stop_time'])/2).apply(np.round).astype(int)\n",
    "display(df_lick.head())\n",
    "display(df_lick.tail())\n",
    "# Convert to a DataFrame like df_data or df_raw\n",
    "df_lick = df_lick[['lick_idx','frame']].reset_index()\n",
    "df_lick = df_lick.groupby(['time','frame']).count().unstack(fill_value=0)\n",
    "display(df_lick.head())\n",
    "df_lick = df_lick['lick_idx'].reindex(index=data.mirow.levels[0],columns=data.icol,fill_value=0)\n",
    "display(df_lick.head())\n",
    "# Number of remaining licks\n",
    "print('Remaining licks',df_lick.sum().sum())\n",
    "# Smoothen\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "df_lick = df_lick.apply(lambda x: gaussian_filter(x.astype(float)*data.FPS, sigma=0.25*data.FPS), axis=1, raw=True)\n",
    "display(df_lick.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_spike = la.pd_zscore_by_roi(df_spike, data.FPS, -2*data.FPS, axis=1)\n",
    "z_data = la.pd_zscore_by_roi(df_data, data.FPS, -2*data.FPS, axis=1)\n",
    "z_raw = la.pd_zscore_by_roi(df_raw, data.FPS, -2*data.FPS, axis=1)\n",
    "z_lick = la.pd_zscore_clip(df_lick, data.FPS, -2*data.FPS, axis=1)\n",
    "\n",
    "z_data = z_data.sort_index()\n",
    "z_raw = z_raw.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigger(data, threshold, rising=True, hold_off=None):\n",
    "    '''Find threshold crossings along first axis'''\n",
    "    data = np.array(data)\n",
    "    trig = np.full(data.shape,False,dtype=bool)\n",
    "    if hold_off:\n",
    "        raise ValueError('Hold off period not implemented yet.')\n",
    "    if rising:\n",
    "        trig[1:] = (data[1:]>threshold) & (data[:-1]<=threshold)\n",
    "    else:\n",
    "        trig[1:] = (data[1:]<threshold) & (data[:-1]>=threshold)\n",
    "    return trig\n",
    "\n",
    "def trigger_find_pd(df, threshold, axis=1, hold_off=None):\n",
    "    '''Find threshold crossings in both directions in a DataFrame'''\n",
    "    triggers_rise = df.apply(lambda x: trigger(x,threshold, True), axis=axis)\n",
    "    triggers_rise[triggers_rise==0]=np.nan\n",
    "    triggers_fall = df.apply(lambda x: trigger(x,threshold, False), axis=axis)\n",
    "    triggers_fall[triggers_fall==0]=np.nan\n",
    "    \n",
    "    if axis==1:\n",
    "        triggers_rise = triggers_rise.stack()\n",
    "        triggers_fall = triggers_fall.stack()\n",
    "    elif axis==0:\n",
    "        triggers_rise = triggers_rise.T.stack().T\n",
    "        triggers_fall = triggers_fall.T.stack().T\n",
    "    else:\n",
    "        warnings.warn('Axis reduction not implemented for axis.')\n",
    "    triggers_rise.name='weight'\n",
    "    triggers_fall.name='weight'\n",
    "    return triggers_rise, triggers_fall\n",
    "\n",
    "def trigger_enable_pd(df, start, stop):\n",
    "    '''Create trigger enabled array based on a pair of switch on and off events'''\n",
    "    mi = pd.MultiIndex.from_product((df.index.values, [start]), names=['time', 'frame'])\n",
    "    triggers_start = pd.Series(1.0, index=mi, name='weight')\n",
    "    mi = pd.MultiIndex.from_product((df.index.values, [stop]), names=['time', 'frame'])\n",
    "    triggers_stop = pd.Series(1.0, index=mi, name='weight')\n",
    "    mi = pd.MultiIndex.from_product((df.index.values, list(range(start,stop))), names=['time', 'frame'])\n",
    "    triggers_allow = pd.Series(1.0, index=mi, name='weight')\n",
    "\n",
    "    return triggers_start, triggers_stop, triggers_allow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_spike_threshold = 5.0/np.sqrt(len(data.rois))\n",
    "\n",
    "max_lik_rate = 20\n",
    "c,b = np.histogram(df_lick.values.ravel(),range=(0,max_lik_rate),bins=max_lik_rate)\n",
    "lick_threshold = (np.argmax(c[1:])+1.5)/2\n",
    "plt.hist(df_lick.values.ravel(),log=True,range=(0,max_lik_rate),bins=max_lik_rate)\n",
    "plt.plot(lick_threshold,2,'y*',ms=15)\n",
    "print(lick_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The histogram shape justifies putting the threshold at the half maximum\n",
    "lick_triggers_rise, lick_triggers_fall = trigger_find_pd(df_lick, lick_threshold)\n",
    "print (lick_triggers_rise.shape,lick_triggers_fall.shape)\n",
    "print ('Port was present in %d trials.'%data.experiment_traits[data.experiment_traits['port']=='W+'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the boundaryof a p<0.005 set \n",
    "spike_triggers_rise, spike_triggers_fall = trigger_find_pd(z_spike.mean(level=0), z_spike_threshold)\n",
    "print (spike_triggers_rise.shape,spike_triggers_fall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csp_triggers_rise, csp_triggers_fall, csp_triggers_allow = trigger_enable_pd(\n",
    "    data.experiment_traits[data.experiment_traits['port']=='W+'],\n",
    "    la.events[1]*data.FPS, la.events[2]*data.FPS)\n",
    "csm_triggers_rise, csm_triggers_fall, csm_triggers_allow = trigger_enable_pd(\n",
    "    data.experiment_traits[data.experiment_traits['port']=='W-'],\n",
    "    la.events[1]*data.FPS, la.events[2]*data.FPS)\n",
    "\n",
    "us_triggers_rise, us_triggers_fall, us_triggers_allow = trigger_enable_pd(\n",
    "    data.experiment_traits[data.experiment_traits['puffed']=='A+'],\n",
    "    la.events[3]*data.FPS, la.events[4]*data.FPS)\n",
    "\n",
    "tra_triggers_rise, tra_triggers_fall, tra_triggers_allow = trigger_enable_pd(\n",
    "    data.experiment_traits[data.experiment_traits['context']=='CS+'],\n",
    "    la.events[2]*data.FPS, la.events[3]*data.FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "class helpmultipage(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.isopen = False\n",
    "        self.open()\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "        \n",
    "    def savefig(self, dpi=None):\n",
    "        if self.isopen:\n",
    "            self.pp.savefig(dpi=dpi)\n",
    "\n",
    "    def open(self):\n",
    "        if (~self.isopen) and len(self.filename):\n",
    "            self.pp = PdfPages(self.filename)\n",
    "            self.isopen = True\n",
    "        \n",
    "    def close(self):\n",
    "        if self.isopen:\n",
    "            self.pp.close()\n",
    "        self.isopen = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanatory figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_explanatory.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "center = data.FPS * (la.events[:-1]+la.events[1:]) /2\n",
    "left = data.FPS * la.events\n",
    "width = data.FPS * (la.events[1:]-la.events[:-1])\n",
    "vcenter = 0.0\n",
    "vstart = -0.5\n",
    "\n",
    "def label90(x,y,text):\n",
    "    ax.text(x, y, text, ha=\"center\", va=\"center\", family='sans-serif', size=14, rotation=90)\n",
    "\n",
    "fig, (empty, ax) = plt.subplots(2,1,figsize=(6,8))\n",
    "fig.tight_layout(pad=3)\n",
    "empty.axis('off')\n",
    "#ax = fig.gca()\n",
    "fig.suptitle('Explanatory figure',fontsize=16)\n",
    "ax.set_xlabel('Camera frame')\n",
    "ax.set_ylabel('z-scored activity')\n",
    "ax.set_ylim(vstart,vstart+1)\n",
    "ax.plot(z_spike.mean(axis=0)+0.00, label=\"(CategoryA, True): #trials\", c=(1,1,0))\n",
    "ax.plot(z_spike.mean(axis=0)+0.02, label=\"(CategoryB, True): #trials\", c=(.5,1,.5))\n",
    "ax.plot(-z_spike.mean(axis=0)+0.00, label=\"(CategoryA, False): #trials\", c=(1,.8,1))\n",
    "ax.plot(-z_spike.mean(axis=0)+0.02, label=\"(CategoryB, False): #trials\", c=(.5,1,1))\n",
    "patches = []\n",
    "# mark delay\n",
    "label90(center[0], vcenter, 'excitation by\\nshowing water')\n",
    "# mark CS\n",
    "rect = mpatches.Rectangle((left[1],vstart), width[1], 1, ec=\"none\")\n",
    "patches.append(rect)\n",
    "label90(center[1], vcenter, 'CS± if tone\\n\"Baseline\" otherwise')\n",
    "# mark delay\n",
    "label90(center[2], vcenter, 'delay')\n",
    "# mark UC\n",
    "rect = mpatches.Rectangle((left[3],vstart), width[3], 1, ec=\"none\")\n",
    "patches.append(rect)\n",
    "label90(center[3], vcenter, 'UC if any')\n",
    "# mark water\n",
    "ax.text((left[0]+left[3])/2, vstart, \"water source present\\niff allowed to lick\",\n",
    "        ha=\"center\", va=\"bottom\", family='sans-serif', size=14, bbox=dict(boxstyle=\"DArrow\", pad=0.0, fc='c'))\n",
    "\n",
    "for i in range(0,len(la.events)):\n",
    "    ax.axvline(x=la.events[i]*data.FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "colors = np.linspace(0, 1, len(patches))\n",
    "collection = PatchCollection(patches, cmap=plt.cm.hsv, alpha=0.1)\n",
    "collection.set_array(np.array(colors))\n",
    "ax.add_collection(collection)\n",
    "\n",
    "leg = ax.legend(loc='lower center', title=\"Category name, Condition name\",\n",
    "               bbox_to_anchor=(0.5, 1.1))\n",
    "leg.get_title().set_fontsize('large')\n",
    "leg.get_title().set_fontweight('bold')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', UserWarning)\n",
    "    fig.show()\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-scored spiking\n",
    "Spiking is \"True\" in the [intervals) given in transients_data.hc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymean = pd.DataFrame.mean\n",
    "mystd = pd.DataFrame.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging in 5\" bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsections = np.arange(0,60,5)*data.FPS\n",
    "bcenters = (bsections[1:]+bsections[:-1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zb_spike = la.pd_aggr_col(z_spike, mymean, bsections, bcenters.astype(str))\n",
    "zb_data = la.pd_aggr_col(z_data, mymean, bsections, bcenters.astype(str))\n",
    "zb_raw = la.pd_aggr_col(z_raw, mymean, bsections, bcenters.astype(str))\n",
    "zb_lick = la.pd_aggr_col(z_lick, mymean, bsections, bcenters.astype(str))\n",
    "\n",
    "zb_data = zb_data.sort_index()\n",
    "zb_raw = zb_raw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_spike = la.pd_aggr_col(df_spike, mymean, bsections, bcenters.astype(str))\n",
    "b_data = la.pd_aggr_col(df_data, mymean, bsections, bcenters.astype(str))\n",
    "b_raw = la.pd_aggr_col(df_raw, mymean, bsections, bcenters.astype(str))\n",
    "b_lick = la.pd_aggr_col(df_lick, mymean, bsections, bcenters.astype(str))\n",
    "\n",
    "b_data = b_data.sort_index()\n",
    "b_raw = b_raw.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging within phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asections = np.append(la.events,[60])*data.FPS\n",
    "acenters = (asections[1:]+asections[:-1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "za_spike = la.pd_aggr_col(z_spike, mymean, asections, acenters.astype(str))\n",
    "za_data = la.pd_aggr_col(z_data, mymean, asections, acenters.astype(str))\n",
    "za_raw = la.pd_aggr_col(z_raw, mymean, asections, acenters.astype(str))\n",
    "za_lick = la.pd_aggr_col(z_lick, mymean, asections, acenters.astype(str))\n",
    "\n",
    "za_data = za_data.sort_index()\n",
    "za_raw = za_raw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_spike = la.pd_aggr_col(df_spike, mymean, asections, acenters.astype(str))\n",
    "a_data = la.pd_aggr_col(df_data, mymean, asections, acenters.astype(str))\n",
    "a_raw = la.pd_aggr_col(df_raw, mymean, asections, acenters.astype(str))\n",
    "a_lick = la.pd_aggr_col(df_lick, mymean, asections, acenters.astype(str))\n",
    "\n",
    "a_data = a_data.sort_index()\n",
    "a_raw = a_raw.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licking statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lick_rate_mean = la.pd_aggr_col(df_lick, mymean, asections, acenters.astype(str))\n",
    "lick_rate_std = la.pd_aggr_col(df_lick, mystd, asections, acenters.astype(str))\n",
    "lick_time_mean = la.pd_aggr_col((df_lick>lick_threshold).astype(float), mymean,\n",
    "                                asections, acenters.astype(str))\n",
    "lick_time_std = la.pd_aggr_col((df_lick>lick_threshold).astype(float), mystd,\n",
    "                               asections, acenters.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_protocol.pdf')\n",
    "fig, ax = plt.subplots(len(data.trials),1,figsize=(10,0.6*len(data.trials)), sharex=True, sharey=True)\n",
    "fig.tight_layout(h_pad=0.1)\n",
    "ind = np.arange(0,5)\n",
    "width = 1\n",
    "height = 1.2\n",
    "spacing = 10\n",
    "i = 0\n",
    "label_df = data.experiment_traits.replace('Baseline','B.L.')\n",
    "for i in range(0,len(data.trials)):\n",
    "    trial = data.trials[i]\n",
    "    sc = 2.0*lick_threshold\n",
    "    rects1 = ax[i].bar(ind+2*spacing, lick_rate_mean.loc[trial]/sc, width, color='r', yerr=lick_rate_std.loc[trial]/sc)\n",
    "    rects2 = ax[i].bar(ind+3*spacing, lick_time_mean.loc[trial], width, color='b') #, yerr=lick_time_std.loc[trial])\n",
    "    #label = label_df.loc[trial,la.sort_learning]\n",
    "    #ax[i].text(1, 0, ', '.join(label.values.astype(str)),\n",
    "    #    horizontalalignment='left',verticalalignment='bottom')\n",
    "    ax[i].set_xlim(xmin=0)\n",
    "    ax[i].set_ylim(ymin=0, ymax=height)\n",
    "    ax[i].set_yticks([0,0.5,1])\n",
    "    la.draw_conditions(ax[i],label_df,trial,data.FPS,loc='lower left',screen_width=0.5, height=height, cw=[0.25, 0.15, 0.15, 0.15, 0.15, 0.15],fontsize=12)\n",
    "ax[i].set_xticks([spacing, 2.2*spacing, 3.2*spacing])\n",
    "ax[i].set_xticklabels(['Conditions', 'Licking rate', 'Licking time'])\n",
    "pp.savefig()\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_pop.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "la.plot_data(df_spike, df_data, df_lick, data.experiment_traits, data.FPS)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single criterion\n",
    "* comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grp = [['context'],['learning_epoch'],['port'],['puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, data.FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, data.FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, data.FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two criteria\n",
    "* comments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = [['context','learning_epoch'],['context','port'],['context','puffed'],['learning_epoch','puffed'],['learning_epoch','port'],['port','puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, data.FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, data.FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, data.FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three criteria\n",
    "* comments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = [['context','learning_epoch','port'],['context','learning_epoch','puffed'],['context','port','puffed'],['learning_epoch','port','puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, data.FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, data.FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, data.FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All criteria\n",
    "* There is no increased population activity for CS+ without puffing. (For mouse 0216_4 the 1 trial with port displays increase during the trace period - why?)\n",
    "* During learning mouse 0216_4 shows incresed activity during the UC phase for CS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = [['context','port','puffed']]\n",
    "la.plot_epochs(z_spike, z_data, df_lick, data.experiment_traits, etc, data.FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_epochs(zb_spike, zb_data, b_lick, data.experiment_traits, etc, data.FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_epochs(za_spike, za_data, a_lick, data.experiment_traits, etc, data.FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities conditional on epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_by_epoch(epoch):\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = z_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    raw_c = z_raw.reindex(experiment_c.index, level='time')\n",
    "    lick_c = df_lick.reindex(experiment_c.index)\n",
    "    print (experiment_c.shape, z_spike.shape)\n",
    "    spike_ca = la.pd_aggr_col(spike_c, mymean, asections, acenters.astype(str))\n",
    "    data_ca = la.pd_aggr_col(data_c, mymean, asections, acenters.astype(str))\n",
    "    raw_ca = la.pd_aggr_col(raw_c, mymean, asections, acenters.astype(str))\n",
    "    lick_ca = la.pd_aggr_col(lick_c, mymean, asections, acenters.astype(str))\n",
    "    print (spike_c.shape, spike_ca.shape)\n",
    "\n",
    "    grp = [['context','port'],['context','puffed'],['port','puffed']]\n",
    "    la.plot_data(spike_c, data_c, lick_c, data.experiment_traits, data.FPS, grp, title=epoch)\n",
    "    pp.savefig()\n",
    "    la.plot_data(spike_ca, data_ca, lick_ca, data.experiment_traits, data.FPS, grp, title=epoch+' averaged over events', div=acenters)\n",
    "    pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Pre-Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Post-Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity vector by phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_phases_sp.pdf')\n",
    "\n",
    "etmp = data.experiment_traits.reset_index(drop=True).set_index(la.sort_learning)\n",
    "\n",
    "for p,aggr in enumerate(za_data.columns):\n",
    "    nplot = len(et.index)\n",
    "    ncol = 14\n",
    "    nrow = int(np.ceil(len(et.index)/float(ncol)))\n",
    "    fig, ax = plt.subplots(nrow,ncol,figsize=(2*ncol,1+10*nrow),squeeze=False,sharey=True)\n",
    "    fig.tight_layout(pad=3, h_pad=3, rect=[0,0,1,0.8])\n",
    "    fig.suptitle('Spikes, Phase: %s'%la.phases[p],fontsize=16)\n",
    "    cax = None\n",
    "    for i, cond in enumerate(et.index):\n",
    "        col = i%ncol\n",
    "        row = int((i-col)/ncol)\n",
    "        sel = etmp.loc[cond,'timestr']\n",
    "        tmp = a_spike.loc[sel.tolist(),aggr].unstack('time')\n",
    "        img = ax[row,col].matshow(tmp.values,origin='lower',vmin=0,vmax=1)\n",
    "        ax[row,col].xaxis.set_ticks_position('bottom')\n",
    "        ax[row,col].set_title('\\n'.join(cond))\n",
    "        ax[row,col].set_ylabel('Unit ID')\n",
    "        ax[row,col].set_xlabel('Trial')\n",
    "    #cax,kw = mpl.colorbar.make_axes([axis for axis in ax.flat])\n",
    "    cax = ax[-1,-1]\n",
    "    plt.colorbar(img,ax=cax)#ax=cax,**kw)\n",
    "    pp.savefig()    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_phases_ca.pdf')\n",
    "\n",
    "etmp = data.experiment_traits.reset_index(drop=True).set_index(la.sort_learning)\n",
    "\n",
    "for p,aggr in enumerate(za_data.columns):\n",
    "    nplot = len(et.index)\n",
    "    ncol = 14\n",
    "    nrow = int(np.ceil(len(et.index)/float(ncol)))\n",
    "    fig, ax = plt.subplots(nrow,ncol,figsize=(2*ncol,1+10*nrow),squeeze=False,sharey=True)\n",
    "    fig.tight_layout(pad=3, h_pad=3, rect=[0,0,1,0.8])\n",
    "    fig.suptitle('Ca-Signal, Phase: %s'%la.phases[p],fontsize=16)\n",
    "    cax = None\n",
    "    for i, cond in enumerate(et.index):\n",
    "        col = i%ncol\n",
    "        row = int((i-col)/ncol)\n",
    "        sel = etmp.loc[cond,'timestr']\n",
    "        tmp = za_data.loc[sel.tolist(),aggr].unstack('time')\n",
    "        img = ax[row,col].matshow(tmp.values,origin='lower',vmin=-3,vmax=3)\n",
    "        ax[row,col].xaxis.set_ticks_position('bottom')\n",
    "        ax[row,col].set_title('\\n'.join(cond))\n",
    "        ax[row,col].set_ylabel('Unit ID')\n",
    "        ax[row,col].set_xlabel('Trial')\n",
    "    #cax,kw = mpl.colorbar.make_axes([axis for axis in ax.flat])\n",
    "    cax = ax[-1,-1]\n",
    "    plt.colorbar(img,ax=cax)#ax=cax,**kw)\n",
    "    pp.savefig()    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of spiking\n",
    "The first 1 second of the recording seems missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Order experiments by settings (deprecated)\n",
    "et3 = data.experiment_traits.copy().reset_index(drop=True)\n",
    "et3 = et3.sort_values(la.sort_learning+[str('session_num')]).set_index(la.sort_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Triggers\n",
    "trig_list_data = [lick_triggers_rise, lick_triggers_fall, spike_triggers_rise, spike_triggers_fall]\n",
    "trig_list_sign = ['o', 's', '^', 'v']\n",
    "trig_list_color = ['b', 'y', 'r', 'g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show an example\n",
    "idx = data.experiment_traits.index[9]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "la.draw_levels(ax, z_data, idx, data.FPS, data.roi_df)\n",
    "ax.set_ylim(ymin=-60,ymax=120)\n",
    "#plot_spiking_nan(ax, df_spike, idx, data.rois.values)\n",
    "#la.draw_behavior(ax, data.behavior, idx, data.FPS)\n",
    "la.draw_population(ax, z_data, idx, pos=-20, c='y', label='population Ca-signal')\n",
    "la.draw_population(ax, z_spike, idx, pos=-20, threshold=z_spike_threshold, label='population z-spike count')\n",
    "la.draw_licking(ax, df_lick, idx, pos=-40, threshold=lick_threshold, label='licking')\n",
    "la.draw_triggers(ax, trig_list_data, idx, -5, trig_list_sign, c=trig_list_color)\n",
    "la.draw_conditions(ax, data.experiment_traits, idx, data.FPS, height=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show an example\n",
    "idx = data.experiment_traits.index[9]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "la.draw_transients(ax, data.transients, idx, data.FPS, data.roi_df)\n",
    "ax.set_ylim(ymin=-60,ymax=len(data.rois)+1)\n",
    "la.draw_spiking_nan(ax, df_spike, idx, data.roi_df)\n",
    "#la.draw_behavior(ax, data.behavior, idx, dta.data.FPS)\n",
    "la.draw_population(ax, z_data, idx, pos=-20, c='y', label='population Ca-signal')\n",
    "la.draw_population(ax, z_spike, idx, pos=-20, threshold=z_spike_threshold, label='population z-spike count')\n",
    "la.draw_licking(ax, df_lick, idx, pos=-40, threshold=lick_threshold, label='licking')\n",
    "la.draw_triggers(ax, trig_list_data, idx, -5, trig_list_sign, c=trig_list_color)\n",
    "la.draw_conditions(ax, data.experiment_traits, idx, data.FPS, height=20)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_firing.pdf')\n",
    "\n",
    "xmax = data.transients.loc[:,['stop_frame']].max().values\n",
    "\n",
    "for idx, val in data.experiment_traits.iterrows(): #et3.iterrows():\n",
    "    fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "    ax.set_xlim(xmax=xmax)\n",
    "    experiment_id = val['timestr']\n",
    "    #print (experiment_id)\n",
    "    fig.suptitle('learning_epoch, context, port, puffed: #context in epoch, #day\\n'+\n",
    "        '%s: session %s, day %s'%(idx,val['session_num'],val['day_num']),fontsize=16)\n",
    "    la.draw_transients(ax, data.transients, idx, data.FPS, data.roi_df)\n",
    "    ax.set_ylim(ymin=-60,ymax=len(data.rois)+1)\n",
    "    #plot_spiking_nan(ax, df_spike, idx, data.rois.values)\n",
    "    la.draw_population(ax, z_data, idx, pos=-20, c='y')\n",
    "    la.draw_population(ax, z_spike, idx, pos=-20, threshold=z_spike_threshold)\n",
    "    la.draw_licking(ax, df_lick, idx, pos=-40, threshold=lick_threshold)\n",
    "    la.draw_triggers(ax, trig_list_data, idx, -5, trig_list_sign, c=trig_list_color)\n",
    "    la.draw_conditions(ax, data.experiment_traits, experiment_id, data.FPS, height=20)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peri-event averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def peri_event_avg(data, triggers, diameter=(-3*data.FPS, 3*data.FPS), allow=None, disable=None):\n",
    "    '''Collect data in windows arond events in an event list'''\n",
    "    window = np.arange(diameter[0],diameter[1])\n",
    "    count=0\n",
    "    ret = []\n",
    "    for idx, weight in triggers.iteritems():\n",
    "        experiment_id, frame = idx\n",
    "        if (experiment_id in data.index) and ((allow is None) or (idx in allow)) and ((disable is None) or (idx not in disable)):\n",
    "            tmp = data.loc[experiment_id,:].reindex(columns=frame+window)\n",
    "            tmp.columns = pd.MultiIndex.from_product([count,window],names=['id','frame'])\n",
    "            ret.append(tmp)\n",
    "            count += 1\n",
    "    if len(ret):\n",
    "        ret = pd.concat(ret,axis=1)\n",
    "        return ret, count\n",
    "    else:\n",
    "        return None, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gauss_window(time_range, rate):\n",
    "    '''Gaussian window'''\n",
    "    rate = float(rate)\n",
    "    if type(time_range) is int:\n",
    "        time_points = np.arange(0,time_range)-0.5*time_range\n",
    "    elif len(time_range)==2:\n",
    "        time_points = np.arange(time_range[0],time_range[-1])\n",
    "    else:\n",
    "        time_points = time_range\n",
    "    decay = np.exp(-np.power(rate*time_points,2)/2.0)\n",
    "    return decay/np.sum(decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_decay(time_range, rate):\n",
    "    '''Exponentially decaying series'''\n",
    "    rate = float(rate)\n",
    "    if type(time_range) is int:\n",
    "        time_points = np.arange(0,time_range)-0.5*time_range\n",
    "    elif len(time_range)==2:\n",
    "        time_points = np.arange(time_range[0],time_range[-1])\n",
    "    else:\n",
    "        time_points = time_range\n",
    "    decay = np.exp(-np.abs(rate*time_points))\n",
    "    return decay/np.sum(decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rev_align(data, shape):\n",
    "    '''Align for broadcast to shape matching axes from the beginning (opposed to numpy convention)'''\n",
    "    data_dim = data.ndim\n",
    "    req_dim = len(shape)\n",
    "    new_axes = np.arange(data_dim,req_dim)\n",
    "    # TODO: using np.reshape is more efficient\n",
    "    ret = data\n",
    "    for axis in new_axes:\n",
    "        ret = np.expand_dims(data, axis=axis)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rev_broadcast(data, shape):\n",
    "    '''Broadcast to shape matching axes from the beginning (opposed to numpy convention)'''\n",
    "    ret = np.broadcast_to(rev_align(data,shape), shape)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match_pattern(data, pattern, std, decay, noise_level=0.01, detailed=False):\n",
    "    '''Match pattern with decaying strength along time axis (rows). Use any number of columns.\n",
    "    Pattern and std may be one (time points given, all columns equal) or two dimensional (matrix given).\n",
    "    Noise_level can be 0 to 2 dimensional, if it is one dimensional then it is understood\n",
    "    on the category axis (all rows equal), noise_level must be positive if there is any std==0.'''\n",
    "    diff = data-rev_align(pattern, data.shape)\n",
    "    scale = rev_align(decay, data.shape)/(noise_level+rev_align(std, data.shape))\n",
    "    ret = np.nanmean(np.abs(diff*scale), axis=(0 if detailed else None))\n",
    "    return -ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlate_pattern(data, pattern, std, decay, noise_level=0.01, detailed=False):\n",
    "    '''Multiply pattern with decaying strength along time axis (rows). Use any number of columns.\n",
    "    Pattern and std may be one (time points given, all columns equal) or two dimensional (matrix given).\n",
    "    Noise_level can be 0 to 2 dimensional, if it is one dimensional then it is understood\n",
    "    on the category axis (all rows equal), noise_level must be positive if there is any std==0.'''\n",
    "    # Note: this is not real correlation unless input is normalized\n",
    "    corr = data*rev_align(pattern, data.shape)\n",
    "    scale = rev_align(decay, data.shape)/(noise_level+rev_align(std, data.shape))\n",
    "    ret = np.nanmean((corr*scale), axis=(0 if detailed else None))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rolling2D(df, func, window, min_periods=None, center=True):\n",
    "    '''Slice a DataFrame along index (rows) to apply 2D function'''\n",
    "    # This was a missing feature in pandas: one could previously correlate a single pattern\n",
    "    # along a selected axis of a 2D DataFrame.\n",
    "    window = int(window)\n",
    "    if window<1:\n",
    "        raise ValueError('window needs positive length')\n",
    "    if min_periods is None:\n",
    "        min_periods = window\n",
    "    else:\n",
    "        min_periods = int(min_periods)\n",
    "    if min_periods<1:\n",
    "        raise ValueError('min_periods needs to be positive')\n",
    "    start = min_periods-window # first point of first window is start, available points evaluate to [0, min_periods)\n",
    "    end = len(df)-min_periods # first point of last window is end, available points evaluate to [len-min_periods, len)\n",
    "    if center:\n",
    "        shift = int(np.floor(window/2))\n",
    "    else:\n",
    "        shift = 0\n",
    "    first = start\n",
    "    data = df.iloc[first:first+window,:]\n",
    "    tmp = func(data)\n",
    "    try:\n",
    "        if len(tmp)==len(df.columns):\n",
    "            ret = pd.DataFrame([], index=df.index, columns=df.columns)\n",
    "        else:\n",
    "            ret = pd.DataFrame([], index=df.index, columns=pd.Index(np.arange(0,len(tmp))))\n",
    "    except:\n",
    "        ret = pd.DataFrame([], index=df.index, columns=pd.Index([0]))\n",
    "    ret.iloc[first+shift,:]=tmp\n",
    "    for first in range(start+1,end+1):\n",
    "        data = df.iloc[first:first+window,:]\n",
    "        tmp = func(data)\n",
    "        ret.iloc[first+shift,:]=tmp\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fine-tuned version of method3\n",
    "def search_pattern(df, triggers, trials, FPS, diam = (-3,3), decay_time=0.1, trigger_allow=None, trigger_disable=None, method='correlate'):\n",
    "    ret = []\n",
    "    diam = int(FPS*diam[0]),int(FPS*diam[1])\n",
    "    window = diam[1]-diam[0]\n",
    "    decay = get_decay(window,1.0/(decay_time*FPS))\n",
    "    dd, c = peri_event_avg(df, triggers, diameter=diam, allow=trigger_allow, disable=trigger_disable)\n",
    "    p1 = dd.mean(axis=1, level=1).T.values\n",
    "    s1 = dd.std(axis=1, level=1).T.values\n",
    "    if method=='match':\n",
    "        func = (lambda x: match_pattern(x.values,p1,s1,decay=decay))\n",
    "    elif method=='correlate':\n",
    "        p1 = p1 - np.nanmean(p1)\n",
    "        func = (lambda x: correlate_pattern(x.values-x.mean().mean(),p1,s1,decay=decay))\n",
    "    else:\n",
    "        raise ValueError('Unaccepted method')\n",
    "    for trial in trials:\n",
    "        tmp = rolling2D(df.loc[trial,:].T,func,window,center=True).T\n",
    "        tmp.index=[trial]\n",
    "        ret.append(tmp)\n",
    "    ret = pd.concat(ret)\n",
    "    return ret.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prog_update = 1467367471\n",
    "print (\"%.0f\"%time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattdb_file = 'pattdb_'+animal+'.h5'\n",
    "if 'pattdb' in locals():\n",
    "    pattdb.close()\n",
    "    del pattdb\n",
    "if (not la.test_hdf(pattdb_file)) or (os.path.getmtime(pattdb_file)<prog_update):\n",
    "    with pd.HDFStore(pattdb_file, mode='w') as pattdb:\n",
    "        for method,sel in itertools.product(['match','correlate'],['sp','ca']):\n",
    "            print(method,sel)\n",
    "            df = df_spike if sel == 'sp' else z_data.reindex(data.mirow)\n",
    "            key = '/'.join((method,sel,'lick_rise_csp'))\n",
    "            pattdb[key] = search_pattern(df, lick_triggers_rise, data.trials,\n",
    "                                        data.FPS, trigger_allow=csp_triggers_allow)\n",
    "            key = '/'.join((method,sel,'lick_fall_csp'))\n",
    "            pattdb[key] = search_pattern(df,lick_triggers_fall, data.trials,\n",
    "                                       data.FPS, trigger_allow=csp_triggers_allow)\n",
    "            key = '/'.join((method,sel,'csp_rise'))\n",
    "            pattdb[key] = search_pattern(df,csp_triggers_rise, data.trials,\n",
    "                                      data.FPS, trigger_allow=csp_triggers_allow)\n",
    "            key = '/'.join((method,sel,'us_rise'))\n",
    "            pattdb[key] = search_pattern(df,us_triggers_rise, data.trials, data.FPS)\n",
    "pattdb = pd.HDFStore(pattdb_file, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_patt = {}\n",
    "for key in pattdb.keys():\n",
    "    if key[0] == '/':\n",
    "        key = key[1:]\n",
    "    z_patt[key] = la.nan_zscore(pattdb[key])\n",
    "pattdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show an example\n",
    "method = 'match' # 'match', 'correlate'\n",
    "sel = 'ca' # 'ca', 'sp'\n",
    "zoom = 3\n",
    "idx = data.experiment_traits.index[13]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "la.draw_transients(ax, data.transients, idx, data.FPS, data.roi_df)\n",
    "ax.set_ylim(ymin=-80,ymax=len(data.rois)+1)\n",
    "la.draw_spiking_nan(ax, df_spike, idx, data.rois.values)\n",
    "#la.draw_behavior(ax, data.behavior, idx, data.FPS)\n",
    "la.draw_licking(ax, z_patt['/'.join((method,sel,'lick_rise_csp'))], idx, pos=-20, c='g', threshold=[-3, 3], zoom=zoom, label='%s: CS+ lick start'%sel)\n",
    "la.draw_licking(ax, z_patt['/'.join((method,sel,'lick_fall_csp'))], idx, pos=-20, c='c', threshold=None, zoom=zoom, label='%s: CS+ lick end'%sel)\n",
    "la.draw_licking(ax, z_patt['/'.join((method,sel,'csp_rise'))], idx, pos=-20, c='orange', threshold=None, zoom=zoom, label='%s: CS+ start'%sel)\n",
    "la.draw_licking(ax, z_patt['/'.join((method,sel,'us_rise'))], idx, pos=-20, c='r', threshold=None, zoom=zoom, label='%s: US start'%sel)\n",
    "la.draw_population(ax, z_data, idx, pos=-40, c='y', label='pop. Ca-signal')\n",
    "la.draw_population(ax, z_spike, idx, pos=-40, threshold=z_spike_threshold, label='pop. z-spike count')\n",
    "la.draw_licking(ax, df_lick, idx, pos=-60, threshold=lick_threshold, label='licking')\n",
    "la.draw_triggers(ax, trig_list_data, idx, -5, trig_list_sign, c=trig_list_color)\n",
    "la.draw_conditions(ax, data.experiment_traits, idx, data.FPS, height=20)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for method,sel in itertools.product(['match','correlate'], ['sp','ca']):\n",
    "    print (method,sel)\n",
    "\n",
    "    pp = helpmultipage(animal+'_triggers_%s_%s.pdf'%(method,sel))\n",
    "    zoom = 4\n",
    "\n",
    "    xmax = data.transients.loc[:,['stop_frame']].max().values\n",
    "\n",
    "    for idx, val in data.experiment_traits.iterrows(): #et3.iterrows():\n",
    "        fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "        ax.set_xlim(xmax=xmax)\n",
    "        experiment_id = val['timestr']\n",
    "        #print (experiment_id)\n",
    "        fig.suptitle('learning_epoch, context, port, puffed: #context in epoch, #day\\n'+\n",
    "            '%s: session %s, day %s'%(idx,val['session_num'],val['day_num']),fontsize=16)\n",
    "        la.draw_transients(ax, data.transients, idx, data.FPS, data.roi_df)\n",
    "        ax.set_ylim(ymin=-80,ymax=len(data.rois)+1)\n",
    "        #la.draw_spiking_nan(ax, df_spike, idx, data.rois.values)\n",
    "        la.draw_licking(ax, z_patt['/'.join((method,sel,'lick_rise_csp'))], idx, pos=-20, c='g',\n",
    "                        threshold=[-3, 3], zoom=zoom, label='%s: CS+ lick start'%sel)\n",
    "        la.draw_licking(ax, z_patt['/'.join((method,sel,'lick_fall_csp'))], idx, pos=-20, c='c',\n",
    "                        threshold=None, zoom=zoom, label='%s: CS+ lick end'%sel)\n",
    "        la.draw_licking(ax, z_patt['/'.join((method,sel,'csp_rise'))], idx, pos=-20, c='orange',\n",
    "                        threshold=None, zoom=zoom, label='%s: CS+ start'%sel)\n",
    "        la.draw_licking(ax, z_patt['/'.join((method,sel,'us_rise'))], idx, pos=-20, c='r',\n",
    "                        threshold=None, zoom=zoom, label='%s: US start'%sel)\n",
    "        la.draw_population(ax, z_data, idx, pos=-40, c='y', label='population Ca-signal')\n",
    "        la.draw_population(ax, z_spike, idx, pos=-40, threshold=z_spike_threshold, label='population z-spike count')\n",
    "        la.draw_licking(ax, df_lick, idx, pos=-60, threshold=lick_threshold, label='licking')\n",
    "        la.draw_triggers(ax, trig_list_data, idx, -5, trig_list_sign, c=trig_list_color)\n",
    "        la.draw_conditions(ax, data.experiment_traits, idx, data.FPS, height=20)\n",
    "        ax.legend()\n",
    "        pp.savefig()\n",
    "        plt.close(fig)\n",
    "\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peri-event plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matlab_tools as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_peri_event1(ax, df, title=None, pos=-15, zoom=10.0, vmin=None, vmax=None):\n",
    "    '''Plot df using matshow'''\n",
    "    extent = np.min(df.columns.values)-0.5, np.max(df.columns.values)+0.5, -0.5, len(df)+0.5\n",
    "    ax.set_xlim(extent[0:2])\n",
    "    ax.set_ylim((pos-zoom,extent[3]))\n",
    "    ret = ax.matshow(df, origin='lower', aspect='auto', extent=extent, vmin=vmin, vmax=vmax)\n",
    "    ax.axhline(y=pos,xmin=0.0,xmax=1.0,c='gray')\n",
    "    ax.axvline(x=0,ymin=0.0,ymax=1.0,c='gray')\n",
    "    ax.plot(zoom*df.mean(axis=0)+pos)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xlabel('$\\Delta$frame')\n",
    "    ax.set_ylabel('Unit ID')\n",
    "    ax.set_xlim(extent[0:2])\n",
    "    ax.set_ylim((pos-zoom,extent[3]))\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_peri_event2(ax, df_mean, df_std, title=None, pos=-15, zoom=10.0, vmin=None, vmax=None):\n",
    "    extent = np.min(df_mean.columns.values)-0.5, np.max(df_mean.columns.values)+0.5, -0.5, len(df_mean)+0.5\n",
    "    '''Plot mean and std using color and lightness-encoding'''\n",
    "    ax.set_xlim(extent[0:2])\n",
    "    ax.set_ylim((pos-zoom,extent[3]))\n",
    "    #img = mt.hls_matrix(mt.crop_series(0.4-0.5*df_mean.T.values,(0,0.8)),mt.crop_series(0.5-0.5*df_std.T.values,(0,1)),0.6)\n",
    "    img = mt.hls_matrix(mt.crop_series(0.2-0.25*df_mean.T.values,(0,0.8)),mt.crop_series(0.5-0.25*df_std.T.values,(0,1)),0.6)\n",
    "    ret = ax.imshow(img,interpolation='none',origin='lower',aspect='auto', extent=extent)\n",
    "    ax.axhline(y=pos,xmin=0.0,xmax=1.0,c='gray')\n",
    "    ax.axvline(x=0,ymin=0.0,ymax=1.0,c='gray')\n",
    "    ax.plot(zoom*df_mean.mean(axis=0)+pos)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xlabel('$\\Delta$frame')\n",
    "    ax.set_ylabel('Unit ID')\n",
    "    ax.set_xlim(extent[0:2])\n",
    "    ax.set_ylim((pos-zoom,extent[3]))\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_peri_collection(collection, title=None, combine=True):\n",
    "    max_cols = 10\n",
    "    num_plots = len(collection) * (1 if combine else 2)\n",
    "    num_rows = int(np.ceil(num_plots/float(max_cols)))\n",
    "    num_cols = max_cols if num_rows>1 else num_plots\n",
    "    fig, ax = plt.subplots(num_rows, num_cols, figsize=(2*num_cols+2,12*num_rows), sharex=True, sharey=True, squeeze=False)\n",
    "    ax = np.ravel(ax)\n",
    "    fig.tight_layout(rect=(0,0,0.9,0.9), w_pad=2, h_pad=8)\n",
    "    gradient = np.linspace(-1, 1, 256)\n",
    "    gradient = pd.DataFrame(np.vstack((gradient, gradient)).T, columns=[2,3])\n",
    "    cax1 = fig.add_axes([0.92, 0.1, 0.02, 0.8])\n",
    "    cax2 = fig.add_axes([0.96, 0.1, 0.02, 0.8])\n",
    "    if combine:\n",
    "        plot_peri_event2(cax1, gradient, gradient*0, 'Mean', vmin=-1, vmax=1)\n",
    "        plot_peri_event2(cax2, gradient*0, gradient+1, 'Std', vmin=-1, vmax=1)\n",
    "    else:\n",
    "        plot_peri_event(cax1, gradient, 'Mean', vmin=-1, vmax=1)\n",
    "        plot_peri_event(cax2, gradient+1, 'Stdev', vmin=0, vmax=2)\n",
    "    cax1.set_ylabel(''); cax1.set_yticks([0,128,256]); cax1.set_yticklabels([-1,0,1])\n",
    "    cax2.set_ylabel(''); cax2.set_yticks([0,128,256]); cax2.set_yticklabels([0,1,2])\n",
    "    cax1.set_xlabel(''); cax1.set_xticks([])\n",
    "    cax2.set_xlabel(''); cax2.set_xticks([])\n",
    "    fig.suptitle(title,fontsize=16)\n",
    "    \n",
    "    for i, (df, trig, allow, disable, title) in enumerate(collection):\n",
    "        dd, c = peri_event_avg(df, trig, allow=allow, disable=disable)\n",
    "        if c:\n",
    "            dd = dd.reindex(data.rois)\n",
    "            if combine:\n",
    "                plot_peri_event2(ax[i], dd.mean(axis=1, level=1), dd.std(axis=1, level=1), '%s: %d'%(title,c), vmin=-1, vmax=1)\n",
    "            else:\n",
    "                plot_peri_event1(ax[2*i], dd.mean(axis=1, level=1), '%s: %d'%(title,c), vmin=-1, vmax=1)\n",
    "                plot_peri_event1(ax[2*i+1], dd.std(axis=1, level=1), 'Stdev', vmin=0, vmax=2)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_peri_3a(df, title=None):\n",
    "    '''Plot collection: CS+ US'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    ret.append([df, lick_triggers_rise, None, None, 'Lick rise'])\n",
    "    ret.append([df, lick_triggers_fall, None, None, 'Lick fall'])\n",
    "    ret.append([df, lick_triggers_rise, csp_triggers_allow, None, 'Lick rise CS+'])\n",
    "    ret.append([df, lick_triggers_fall, csp_triggers_allow, None, 'Lick fall CS+'])\n",
    "    ret.append([df, csp_triggers_rise, None, None, 'CS+ start'])\n",
    "    ret.append([df, csp_triggers_fall, None, None, 'CS+ end'])\n",
    "    ret.append([df, lick_triggers_rise, us_triggers_allow, None, 'Lick rise US'])\n",
    "    ret.append([df, lick_triggers_fall, us_triggers_allow, None, 'Lick fall US'])\n",
    "    ret.append([df, us_triggers_rise, None, None, 'US start'])\n",
    "    ret.append([df, us_triggers_fall, None, None, 'US end'])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_peri_3b(df, title=None):\n",
    "    '''Plot collection: CS+ US'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    ret.append([df, lick_triggers_rise, None, None, 'Lick rise'])\n",
    "    ret.append([df, lick_triggers_fall, None, None, 'Lick fall'])\n",
    "    ret.append([df, lick_triggers_rise, csp_triggers_allow, None, 'Lick rise CS+'])\n",
    "    ret.append([df, lick_triggers_fall, csp_triggers_allow, None, 'Lick fall CS+'])\n",
    "    ret.append([df, csp_triggers_rise, None, None, 'CS+ start'])\n",
    "    ret.append([df, csp_triggers_fall, None, None, 'CS+ end'])\n",
    "    ret.append([df, lick_triggers_rise, csm_triggers_allow, None, 'Lick rise CS-'])\n",
    "    ret.append([df, lick_triggers_fall, csm_triggers_allow, None, 'Lick fall CS-'])\n",
    "    ret.append([df, csm_triggers_rise, None, None, 'CS- start'])\n",
    "    ret.append([df, csm_triggers_fall, None, None, 'CS- end'])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_peri1.pdf')\n",
    "for epoch in la.epochs.values:\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    fig=plot_peri_collection(list_peri_3a(spike_c),'%s Spiking on US'%epoch,combine=False)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    fig=plot_peri_collection(list_peri_3b(spike_c),'%s Spiking on CS+/-'%epoch,combine=False)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "for epoch in la.epochs.values:\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    fig=plot_peri_collection(list_peri_3a(data_c),'%s Ca-level on US'%epoch,combine=False)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    fig=plot_peri_collection(list_peri_3b(data_c),'%s Ca-level on CS+/-'%epoch,combine=False)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_peri2.pdf')\n",
    "for epoch in la.epochs.values:\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    fig=plot_peri_collection(list_peri_3a(spike_c),'%s Spiking on US'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    fig=plot_peri_collection(list_peri_3b(spike_c),'%s Spiking on CS+/-'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "for epoch in la.epochs.values:\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    fig=plot_peri_collection(list_peri_3a(data_c),'%s Ca-level on US'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    fig=plot_peri_collection(list_peri_3b(data_c),'%s Ca-level on CS+/-'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig=plot_peri_collection(list_peri_3a(df_spike),'Spiking',combine=False)\n",
    "fig=plot_peri_collection(list_peri_3a(df_spike),'Spiking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual ROIs\n",
    "* since there are many of them, save figure to pdf\n",
    "* THIS WILL <font color=\"red\">TAKE A WHILE</font>, consider testing with a small range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roi(df_spike, df_data, filaname, grp, title_template, by_epoch=False, div=None, fill=None):\n",
    "    pp = PdfPages(filaname)\n",
    "    for i in range(0,len(data.rois)):\n",
    "        spike_c = df_spike.loc[(slice(None),data.rois[i]),:]\n",
    "        data_c = df_data.loc[(slice(None),data.rois[i]),:]\n",
    "        #raw_c = df_raw.loc[(slice(None),data.rois[i]),:]\n",
    "        if by_epoch:\n",
    "            fig = la.plot_epochs(spike_c, data_c, None, data.experiment_traits, etc, data.FPS, grp, title=title_template%(i,data.rois[i]), div=div, fill=fill)\n",
    "        else:\n",
    "            fig = la.plot_data(spike_c, data_c, None, data.experiment_traits, data.FPS, grp, title=title_template%(i,data.rois[i]), div=div, fill=fill)\n",
    "        pp.savefig()\n",
    "        plt.close(fig)\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if batch_animal is None:\n",
    "    raise ValueError(\"You don't want to run this automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roi1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roi2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roiAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging over intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intervals aligned to events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avg1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s',div=acenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avg2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s',div=acenters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avgAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True,div=acenters, fill='err')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging over bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roi(b_spike, b_data, animal+'_bin1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s',div=bcenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(a_spike, a_data, animal+'_bn2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s',div=bcenters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roi(a_spike, a_data, animal+'_binAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True,div=acenters, fill='err')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine information\n",
    "ord1 = z_data.reindex(data.mirow, data.icol)\n",
    "et1 = data.experiment_traits.copy().loc[:,la.sort_learning+['day_num','session_num']]\n",
    "ord1 = ord1.join(et1, how='inner').reset_index().drop('time', axis=1).set_index(la.sort_learning+['roi_id', 'session_num']).sort_index()\n",
    "ord1.columns.name='Spike'\n",
    "print(ord1.shape)\n",
    "display(ord1.head())\n",
    "\n",
    "# Search for days that contain experiments with same traits and session_num\n",
    "# These entries would jeopardize unstacking\n",
    "et2 = et1.reset_index(drop=True).set_index(la.sort_learning+['session_num']).sort_index()\n",
    "second_occur = et2.index.duplicated()\n",
    "set1 = et2.loc[second_occur,'day_num'].unique()\n",
    "all_occur = et2.index.get_duplicates()\n",
    "set_all = et2.loc[all_occur,'day_num'].unique()\n",
    "set2 = np.array(list(set(set_all)-set(set1)))\n",
    "print(set1,set2)\n",
    "\n",
    "# Filter out second occurrences stored in set2\n",
    "if len(set2):\n",
    "    ord1 = ord1[ord1.loc[:,'day_num'].apply(lambda x: x not in set2)]\n",
    "print(ord1.shape)\n",
    "\n",
    "# Reshape for correlation analysis\n",
    "# integer values get converted to float if needed to hold NaN-s\n",
    "calendar = ord1['day_num'].unstack(fill_value=0)\n",
    "ord1 = ord1.drop(['day_num'], axis=1).unstack()\n",
    "display(calendar.head())\n",
    "display(ord1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the pre-learning structure, without airpuff\n",
    "key_ref = ('Post-Learning','CS+','W+','A+')\n",
    "time_ref = np.array([15, 40])\n",
    "col_ref = slice(int(time_ref[0]*data.FPS),int(time_ref[1]*data.FPS))\n",
    "sel = ord1.loc[key_ref+(slice(None),),col_ref]\n",
    "print(key_ref,time_ref,col_ref,sel.shape)\n",
    "\n",
    "# Correlate\n",
    "corr_df = sel.T.corr()\n",
    "corr_np = corr_df.fillna(0).values\n",
    "\n",
    "# Discard invalid series\n",
    "keep = (np.diag(corr_np) == 1.0)\n",
    "corr_np = corr_np[keep,:][:,keep]\n",
    "\n",
    "# Show\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "img = ax[0].matshow(corr_df.values)\n",
    "img = ax[1].matshow(corr_np)\n",
    "fig.colorbar(img, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_correl.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define an ordering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "sq_dist = squareform(1.0-corr_np)\n",
    "corr_link = linkage(sq_dist, 'average')\n",
    "fig, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "fig.suptitle('Reference is presented here: '+(', '.join(np.array(key_ref)))+\n",
    "            ' and time '+('..'.join(time_ref.astype(str)))+'s',fontsize=16)\n",
    "labels = sel.index.get_level_values(4).to_series().reset_index(drop=True)[keep]\n",
    "dendo = dendrogram(corr_link, ax=ax[1], labels=labels.values, leaf_font_size=2.5, orientation='left')\n",
    "ax[1].set_title('Distance of firing patterns')\n",
    "corr_order = dendo['leaves']\n",
    "# Show reordered\n",
    "img = ax[0].matshow(corr_np[corr_order,:][:,corr_order], origin='lower', vmin=-0.8, vmax=1)\n",
    "ax[0].xaxis.set_ticks_position('bottom')\n",
    "ax[0].set_title('Ordered correlation matrix', y=1.0)\n",
    "fig.colorbar(img)\n",
    "pp.savefig(dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phase_start = data.event_frames+data.FPS\n",
    "phase_end = data.event_frames[1:]-data.FPS\n",
    "\n",
    "num_phases = 3\n",
    "num_rows = len(et.index)\n",
    "num_cols = num_phases\n",
    "fig, ax = plt.subplots(num_rows,num_cols, figsize=(5*num_cols,5*num_rows))\n",
    "fig.suptitle('Correlation structure under different conditions: learning_epoch, context, port, puffed\\n'+\n",
    "             '(small number of trials might lead to larger percieved correlation)\\n'+\n",
    "             '(in phases Ready, CS, Trace the conditions A+ and A- should be very similar)',fontsize=16)\n",
    "#ax = np.ravel(ax)\n",
    "mx = {}\n",
    "mi = pd.DataFrame([], index=pd.Index(la.phases[0:num_phases],name='phase'), columns = et.index).unstack().index\n",
    "ds = pd.DataFrame(columns=mi)\n",
    "\n",
    "for row,col in itertools.product(range(0,num_rows),range(0,num_cols)):\n",
    "    # Find the pre-learning structure\n",
    "    key = et.index[row]\n",
    "    phase = la.phases[col]\n",
    "    count = et.ix[row]\n",
    "    col_sel = slice(int(phase_start[col]),int(phase_end[col]))\n",
    "    sel = ord1.loc[key+(slice(None),),col_sel]\n",
    "    print(key,phase,ord1.shape,sel.shape)\n",
    "    \n",
    "    # Correlate\n",
    "    corr_tmp = sel.T.corr()\n",
    "    corr_tmp = corr_tmp.fillna(0).values\n",
    "\n",
    "    # Discard invalid series\n",
    "    #if len(corr_tmp):\n",
    "    corr_tmp = corr_tmp[keep,:][:,keep][corr_order,:][:,corr_order]\n",
    "    img = ax[row,col].matshow(corr_tmp, origin='lower', vmin=-0.8, vmax=1)\n",
    "    ax[row,col].xaxis.set_ticks_position('bottom')\n",
    "        \n",
    "    mx[key+(phase,)] = corr_tmp\n",
    "    ds[key+(phase,)] = np.ravel(corr_tmp+np.diag(np.nan*np.diag(corr_tmp)))\n",
    "    ax[row,col].set_title('%s, %s: %d'%(key,phase,count))\n",
    "pp.savefig(dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of the correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rows = len(et.index)\n",
    "num_cols = num_phases\n",
    "\n",
    "fig, ax = plt.subplots(num_rows,num_cols, figsize=(5*num_cols,5*num_rows))\n",
    "fig.suptitle('Distribution of the above correlation coefficients\\n(diagonals excluded)',fontsize=16)\n",
    "#ax = np.ravel(ax)\n",
    "\n",
    "for row,col in itertools.product(range(0,num_rows),range(0,num_cols)):\n",
    "    key = et.index[row]\n",
    "    phase = la.phases[col]\n",
    "    count = et.ix[row]\n",
    "    col_sel = slice(int(phase_start[col]),int(phase_end[col]))\n",
    "    sel = ord1.loc[key+(slice(None),),col_sel]\n",
    "    print(key,phase,ord1.shape,sel.shape)\n",
    "\n",
    "    corr_tmp = mx[key+(phase,)]\n",
    "    corr_tmp = corr_tmp+np.diag(np.nan*np.diag(corr_tmp))\n",
    "    ax[row,col].hist(np.ravel(corr_tmp),range=(-1,1),bins=20)\n",
    "    ax[row,col].set_yscale('log')\n",
    "    ax[row,col].set_title('%s, %s: %d'%(key,phase,count))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#help(pd.tools.plotting.table)\n",
    "# FIXME index column toooo wide\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,16))\n",
    "fig.suptitle('Statistics on the correlation coefficients',fontsize=16)\n",
    "ax.axis('off')\n",
    "#ax.set_position([.5, 0.2, 0.5, 0.6])\n",
    "a = la.df_epoch(np.round(ds.describe(),4).T)\n",
    "cw = np.ones((len(a.columns),))\n",
    "#t = pd.tools.plotting.table(ax, a, loc='upper right', fontsize=12, colWidths=0.6*cw/np.sum(cw))\n",
    "tab = mpl.table.table(ax, cellText=a.values,\n",
    "                             rowLabels=[', '.join(x) for x in a.index.values], colLabels=a.columns.values.astype(str),\n",
    "                             loc='upper right', fontsize=20, colWidths=0.6*cw/np.sum(cw), bbox=[0.3,0,0.7,1], cellLoc='center')\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rows = num_phases\n",
    "num_cols = len(la.epochs)\n",
    "fig, ax = plt.subplots(num_rows,num_cols, figsize=(5*num_cols,5*num_rows), sharex=True, sharey=True)\n",
    "fig.suptitle('Distribution of the above correlation coefficients\\n(diagonals excluded)',fontsize=16)\n",
    "#mi = pd.MultiIndex.from_product([['CS+','CS-'],la.port,la.puff],names=['context','port','puffed'])\n",
    "#mi = mi.insert(0,('Baseline','W+','A-'))\n",
    "mi = pd.MultiIndex.from_tuples(la.legal_conditions,names=['context','port','puffed'])\n",
    "#color = ['y','r','r','g','g','b','b','g','g']\n",
    "color = ['y', 'magenta','purple','red','maroon','cyan','lime']\n",
    "cat = len(mi)\n",
    "b = a.reset_index().set_index(['phase']+la.sort_learning)\n",
    "for (irow,row), (icol,col) in itertools.product(enumerate(la.phases),enumerate(la.epochs)):\n",
    "    try:\n",
    "        bar = b.loc[(row, col),:].reindex(mi)\n",
    "        ax[irow,icol].set_title(col)\n",
    "        ax[irow,icol].set_ylabel(row)\n",
    "        low, high = [0]+bar['25%'].fillna(0).tolist(),[0]+bar['75%'].fillna(0).tolist()\n",
    "        ax[irow,icol].fill_between(np.arange(0,cat+1), low, high, alpha=0.1, interpolate=False, color='grey', edgecolor=None, step='pre')\n",
    "        ax[irow,icol].bar(range(0,cat),bar['mean'],1,yerr=bar['std'],color=color)\n",
    "        ax[irow,icol].set_xticks(np.arange(0,cat)+0.5)\n",
    "        ax[irow,icol].set_xticklabels(mi.values, rotation='vertical')\n",
    "        \n",
    "    except KeyError:\n",
    "        pass\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#help(pd.tools.plotting.table)\n",
    "# FIXME index column toooo wide\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,16))\n",
    "fig.suptitle('Statistics on the absolute value of correlation coefficients',fontsize=16)\n",
    "ax.axis('off')\n",
    "#ax.set_position([.5, 0.2, 0.5, 0.6])\n",
    "a = la.df_epoch(np.round(np.abs(ds).describe(),4).T)\n",
    "cw = np.ones((len(a.columns),))\n",
    "#t = pd.tools.plotting.table(ax, a, loc='upper right', fontsize=12, colWidths=cw/np.sum(cw))\n",
    "tab = mpl.table.table(ax, cellText=a.values,\n",
    "                             rowLabels=[', '.join(x) for x in a.index.values], colLabels=a.columns.values.astype(str),\n",
    "                             loc='upper right', fontsize=20, colWidths=0.6*cw/np.sum(cw), bbox=[0.3,0,0.7,1], cellLoc='center')\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rows = num_phases\n",
    "num_cols = len(la.epochs)\n",
    "fig, ax = plt.subplots(num_rows,num_cols, figsize=(5*num_cols,5*num_rows), sharex=True, sharey=True)\n",
    "fig.suptitle('Distribution of the above absolute value of the correlation coefficients\\n(diagonals excluded)',fontsize=16)\n",
    "#mi = pd.MultiIndex.from_product([['CS+','CS-'],la.port,la.puff],names=['context','port','puffed'])\n",
    "#mi = mi.insert(0,('Baseline','W+','A-'))\n",
    "mi = pd.MultiIndex.from_tuples(la.legal_conditions,names=['context','port','puffed'])\n",
    "#color = ['y','r','r','g','g','b','b','g','g']\n",
    "color = ['y', 'magenta','purple','red','maroon','cyan','lime']\n",
    "cat = len(mi)\n",
    "b = a.reset_index().set_index(['phase']+la.sort_learning)\n",
    "for (irow,row), (icol,col) in itertools.product(enumerate(la.phases),enumerate(la.epochs)):\n",
    "    try:\n",
    "        bar = b.loc[(row, col),:].reindex(mi)\n",
    "        ax[irow,icol].set_title(col)\n",
    "        ax[irow,icol].set_ylabel(row)\n",
    "        low, high = [0]+bar['25%'].fillna(0).tolist(),[0]+bar['75%'].fillna(0).tolist()\n",
    "        ax[irow,icol].fill_between(np.arange(0,cat+1), low, high, alpha=0.1, interpolate=False, color='grey', edgecolor=None, step='pre')\n",
    "        ax[irow,icol].bar(range(0,cat),bar['mean'],1,yerr=bar['std'],color=color)\n",
    "        ax[irow,icol].set_xticks(np.arange(0,cat)+0.5)\n",
    "        ax[irow,icol].set_xticklabels(mi.values, rotation='vertical')\n",
    "        \n",
    "    except KeyError:\n",
    "        pass\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity of correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_rows = len(et.index)\n",
    "num_cols = num_phases\n",
    "\n",
    "change = np.zeros((num_cols,num_rows,num_rows))\n",
    "for col in range(0,num_cols):\n",
    "    phase = la.phases[col]\n",
    "    for row1 in range(0,num_rows):\n",
    "        key1 = et.index[row1]\n",
    "        count1 = et.ix[row1]\n",
    "        for row2 in range(0,num_rows):\n",
    "            key2 = et.index[row2]\n",
    "            count2 = et.ix[row2]\n",
    "            change[col,row1,row2] = np.linalg.norm(np.ravel(mx[key1+(phase,)]-mx[key2+(phase,)])/np.size(mx[key2+(phase,)]),2)\n",
    "\n",
    "for col in range(0,num_cols):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "    fig.tight_layout(rect=[0.4,0,0.95,0.55])\n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.gca()\n",
    "    img = ax.matshow(change[col]+np.diag(np.nan*np.diag(change[col])), cmap=plt.get_cmap('rainbow'))\n",
    "\n",
    "    fig.suptitle('Difference between test cases (RMS distance)\\n'+', '.join(et.index.names),fontsize=16)\n",
    "    ax.set_xticks(np.array(range(0,len(et.index))))\n",
    "    ax.set_xticklabels(et.index.values.tolist(),rotation=90)\n",
    "    ax.set_yticks(np.array(range(0,len(et.index))))\n",
    "    ax.set_yticklabels(et.index.values.tolist())\n",
    "\n",
    "    # without set_yticks\n",
    "    # ax.set_yticklabels([tuple()]+et.index.values.tolist())\n",
    "    fig.colorbar(img)\n",
    "    pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
