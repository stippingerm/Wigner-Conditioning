{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to install module future, not importing from \\_\\_future\\_\\_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from future.utils import PY3\n",
    "import future\n",
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "#from IPython.display import display\n",
    "import IPython.display as disp\n",
    "display = disp.display\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "zscore, describe = stats.mstats.zscore, stats.describe\n",
    "import warnings\n",
    "import datetime\n",
    "dt, td = datetime.datetime, datetime.timedelta\n",
    "import imp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ca_lib as la\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display database folders\n",
    "display(os.listdir('../_share/Losonczi/'))\n",
    "\n",
    "# Select animal\n",
    "#animal = 'msa1215_1'; FPS = 30\n",
    "#animal = 'msa0216_4'; FPS = 8\n",
    "animal = 'msa0316_1'; FPS = 8\n",
    "#animal = 'msa0316_3'; FPS = 8\n",
    "#animal = 'msa0316ag_1'; FPS = 8\n",
    "\n",
    "# List dir\n",
    "mydir = os.path.join('../_share/Losonczi',animal)\n",
    "os.listdir(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Available trials and ROIs\n",
    "data = la.load_files(mydir)\n",
    "print (data.raw.shape, '\\n', data.trials, '\\n', data.rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Post-Learning may repeat session_num therefore an additional index,\n",
    "# day_num is created. See msa0316_1.\n",
    "# It seems though that Pre-Learning and Learning treats session_num as documented.\n",
    "display(data.experiment_traits.head())\n",
    "display(data.experiment_traits[data.experiment_traits['day_leap']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment protocol configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et = data.experiment_traits.copy()\n",
    "et = la.df_epoch(et.groupby(['learning_epoch','context','puffed','port']).size().to_frame(name='count'))\n",
    "#et.to_clipboard()\n",
    "disp.display(disp.HTML('<font color=\"red\">ATTENTION, </font>for later conformity we store columns in a <b>different order</b>!!!'))\n",
    "display(la.df_epoch(et))\n",
    "\n",
    "et = data.experiment_traits.copy()\n",
    "etc= et.groupby(['context','port','puffed']).size().to_frame(name='count')\n",
    "et = la.df_epoch(et.groupby(['learning_epoch','context','port','puffed']).size().to_frame(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data = data.filtered\n",
    "df_raw = data.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See how many ROIs are available for which frames\n",
    "\n",
    "avail_sum = (~data.filtered.isnull()).sum() / len(data.trials)\n",
    "plt.plot(avail_sum)\n",
    "plt.xlabel('Camera frame within experiment')\n",
    "plt.ylabel('Available ROIs on average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See which ROI is available in which trial and for how many frames\n",
    "\n",
    "avail = ((~data.filtered.isnull()).sum(axis=1)).to_frame('nFrames').unstack()\n",
    "\n",
    "print(avail.shape)\n",
    "display(avail.head())\n",
    "display(avail.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create boolean DataFrame which ROI is spiking in which camera frame\n",
    "\n",
    "# create empty structure for cumsum\n",
    "df_template = pd.DataFrame(data=0,index=data.mirow,columns=data.icol)\n",
    "df_spike = df_template.copy()\n",
    "\n",
    "# select spike data\n",
    "spikes = data.transients.loc[data.transients['in_motion_period']==False,['start_frame','stop_frame']]\n",
    "spikes['count']=1\n",
    "\n",
    "# fill in spike start and stop points\n",
    "sp = spikes[['start_frame','count']].pivot(columns='start_frame').fillna(0)\n",
    "df_spike = df_spike.add(sp['count'], fill_value=0)\n",
    "sp = spikes[['stop_frame','count']].pivot(columns='stop_frame').fillna(0)\n",
    "df_spike = df_spike.add(-sp['count'], fill_value=0)\n",
    "\n",
    "# cumulate, converion to int is not adviced if using NaNs\n",
    "df_spike = df_spike.cumsum(axis=1).astype(int)\n",
    "\n",
    "print('table shape', df_spike.shape, 'active frames*ROIs', df_spike.sum().sum())\n",
    "display(df_spike.head(25))\n",
    "display(df_spike.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create boolean DataFrame whether licking happens in camera frame\n",
    "\n",
    "# Check for valid data and calculate their frame\n",
    "print('All entries', data.behavior.shape)\n",
    "df_lick = data.behavior[data.behavior.loc[:,'stop_time']>data.behavior.loc[:,'start_time']].copy()\n",
    "print('Valid licks', df_lick.shape)\n",
    "df_lick['mid_frame'] = (FPS*(df_lick['start_time']+df_lick['stop_time'])/2).apply(np.round).astype(int)\n",
    "display(df_lick.head())\n",
    "display(df_lick.tail())\n",
    "# Convert to a DataFrame like df_data or df_raw, this eventually skips multiple licks in one camera frame\n",
    "df_lick = df_lick.reset_index().rename(columns={'index':'time'})\n",
    "df_lick = df_lick.drop_duplicates(['time','mid_frame']).pivot(index='time', columns='mid_frame')\n",
    "display(df_lick.head())\n",
    "df_lick = pd.DataFrame(index=pd.Index([],name='time'),columns=data.icol).append(\n",
    "    ~df_lick['lick_idx'].isnull()).fillna(0).astype(int)\n",
    "display(df_lick.head())\n",
    "# Number of remaining licks\n",
    "print('Remaining licks',df_lick.sum().sum())\n",
    "# Smoothen\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "df_lick = df_lick.apply(lambda x: gaussian_filter(x.astype(float), sigma=2), axis=1, raw=True)\n",
    "display(df_lick.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_spike = la.pd_zscore_by_roi(df_spike, FPS, -2*FPS, axis=1)\n",
    "z_data = la.pd_zscore_by_roi(df_data, FPS, -2*FPS, axis=1)\n",
    "z_raw = la.pd_zscore_by_roi(df_raw, FPS, -2*FPS, axis=1)\n",
    "z_lick = la.pd_zscore_clip(df_lick, FPS, -2*FPS, axis=1)\n",
    "\n",
    "z_data = z_data.sort_index()\n",
    "z_raw = z_raw.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "class helpmultipage(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.isopen = False\n",
    "        self.open()\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "        \n",
    "    def savefig(self, dpi=None):\n",
    "        if self.isopen:\n",
    "            self.pp.savefig(dpi=dpi)\n",
    "\n",
    "    def open(self):\n",
    "        if (~self.isopen) and len(self.filename):\n",
    "            self.pp = PdfPages(self.filename)\n",
    "            self.isopen = True\n",
    "        \n",
    "    def close(self):\n",
    "        if self.isopen:\n",
    "            self.pp.close()\n",
    "        self.isopen = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanatory figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage('explanatory.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "center = FPS * (la.events[:-1]+la.events[1:]) /2\n",
    "left = FPS * la.events\n",
    "width = FPS * (la.events[1:]-la.events[:-1])\n",
    "vcenter = 0.0\n",
    "vstart = -0.5\n",
    "\n",
    "def label90(x,y,text):\n",
    "    ax.text(x, y, text, ha=\"center\", va=\"center\", family='sans-serif', size=14, rotation=90)\n",
    "\n",
    "fig, (empty, ax) = plt.subplots(2,1,figsize=(6,8))\n",
    "fig.tight_layout(pad=3)\n",
    "empty.axis('off')\n",
    "#ax = fig.gca()\n",
    "fig.suptitle('Explanatory figure')\n",
    "ax.set_xlabel('Camera frame')\n",
    "ax.set_ylabel('z-scored activity')\n",
    "ax.set_ylim(vstart,vstart+1)\n",
    "ax.plot(z_spike.mean(axis=0)+0.00, label=\"(CategoryA, True): #trials\", c=(1,1,0))\n",
    "ax.plot(z_spike.mean(axis=0)+0.02, label=\"(CategoryB, True): #trials\", c=(.5,1,.5))\n",
    "ax.plot(-z_spike.mean(axis=0)+0.00, label=\"(CategoryA, False): #trials\", c=(1,.8,1))\n",
    "ax.plot(-z_spike.mean(axis=0)+0.02, label=\"(CategoryB, False): #trials\", c=(.5,1,1))\n",
    "patches = []\n",
    "# mark delay\n",
    "label90(center[0], vcenter, 'excitation by\\nshowing water')\n",
    "# mark CS\n",
    "rect = mpatches.Rectangle((left[1],vstart), width[1], 1, ec=\"none\")\n",
    "patches.append(rect)\n",
    "label90(center[1], vcenter, 'CSÂ± if tone\\n\"Baseline\" otherwise')\n",
    "# mark delay\n",
    "label90(center[2], vcenter, 'delay')\n",
    "# mark UC\n",
    "rect = mpatches.Rectangle((left[3],vstart), width[3], 1, ec=\"none\")\n",
    "patches.append(rect)\n",
    "label90(center[3], vcenter, 'UC if any')\n",
    "# mark water\n",
    "ax.text((left[0]+left[3])/2, vstart, \"water source present\\niff allowed to lick\",\n",
    "        ha=\"center\", va=\"bottom\", family='sans-serif', size=14, bbox=dict(boxstyle=\"DArrow\", pad=0.0, fc='c'))\n",
    "\n",
    "for i in range(0,len(la.events)):\n",
    "    ax.axvline(x=la.events[i]*FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "colors = np.linspace(0, 1, len(patches))\n",
    "collection = PatchCollection(patches, cmap=plt.cm.hsv, alpha=0.1)\n",
    "collection.set_array(np.array(colors))\n",
    "ax.add_collection(collection)\n",
    "\n",
    "leg = ax.legend(loc='lower center', title=\"Category name, Condition name\",\n",
    "               bbox_to_anchor=(0.5, 1.1))\n",
    "leg.get_title().set_fontsize('large')\n",
    "leg.get_title().set_fontweight('bold')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', UserWarning)\n",
    "    fig.show()\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_pop.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "la.plot_data(df_spike, df_data, df_lick, data.experiment_traits, FPS)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-scored spiking\n",
    "Spiking is \"True\" in the [intervals) given in transients_data.hc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bsections = np.arange(0,60,5)*FPS\n",
    "bcenters = (bsections[1:]+bsections[:-1])/2\n",
    "#mybfun = lambda x: la.func_over_intervals(np.nanmean, bsections, np.array(x))\n",
    "mybfun = pd.DataFrame.mean\n",
    "\n",
    "zb_spike = la.pd_aggr_col(z_spike, mybfun, bsections, bcenters.astype(str))\n",
    "zb_data = la.pd_aggr_col(z_data, mybfun, bsections, bcenters.astype(str))\n",
    "zb_raw = la.pd_aggr_col(z_raw, mybfun, bsections, bcenters.astype(str))\n",
    "zb_lick = la.pd_aggr_col(z_lick, mybfun, bsections, bcenters.astype(str))\n",
    "b_lick = la.pd_aggr_col(df_lick, mybfun, bsections, bcenters.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asections = np.append(la.events,[60])*FPS\n",
    "acenters = (asections[1:]+asections[:-1])/2\n",
    "#myafun = lambda x: la.func_over_intervals(np.nanmean, asections, np.array(x))\n",
    "myafun = pd.DataFrame.mean\n",
    "\n",
    "za_spike = la.pd_aggr_col(z_spike, myafun, asections, acenters.astype(str))\n",
    "za_data = la.pd_aggr_col(z_data, myafun, asections, acenters.astype(str))\n",
    "za_raw = la.pd_aggr_col(z_raw, myafun, asections, acenters.astype(str))\n",
    "za_lick = la.pd_aggr_col(z_lick, myafun, asections, acenters.astype(str))\n",
    "a_lick = la.pd_aggr_col(df_lick, myafun, asections, acenters.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single criterion\n",
    "* interestingly population activity is high both for puffed and port during the UC session, to be checked in the cross-correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = [['context'],['learning_epoch'],['port'],['puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two criteria\n",
    "* selecting (port and puffed) makes clear that only the airpuffing correlates with UC (they are the same) and not port\n",
    "* selecting (epoch and puffed) shows that activity during UC decreases in the post-learning period\n",
    "* selecting (context and puffed) shows that CS+ alone does not involve higher population activity"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = [['context','learning_epoch'],['context','port'],['context','puffed'],['learning_epoch','puffed'],['learning_epoch','port'],['port','puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three criteria\n",
    "* comments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = [['context','learning_epoch','port'],['context','learning_epoch','puffed'],['context','port','puffed'],['learning_epoch','port','puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All criteria\n",
    "* There is no increased population activity for CS+ without puffing. (For mouse 0216_4 the 1 trial with port displays increase during the trace period - why?)\n",
    "* During learning mouse 0216_4 shows incresed activity during the UC phase for CS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = [['context','port','puffed']]\n",
    "la.plot_epochs(z_spike, z_data, df_lick, data.experiment_traits, etc, FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_epochs(zb_spike, zb_data, b_lick, data.experiment_traits, etc, FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_epochs(za_spike, za_data, a_lick, data.experiment_traits, etc, FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities conditional on epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_by_epoch(epoch):\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = z_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    raw_c = z_raw.reindex(experiment_c.index, level='time')\n",
    "    lick_c = df_lick.reindex(experiment_c.index)\n",
    "    print (experiment_c.shape, z_spike.shape)\n",
    "    spike_ca = la.pd_aggr_col(spike_c, myafun, asections, acenters.astype(str))\n",
    "    data_ca = la.pd_aggr_col(data_c, myafun, asections, acenters.astype(str))\n",
    "    raw_ca = la.pd_aggr_col(raw_c, myafun, asections, acenters.astype(str))\n",
    "    lick_ca = la.pd_aggr_col(lick_c, myafun, asections, acenters.astype(str))\n",
    "    print (spike_c.shape, spike_ca.shape)\n",
    "\n",
    "    grp = [['context','port'],['context','puffed'],['port','puffed']]\n",
    "    la.plot_data(spike_c, data_c, lick_c, data.experiment_traits, FPS, grp, title=epoch)\n",
    "    pp.savefig()\n",
    "    la.plot_data(spike_ca, data_ca, lick_ca, data.experiment_traits, FPS, grp, title=epoch+' averaged over events', div=acenters)\n",
    "    pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Pre-Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Post-Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual ROIs\n",
    "* since there are many of them, save figure to pdf\n",
    "* THIS WILL <font color=\"red\">TAKE A WHILE</font>, consider testing with a small range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roi(df_spike, df_data, filaname, grp, title_template, by_epoch=False, div=None):\n",
    "    pp = PdfPages(filaname)\n",
    "    for i in range(0,len(data.rois)):\n",
    "        spike_c = df_spike.loc[(slice(None),data.rois[i]),:]\n",
    "        data_c = df_data.loc[(slice(None),data.rois[i]),:]\n",
    "        #raw_c = df_raw.loc[(slice(None),data.rois[i]),:]\n",
    "        if by_epoch:\n",
    "            fig = la.plot_epochs(spike_c, data_c, None, data.experiment_traits, etc, FPS, grp, title=title_template%(i,data.rois[i]), div=div)\n",
    "        else:\n",
    "            fig = la.plot_data(spike_c, data_c, None, data.experiment_traits, FPS, grp, title=title_template%(i,data.rois[i]), div=div)\n",
    "        pp.savefig()\n",
    "        plt.close(fig)\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raise ValueError(\"You don't want to run this automaticly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ca_lib as la\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roi1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roi2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roiAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging over intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intervals aligned to events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_spike = la.pd_aggr_col(df_spike, myafun, asections, acenters.astype(str))\n",
    "a_data = la.pd_aggr_col(df_data, myafun, asections, acenters.astype(str))\n",
    "a_raw = la.pd_aggr_col(df_raw, myafun, asections, acenters.astype(str))\n",
    "a_lick = la.pd_aggr_col(df_lick, myafun, asections, acenters.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_data = a_data.sort_index()\n",
    "a_raw = a_raw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avg1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s',div=acenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avg2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s',div=acenters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avgAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True,div=acenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pp = PdfPages(animal+'_avg1crit.pdf')\n",
    "for i in range(0,len(data.rois)):\n",
    "    spike_c = a_spike.loc[(slice(None),data.rois[i]),:]\n",
    "    data_c = a_data.loc[(slice(None),data.rois[i]),:]\n",
    "    raw_c = a_raw.loc[(slice(None),data.rois[i]),:]\n",
    "    fig = plot_roi(spike_c, data_c, [['context'],['learning_epoch'],['port'],['puffed']],\n",
    "                   title='ROI %d:\\n%s'%(i,data.rois[i]), div=centers)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pp = PdfPages(animal+'_avg2crit.pdf')\n",
    "for i in range(0,len(data.rois)):\n",
    "    spike_c = a_spike.loc[(slice(None),data.rois[i]),:]\n",
    "    data_c = a_data.loc[(slice(None),data.rois[i]),:]\n",
    "    raw_c = a_raw.loc[(slice(None),data.rois[i]),:]\n",
    "    fig = plot_roi(spike_c, data_c, [['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],\n",
    "                   title='ROI %d:\\n%s'%(i,data.rois[i]), div=centers)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pp = PdfPages(animal+'_avgAcrit.pdf')\n",
    "for i in range(0,len(data.rois)):\n",
    "    spike_c = a_spike.loc[(slice(None),data.rois[i]),:]\n",
    "    data_c = a_data.loc[(slice(None),data.rois[i]),:]\n",
    "    raw_c = a_raw.loc[(slice(None),data.rois[i]),:]\n",
    "    grp = [['context','port','puffed']]\n",
    "    fig = plot_epochs(spike_c, data_c, None, grp, title='ROI %d:\\n%s'%(i,data.rois[i]))\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging over bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_spike = la.pd_aggr_col(df_spike, mybfun, bsections, bcenters.astype(str))\n",
    "b_data = la.pd_aggr_col(df_data, mybfun, bsections, bcenters.astype(str))\n",
    "b_raw = la.pd_aggr_col(df_raw, mybfun, bsections, bcenters.astype(str))\n",
    "b_lick = la.pd_aggr_col(df_lick, mybfun, bsections, bcenters.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_data = b_data.sort_index()\n",
    "b_raw = b_raw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roi(b_spike, b_data, animal+'_bin1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s',div=bcenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(a_spike, a_data, animal+'_bn2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s',div=bcenters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_roi(a_spike, a_data, animal+'_binAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True,div=bcenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pp = PdfPages(animal+'_bin1crit.pdf')\n",
    "for i in range(0,len(rois)):\n",
    "    spike_c = b_spike.loc[(slice(None),rois[i]),:]\n",
    "    data_c = b_data.loc[(slice(None),rois[i]),:]\n",
    "    raw_c = b_raw.loc[(slice(None),rois[i]),:]\n",
    "    fig = plot_roi(spike_c, data_c, [['context'],['learning_epoch'],['port'],['puffed']],\n",
    "                   title='ROI %d:\\n%s'%(i,rois[i]), div=centers)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pp = PdfPages(animal+'_bin2crit.pdf')\n",
    "for i in range(0,len(rois)):\n",
    "    spike_c = b_spike.loc[(slice(None),rois[i]),:]\n",
    "    data_c = b_data.loc[(slice(None),rois[i]),:]\n",
    "    raw_c = b_raw.loc[(slice(None),rois[i]),:]\n",
    "    fig = plot_roi(spike_c, data_c, [['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],\n",
    "                   title='ROI %d:\\n%s'%(i,rois[i]), div=centers)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pp = PdfPages(animal+'_binAcrit.pdf')\n",
    "for i in range(0,len(rois)):\n",
    "    spike_c = b_spike.loc[(slice(None),rois[i]),:]\n",
    "    data_c = b_data.loc[(slice(None),rois[i]),:]\n",
    "    raw_c = b_raw.loc[(slice(None),rois[i]),:]\n",
    "    grp = [['context','port','puffed']]\n",
    "    fig = plot_epochs(spike_c, data_c, None, grp, title='ROI %d:\\n%s'%(i,rois[i]))\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to ordinal, here we use indices that way\n",
    "et1 = experiment_traits.copy().drop('time', axis=1)\n",
    "et1[['session_num', 'day_num']] = et1[['session_num', 'day_num']].astype(int)\n",
    "ord1 = z_data.reindex(df_template.index, df_template.columns)\n",
    "ord1.columns = pd.Index(ord1.columns.values.astype(int), name=ord1.columns.name)\n",
    "\n",
    "# Combine information\n",
    "ord1 = ord1.join(et1, how='inner').reset_index().drop('time', axis=1).set_index(['roi_id','learning_epoch','context','port','puffed','session_num']).sort_index()\n",
    "ord1.columns.name='Spike'\n",
    "print(ord1.shape)\n",
    "display(ord1.head())\n",
    "\n",
    "# Search for days that contain experiments with same traits and session_num\n",
    "# These entries would jeopardize unstacking\n",
    "et2 = et1.reset_index(drop=True).set_index(['learning_epoch','context','port','puffed','session_num']).sort_index()\n",
    "second_occur = et2.index.duplicated()\n",
    "set1 = et2.loc[second_occur,'day_num'].unique()\n",
    "all_occur = et2.index.get_duplicates()\n",
    "set_all = et2.loc[all_occur,'day_num'].unique()\n",
    "set2 = np.array(list(set(set_all)-set(set1)))\n",
    "print(set1,set2)\n",
    "\n",
    "# Filter out second occurrences stored in set2\n",
    "if len(set2):\n",
    "    ord1 = ord1[ord1.loc[:,'day_num'].apply(lambda x: x not in set2)]\n",
    "print(ord1.shape)\n",
    "\n",
    "# Reshape for correlation analysis\n",
    "# some value get converted to float to be able to hold nan-s\n",
    "comp = ord1['day_num'].unstack().sort_index(axis=1)\n",
    "ord1 = ord1.drop(['day_num'], axis=1).unstack()\n",
    "ord1 = ord1.reset_index().set_index(['learning_epoch','context','port','puffed','roi_id']).sort_index()\n",
    "display(comp.head())\n",
    "display(ord1.head(10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Reorder\n",
    "#ord2 = ord1.reset_index().groupby(['learning_epoch','context','port','puffed','roi_id']).mean()\n",
    "ord2 = ord1.reset_index().set_index(['learning_epoch','context','port','puffed','roi_id'])\n",
    "# Change type for slicing\n",
    "ord2.columns = ord2.columns.values.astype(int)\n",
    "print(ord2.shape)\n",
    "display(ord2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the pre-learning structure, without airpuff\n",
    "key_ref = ('Pre-Learning','CS+',True,False)\n",
    "time_ref = np.array([15, 40])\n",
    "col_ref = slice(int(time_ref[0]*FPS),int(time_ref[1]*FPS))\n",
    "sel = ord1.loc[key_ref+(slice(None),),col_ref]\n",
    "print(sel.shape)\n",
    "\n",
    "# Correlate\n",
    "corr_df = sel.T.corr()\n",
    "corr_np = corr_df.fillna(0).values\n",
    "\n",
    "# Discard invalid series\n",
    "keep = (np.diag(corr_np) == 1.0)\n",
    "corr_np = corr_np[keep,:][:,keep]\n",
    "\n",
    "# Show\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].matshow(corr_df.values)\n",
    "ax[1].matshow(corr_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_correl.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define an ordering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "sq_dist = squareform(1.0-corr_np)\n",
    "corr_link = linkage(sq_dist, 'average')\n",
    "fig, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "fig.suptitle('Reference is presented here: '+(', '.join(np.array(key_ref)))+\n",
    "            ' and time '+('..'.join(time_ref.astype(str)))+'s')\n",
    "labels = sel.index.get_level_values(4).to_series().reset_index(drop=True)[keep]\n",
    "dendo = dendrogram(corr_link, ax=ax[1], labels=labels.values, leaf_font_size=2.5, orientation='left')\n",
    "ax[1].set_title('Distance of firing patterns')\n",
    "corr_order = dendo['leaves']\n",
    "# Show reordered\n",
    "cax = ax[0].matshow(corr_np[corr_order,:][:,corr_order], origin='lower', vmin=-0.8, vmax=1)\n",
    "ax[0].xaxis.set_ticks_position('bottom')\n",
    "ax[0].set_title('Ordered correlation matrix', y=1.0)\n",
    "fig.colorbar(cax)\n",
    "pp.savefig(dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_plots = len(et.index)\n",
    "num_rows = int(np.ceil(num_plots/3.0))\n",
    "fig, ax = plt.subplots(num_rows,3, figsize=(12,4.5*num_rows))\n",
    "fig.suptitle('Correlation structure under different conditions: learning_epoch, context, port, puffed\\n'+\n",
    "             '(small number of trials might lead to larger percieved correlation)')\n",
    "ax = np.ravel(ax)\n",
    "mx = {}\n",
    "ds = pd.DataFrame(columns=et.index)\n",
    "\n",
    "for idx in range(0,num_plots):\n",
    "    # Find the pre-learning structure\n",
    "    key = et.index[idx]\n",
    "    sel = ord1.loc[key+(slice(None),),col_ref]\n",
    "    print(key,ord1.shape,sel.shape)\n",
    "    \n",
    "    # Correlate\n",
    "    corr_tmp = sel.T.corr()\n",
    "    corr_tmp = corr_tmp.fillna(0).values\n",
    "\n",
    "    # Discard invalid series\n",
    "    #if len(corr_tmp):\n",
    "    corr_tmp = corr_tmp[keep,:][:,keep][corr_order,:][:,corr_order]\n",
    "    cax = ax[idx].matshow(corr_tmp, origin='lower', vmin=-0.8, vmax=1)\n",
    "    ax[idx].xaxis.set_ticks_position('bottom')\n",
    "        \n",
    "    mx[et.index[idx]] = corr_tmp\n",
    "    ds[et.index[idx]] = np.ravel(corr_tmp+np.diag(np.nan*np.diag(corr_tmp)))\n",
    "    ax[idx].set_title('%s: %d'%(et.index[idx],et.ix[idx]))\n",
    "pp.savefig(dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num_rows,3, figsize=(12,4.5*num_rows))\n",
    "fig.suptitle('Distribution of the above correlation coefficients\\n(diagonals excluded)')\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "for idx in range(0,num_plots):\n",
    "    corr_tmp = mx[et.index[idx]]\n",
    "    corr_tmp = corr_tmp+np.diag(np.nan*np.diag(corr_tmp))\n",
    "    ax[idx].hist(np.ravel(corr_tmp),range=(-1,1),bins=20)\n",
    "    ax[idx].set_yscale('log')\n",
    "    ax[idx].set_title('%s: %d'%(et.index[idx],et.ix[idx]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#help(pd.tools.plotting.table)\n",
    "# FIXME index column toooo wide\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.suptitle('Statistics on the correlation coefficients')\n",
    "ax.axis('off')\n",
    "ax.set_position([.5, 0.2, 0.5, 0.6])\n",
    "a = df_epoch(np.round(ds.describe(),4).T)\n",
    "cw = np.ones((len(a.columns),))\n",
    "t = pd.tools.plotting.table(ax, a, loc='upper right', fontsize=12, colWidths=cw/np.sum(cw))\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#help(pd.tools.plotting.table)\n",
    "# FIXME index column toooo wide\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.suptitle('Statistics on the absolute value of correlation coefficients')\n",
    "ax.axis('off')\n",
    "ax.set_position([.5, 0.2, 0.5, 0.6])\n",
    "a = df_epoch(np.round(np.abs(ds).describe(),4).T)\n",
    "cw = np.ones((len(a.columns),))\n",
    "t = pd.tools.plotting.table(ax, a, loc='upper right', fontsize=12, colWidths=cw/np.sum(cw))\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "change = np.zeros((num_plots,num_plots))\n",
    "for idx1 in range(0,num_plots):\n",
    "    for idx2 in range(0,num_plots):\n",
    "        change[idx1,idx2] = np.linalg.norm(np.ravel(mx[et.index[idx1]]-mx[et.index[idx2]])/np.size(mx[et.index[idx2]]),2)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "fig.tight_layout(rect=[0.4,0,0.95,0.55])\n",
    "#fig = plt.figure()\n",
    "#ax = fig.gca()\n",
    "cax = ax.matshow(change+np.diag(np.nan*np.diag(change)), cmap=plt.get_cmap('rainbow'))\n",
    "\n",
    "fig.suptitle('Difference between test cases (RMS distance)\\n'+', '.join(et.index.names))\n",
    "ax.set_xticks(np.array(range(0,len(et.index))))\n",
    "ax.set_xticklabels(et.index.values.tolist(),rotation=90)\n",
    "ax.set_yticks(np.array(range(0,len(et.index))))\n",
    "ax.set_yticklabels(et.index.values.tolist())\n",
    "\n",
    "# without set_yticks\n",
    "# ax.set_yticklabels([tuple()]+et.index.values.tolist())\n",
    "fig.colorbar(cax)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of spiking\n",
    "The first 1 second of the recording seems missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_firing(ax, experiment_id, rois=None):\n",
    "    # Plot all neural units in this experiment\n",
    "    if rois is None:\n",
    "        rois = transients_data.loc[experiment_id].index.unique()\n",
    "    for i in range(0,len(rois)):\n",
    "        unit = rois[i]\n",
    "        try:\n",
    "            firing = np.array(transients_data.loc[(experiment_id,unit),['start_frame', 'stop_frame']])\n",
    "            if len(firing):\n",
    "                ax.plot(firing.T,i*np.ones_like(firing.T),c='k')\n",
    "            firing = transients_data.loc[(experiment_id,unit),'max_frame']\n",
    "            if len(firing):\n",
    "                ax.plot(firing,i*np.ones_like(firing),'|',ms=5)\n",
    "        except:\n",
    "            pass\n",
    "    for i in range(0,len(events)):\n",
    "        ax.axvline(x=events[i]*FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "    ax.set_title('Transient peaks and durations ExID: '+experiment_id)\n",
    "    ax.set_xlabel('Camera frame')\n",
    "    ax.set_ylabel('Unit ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et3 = experiment_traits.copy().reset_index(drop=True)\n",
    "et3.loc[:,'session_num'] = et3.loc[:,'session_num'].astype(int)\n",
    "et3 = et3.sort_values(['learning_epoch','context','port','puffed','session_num']).set_index(['learning_epoch','context','port','puffed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_firing.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmax = transients_data.loc[:,['stop_frame']].max().values\n",
    "\n",
    "for idx, val in et3.iterrows():\n",
    "    fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "    ax.set_xlim(xmax=xmax)\n",
    "    experiment_id = val['time']\n",
    "    print (experiment_id)\n",
    "    fig.suptitle('learning_epoch, context, port, puffed: #context in epoch\\n'+\n",
    "        '%s: session %s'%(idx,val['session_num']))\n",
    "    plot_firing(ax, experiment_id, rois.values)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
