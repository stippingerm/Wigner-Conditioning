{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to install module future, not importing from \\_\\_future\\_\\_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from future.utils import PY3\n",
    "import future\n",
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats.mstats import zscore\n",
    "import warnings\n",
    "from datetime import datetime as dt, timedelta as td\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set event lengths\n",
    "durations=np.array([0,10,20,15,5])\n",
    "events=np.cumsum(durations)\n",
    "\n",
    "# Set date formate\n",
    "dtformat = '%Y-%m-%d-%Hh%Mm%Ss'\n",
    "\n",
    "# Display database folders\n",
    "display(os.listdir('../_share/Losonczi/'))\n",
    "\n",
    "# Select animal\n",
    "#animal = 'msa1215_1'; FPS = 30\n",
    "animal = 'msa0316_1'; FPS = 8\n",
    "\n",
    "# List dir\n",
    "mydir = os.path.join('../_share/Losonczi',animal)\n",
    "os.listdir(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load files\n",
    "experiment_traits = pd.read_hdf(os.path.join(mydir,'experiment_traits.h5'),key='table')\n",
    "raw_data = pd.read_hdf(os.path.join(mydir,'raw_data.h5'),key='table')\n",
    "df_data = pd.read_hdf(os.path.join(mydir,'df_data.h5'),key='table')\n",
    "transients_data = pd.read_hdf(os.path.join(mydir,'transients_data.h5'),key='table')\n",
    "behavior_data = pd.read_hdf(os.path.join(mydir,'behavior_data.h5'),key='table')\n",
    "max_nframe = df_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Available trials and ROIs\n",
    "trials = df_data.index.levels[0]\n",
    "rois = df_data.index.levels[1]\n",
    "print (df_data.shape, '\\n', trials, '\\n', rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Post-Learning may repeat session_num therefore an additional categorical index,\n",
    "# day_num is created.\n",
    "# It seems though that Pre-Learning and Learning treas session_num as documented.\n",
    "numtime = experiment_traits['time'].apply(lambda t: dt.strptime(t, dtformat))\n",
    "leapaday = (numtime.values[1:]-numtime.values[:-1]) > np.timedelta64(8,'h')\n",
    "numday = np.cumsum(np.append([0],leapaday.astype(int)))\n",
    "experiment_traits['day_num'] = numday.astype(str)\n",
    "display(experiment_traits[np.append([True],leapaday)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment protocol configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et = experiment_traits.copy()\n",
    "et['sum'] = 1\n",
    "display(et.groupby(['learning_epoch','context','puffed','licking']).sum())\n",
    "et = et.groupby(['learning_epoch','context','licking','puffed']).sum()\n",
    "### ATTENTION, for later conformity we store a different order than the one displayed here!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See how many ROIs are available for which frames\n",
    "\n",
    "avail_sum = (~df_data.isnull()).sum() / len(df_data.index.levels[0])\n",
    "plt.plot(avail_sum)\n",
    "plt.xlabel('Camera frame within experiment')\n",
    "plt.ylabel('Available ROIs on average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See which ROI is available in which trial and for how many frames\n",
    "\n",
    "## METHOD 1, step-by-step, simple availability\n",
    "#avail = df_data[[]].copy()\n",
    "#avail['isFound']=1\n",
    "#avail.reset_index() #[['time','roi_id','isFound']]\n",
    "## METHOD 2, directly with frame count\n",
    "avail = ((~df_data.isnull()).sum(axis=1)).to_frame('nFrames')\n",
    "\n",
    "# create table\n",
    "## METHOD A, step-by-step\n",
    "#avail.reset_index().pivot(index='time', columns='roi_id')\n",
    "## BETHOD B, taking advantage of multi-indexing\n",
    "avail = avail.unstack()\n",
    "\n",
    "print(avail.shape)\n",
    "display(avail.head())\n",
    "display(avail.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create boolean DataFrame which ROI is spiking in which camera frame\n",
    "\n",
    "# create empty structure for cumsum\n",
    "mir = pd.MultiIndex.from_product((trials.values,rois.values),names=('time','roi_id'))\n",
    "mic = pd.MultiIndex.from_product(('Spiking',np.array(range(0,max_nframe))),names=('','frame'))\n",
    "df_spike = pd.DataFrame(data=0,index=mir,columns=pd.Index(np.array(range(0,max_nframe)),name='frame'))\n",
    "df_spike.shape\n",
    "\n",
    "# select spike data\n",
    "spikes = transients_data.loc[transients_data['in_motion_period']==False,['start_frame','stop_frame']]\n",
    "spikes['count']=1\n",
    "\n",
    "# fill in spike start and stop points\n",
    "## METHOD 0, this kind of indeing would work for numpy, not here\n",
    "#ix0 = zip(spikes.reset_index()['time'],spikes.reset_index()['roi_id'])\n",
    "#ix1 = spikes['start_frame'].values\n",
    "#df_spike.loc[zip(ix0,ix1)]+=1\n",
    "## METHOD 1, slowest in both ways\n",
    "#for (idx,data) in spikes.iterrows():\n",
    "#    df_spike.loc[idx,data.values]+=[1,-1]\n",
    "## METHOD 2, fastest in both\n",
    "#for (idx,start,stop) in spikes.itertuples():\n",
    "#    df_spike.loc[idx,start]+=1\n",
    "#    df_spike.loc[idx,stop]-=1\n",
    "## ULTIMATE METHOD, without for loop is best:\n",
    "sp = spikes[['start_frame','count']].pivot(columns='start_frame').fillna(0)\n",
    "#sp.columns = pd.Index(sp.columns.levels[1].values) # would eliminate the need for ['count'] below\n",
    "df_spike = df_spike.add(sp['count'], fill_value=0)\n",
    "sp = spikes[['stop_frame','count']].pivot(columns='stop_frame').fillna(0)\n",
    "#sp.columns = pd.Index(sp.columns.levels[1].values) # would eliminate the need for ['count'] below\n",
    "df_spike = df_spike.add(-sp['count'], fill_value=0)\n",
    "\n",
    "# cumulate, converion to int is not adviced if using NaNs\n",
    "df_spike = df_spike.cumsum(axis=1).astype(int)\n",
    "\n",
    "print('table shape', df_spike.shape, 'active frames*ROIs', df_spike.sum().sum())\n",
    "display(df_spike.head(25))\n",
    "display(df_spike.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create boolean DataFrame whether licking happens in camera frame\n",
    "\n",
    "# Check for valid data and calculate their frame\n",
    "print(behavior_data.shape)\n",
    "df_lick = behavior_data[behavior_data.loc[:,'stop_time']>behavior_data.loc[:,'start_time']].copy()\n",
    "print(df_lick.shape)\n",
    "df_lick['mid_frame'] = (FPS*(df_lick['start_time']+df_lick['stop_time'])/2).apply(np.round).astype(int)\n",
    "display(df_lick.head())\n",
    "display(df_lick.tail())\n",
    "# Convert to a DataFrame like df_data or df_raw, this eventually skips multiple licks in one camera frame\n",
    "df_lick = df_lick.reset_index().rename(columns={'index':'time'})\n",
    "df_lick = df_lick.drop_duplicates(['time','mid_frame']).pivot(index='time', columns='mid_frame')\n",
    "display(df_lick.head())\n",
    "df_lick = (~df_lick['lick_idx'].isnull()).astype(int)\n",
    "df_lick.columns.name = ''\n",
    "display(df_lick.head())\n",
    "# Number of remaining licks\n",
    "print(df_lick.sum().sum())\n",
    "# Smoothen\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "df_lick = df_lick.apply(lambda x: gaussian_filter(x.astype(float), sigma=2), axis=1, raw=True)\n",
    "display(df_lick.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pd_zscore_rows(df):\n",
    "    ret = df.copy()\n",
    "    for idx, row in df.iterrows():\n",
    "        ret.loc[idx,:] = (row - row.mean())/row.std(ddof=0)\n",
    "    return ret\n",
    "\n",
    "def nan_zscore(data):\n",
    "    return (data-np.nanmean(data))/np.nanstd(data)\n",
    "    \n",
    "def pd_zscore(df, axis = 0):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', RuntimeWarning)\n",
    "        ret = df.apply(nan_zscore, axis=axis, raw=True)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## BENCHMARK\n",
    "#z_spike = pd_zscore_rows(df_spike)\n",
    "#z_data = pd_zscore_rows(df_data)\n",
    "#z_raw = pd_zscore_rows(df_raw)\n",
    "#z_lick = pd_zscore_rows(df_lick)\n",
    "\n",
    "## FAST\n",
    "z_spike = pd_zscore(df_spike, axis=1)\n",
    "z_data = pd_zscore(df_data, axis=1)\n",
    "z_raw = pd_zscore(raw_data, axis=1)\n",
    "z_lick = pd_zscore(df_lick, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_data = z_data.sort_index()\n",
    "z_raw = z_raw.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Introductory figure')\n",
    "plt.xlabel('Camera frame')\n",
    "plt.ylabel('Absolute activity')\n",
    "plt.plot(df_spike.mean(axis=0), label=\"Population activity\")\n",
    "for i in range(0,len(events)):\n",
    "    plt.axvline(x=events[i]*FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "class helpmultipage(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.isopen = False\n",
    "        self.open()\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "        \n",
    "    def savefig(self):\n",
    "        if self.isopen:\n",
    "            self.pp.savefig()\n",
    "\n",
    "    def open(self):\n",
    "        if ~self.isopen:\n",
    "            self.pp = PdfPages(self.filename)\n",
    "        self.isopen = True\n",
    "        \n",
    "    def close(self):\n",
    "        if self.isopen:\n",
    "            self.pp.close()\n",
    "        self.isopen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_activity(data, grp = ['context','learning_epoch','licking','puffed'],\n",
    "                  name = 'Population activity (spiking)', ax = None, div=None):\n",
    "    # NOTE: session_num is a string object therefore it is not included in the summation or averaging at the aggregation step of groupby\n",
    "    # but the traits licking and puffed are boolean and kept if uniform, so we get rid of them by conforming to the original index\n",
    "    from matplotlib.font_manager import FontProperties\n",
    "    fontP = FontProperties()\n",
    "    fontP.set_size('xx-small')\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca()\n",
    "    if len(grp):\n",
    "        res = data.join(experiment_traits,how='left').groupby(grp).mean().reindex(columns=data.columns)\n",
    "        count = data[[]].reset_index().drop_duplicates(['time']).set_index(['time']).join(experiment_traits,how='left').groupby(grp).count()\n",
    "        if (count.ndim>1):\n",
    "            count = count.ix[:,0]\n",
    "        for i in range(0,len(res)):\n",
    "            if div is None:\n",
    "                ax.plot(res.values[i],label=('%s: %d'%(res.index.values[i],count.values[i])))\n",
    "            else:\n",
    "                ax.plot(div,res.values[i],label=('%s: %d'%(res.index.values[i],count.values[i])))\n",
    "    else:\n",
    "        res = data.mean(axis=0)\n",
    "        if div is None:\n",
    "            ax.plot(res.values,label='whole popuation')\n",
    "        else:\n",
    "            ax.plot(div,res.values,label='whole popuation')\n",
    "    q = np.nanpercentile(res.values,[1,99])\n",
    "    ax.set_ylim(np.mean(q)+2*(q-np.mean(q)))\n",
    "    for i in range(0,len(events)):\n",
    "        ax.axvline(x=events[i]*FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "    ax.set_xlabel('Camera frame')\n",
    "    ax.set_ylabel(name)\n",
    "    leg = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), title=', '.join(grp)) # prop=fontP)\n",
    "    leg.get_title().set_fontsize('large')\n",
    "    leg.get_title().set_fontweight('bold')\n",
    "    #ax.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_data(df_spike, df_data, df_lick, grps = [[]], title=''):\n",
    "    ncol = len(grps)\n",
    "    fig, ax = plt.subplots(4, ncol, figsize=(6*ncol,13), sharex=True, squeeze=False, dpi=72)\n",
    "    fig.tight_layout(pad=3, h_pad=3)\n",
    "    if len(title):\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "    for i in range(0, ncol):\n",
    "        ax[0,i].axis('off')\n",
    "        plot_activity(df_spike,grps[i],\"Spiking\",ax=ax[1,i])\n",
    "        leg = ax[1,i].legend(loc='lower center', bbox_to_anchor=(0.5, 1.1), title=', '.join(grps[i]))\n",
    "        leg.get_title().set_fontsize('large')\n",
    "        leg.get_title().set_fontweight('bold')\n",
    "        plot_activity(df_data,grps[i],\"Ca-level\",ax=ax[2,i])\n",
    "        ax[2,i].legend_.remove()\n",
    "        plot_activity(df_lick,grps[i],\"Licking\",ax=ax[3,i])\n",
    "        ax[3,i].legend_.remove()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', UserWarning)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage('explanatory.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "center = FPS * (events[:-1]+events[1:]) /2\n",
    "left = FPS * events\n",
    "width = FPS * (events[1:]-events[:-1])\n",
    "vcenter = 0.0\n",
    "vstart = -0.5\n",
    "\n",
    "def label90(x,y,text):\n",
    "    ax.text(x, y, text, ha=\"center\", va=\"center\", family='sans-serif', size=14, rotation=90)\n",
    "\n",
    "fig, (empty, ax) = plt.subplots(2,1,figsize=(6,8))\n",
    "fig.tight_layout(pad=3)\n",
    "empty.axis('off')\n",
    "#ax = fig.gca()\n",
    "fig.suptitle('Explanatory figure')\n",
    "ax.set_xlabel('Camera frame')\n",
    "ax.set_ylabel('z-scored activity')\n",
    "ax.set_ylim(vstart,vstart+1)\n",
    "ax.plot(z_spike.mean(axis=0)+0.00, label=\"(CategoryA, True): #trials\", c=(1,1,0))\n",
    "ax.plot(z_spike.mean(axis=0)+0.02, label=\"(CategoryB, True): #trials\", c=(.5,1,.5))\n",
    "ax.plot(-z_spike.mean(axis=0)+0.00, label=\"(CategoryA, False): #trials\", c=(1,.8,1))\n",
    "ax.plot(-z_spike.mean(axis=0)+0.02, label=\"(CategoryB, False): #trials\", c=(.5,1,1))\n",
    "patches = []\n",
    "# mark delay\n",
    "label90(center[0], vcenter, 'excitation by\\nshowing water')\n",
    "# mark CS\n",
    "rect = mpatches.Rectangle((left[1],vstart), width[1], 1, ec=\"none\")\n",
    "patches.append(rect)\n",
    "label90(center[1], vcenter, 'CSÂ± if tone\\n\"Baseline\" otherwise')\n",
    "# mark delay\n",
    "label90(center[2], vcenter, 'delay')\n",
    "# mark UC\n",
    "rect = mpatches.Rectangle((left[3],vstart), width[3], 1, ec=\"none\")\n",
    "patches.append(rect)\n",
    "label90(center[3], vcenter, 'UC if any')\n",
    "# mark water\n",
    "#arrow = mpatches.FancyArrowPatch((left[1], 0.1), (left[3], 0.1),\n",
    "#          arrowstyle=mpatches.ArrowStyle(\"simple\", head_length=2*FPS, head_width=0.2, tail_width=0.1))\n",
    "#patches.append(arrow)\n",
    "ax.text((left[0]+left[3])/2, vstart, \"water source present\\niff allowed to lick\",\n",
    "        ha=\"center\", va=\"bottom\", family='sans-serif', size=14, bbox=dict(boxstyle=\"DArrow\", pad=0.0, fc='c'))\n",
    "\n",
    "for i in range(0,len(events)):\n",
    "    ax.axvline(x=events[i]*FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "colors = np.linspace(0, 1, len(patches))\n",
    "collection = PatchCollection(patches, cmap=plt.cm.hsv, alpha=0.1)\n",
    "collection.set_array(np.array(colors))\n",
    "ax.add_collection(collection)\n",
    "\n",
    "leg = ax.legend(loc='lower center', title=\"Category name, Condition name\",\n",
    "               bbox_to_anchor=(0.5, 1.1))\n",
    "leg.get_title().set_fontsize('large')\n",
    "leg.get_title().set_fontweight('bold')\n",
    "fig.show()\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_pop.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data(df_spike, df_data, df_lick)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-scored spiking\n",
    "Spiking is \"True\" in the [intervals) given in transients_data.hc5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single criterion\n",
    "* interestingly population activity is high both for puffed and licking during the UC session, to be checked in the cross-correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data(z_spike, z_data, z_lick, [['context'],['learning_epoch'],['licking'],['puffed']], title='Population activity')\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two criteria\n",
    "* selecting (licking and puffed) makes clear that only the airpuffing correlates with UC (they are the same) and not licking\n",
    "* selecting (epoch and puffed) shows that activity during UC decreases in the post-learning period\n",
    "* selecting (context and puffed) shows that CS+ alone does not involve higher population activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_data(z_spike, z_data, z_lick, [['context','learning_epoch'],['context','licking'],['context','puffed'],['learning_epoch','puffed'],['learning_epoch','licking'],['licking','puffed']], title='Population activity')\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities conditional on epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_c = experiment_traits[experiment_traits.loc[:,'learning_epoch']=='Pre-Learning']\n",
    "print (experiment_c.shape)\n",
    "spike_c = z_spike.reindex(experiment_c.index, level='time')\n",
    "data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "raw_c = z_raw.reindex(experiment_c.index, level='time')\n",
    "lick_c = z_lick.reindex(experiment_c.index)\n",
    "print (spike_c.shape)\n",
    "\n",
    "plot_data(spike_c, data_c, lick_c, [['context','licking'],['context','puffed'],['licking','puffed']], title='Pre-Learning')\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_c = experiment_traits[experiment_traits.loc[:,'learning_epoch']=='Learning']\n",
    "print (experiment_c.shape)\n",
    "spike_c = z_spike.reindex(experiment_c.index, level='time')\n",
    "data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "raw_c = z_raw.reindex(experiment_c.index, level='time')\n",
    "lick_c = z_lick.reindex(experiment_c.index)\n",
    "print (spike_c.shape)\n",
    "\n",
    "plot_data(spike_c, data_c, lick_c, [['context','licking'],['context','puffed'],['licking','puffed']], title='Learning')\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_c = experiment_traits[experiment_traits.loc[:,'learning_epoch']=='Post-Learning']\n",
    "print (experiment_c.shape)\n",
    "spike_c = z_spike.reindex(experiment_c.index, level='time')\n",
    "data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "raw_c = z_raw.reindex(experiment_c.index, level='time')\n",
    "lick_c = z_lick.reindex(experiment_c.index)\n",
    "print (spike_c.shape)\n",
    "\n",
    "plot_data(spike_c, data_c, lick_c, [['context','licking'],['context','puffed'],['licking','puffed']], title='Post-Learning')\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual ROIs\n",
    "* since there are many of them, save figure to pdf\n",
    "* THIS WILL <font color=\"red\">TAKE A WHILE</font>, consider testing with a small range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roi(df_spike, df_data, grps = [[]], title='', div=None):\n",
    "    ncol = len(grps)\n",
    "    fig, ax = plt.subplots(2, ncol, figsize=(6*ncol,9), sharex=True, squeeze=False, dpi=72)\n",
    "    fig.tight_layout(pad=3, h_pad=3, rect=(0,0,1,0.80))\n",
    "    if len(title):\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "    for i in range(0, ncol):\n",
    "        plot_activity(df_data,grps[i],\"Ca-level\",ax=ax[0,i],div=div)\n",
    "        leg = ax[0,i].legend(loc='lower center', bbox_to_anchor=(0.5, 1.1), title=', '.join(grps[i]))\n",
    "        leg.get_title().set_fontsize('large')\n",
    "        leg.get_title().set_fontweight('bold')\n",
    "        plot_activity(df_spike,grps[i],\"Spiking\",ax=ax[1,i],div=div)\n",
    "        ax[1,i].legend_.remove()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', UserWarning)\n",
    "        #fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raise ValueError(\"You don't want to run this automaticly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = PdfPages(animal+'_roi1crit.pdf')\n",
    "for i in range(0,len(rois)):\n",
    "    spike_c = z_spike.loc[(slice(None),rois[i]),:]\n",
    "    data_c = z_data.loc[(slice(None),rois[i]),:]\n",
    "    raw_c = z_raw.loc[(slice(None),rois[i]),:]\n",
    "    fig = plot_roi(spike_c, data_c, [['context'],['learning_epoch'],['licking'],['puffed']], title='ROI %d:\\n%s'%(i,rois[i]))\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = PdfPages(animal+'_roi2crit.pdf')\n",
    "for i in range(0,len(rois)):\n",
    "    spike_c = z_spike.loc[(slice(None),rois[i]),:]\n",
    "    data_c = z_data.loc[(slice(None),rois[i]),:]\n",
    "    raw_c = z_raw.loc[(slice(None),rois[i]),:]\n",
    "    fig = plot_roi(spike_c, data_c, [['learning_epoch','context'],['learning_epoch','licking'],['learning_epoch','puffed'],['context','licking'],['context','puffed'],['licking','puffed']], title='ROI %d:\\n%s'%(i,rois[i]))\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging over intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func_over_intervals(func, intervals, data, axis=0):\n",
    "    shape = np.array(data.shape)\n",
    "    n_ivs = len(intervals)-1\n",
    "    shape[axis] = n_ivs\n",
    "    ret = np.zeros(shape)\n",
    "    for i in range(0,n_ivs):\n",
    "        ret[i] = func(data[intervals[i]:intervals[i+1]])\n",
    "    return tuple(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intervals aligned to events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sections = np.append(events,[60])*FPS\n",
    "centers = (sections[1:]+sections[:-1])/2\n",
    "def myfun(x):\n",
    "    return func_over_intervals(np.nanmean, sections, np.array(x))\n",
    "\n",
    "a_spike = df_spike.apply(myfun, axis=1, raw=True)\n",
    "a_spike = pd.DataFrame(a_spike.tolist(), columns=centers.astype(str), index=a_spike.index)\n",
    "a_data = df_data.apply(myfun, axis=1, raw=True)\n",
    "a_data = pd.DataFrame(a_data.tolist(), columns=centers.astype(str), index=a_data.index)\n",
    "a_raw = raw_data.apply(myfun, axis=1, raw=True)\n",
    "a_raw = pd.DataFrame(a_raw.tolist(), columns=centers.astype(str), index=a_raw.index)\n",
    "a_lick = df_lick.apply(myfun, axis=1, raw=True)\n",
    "a_lick = pd.DataFrame(a_lick.tolist(), columns=centers.astype(str), index=a_lick.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_data = a_data.sort_index()\n",
    "a_raw = a_raw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = PdfPages(animal+'_avg1crit.pdf')\n",
    "for i in range(0,len(rois)):\n",
    "    spike_c = a_spike.loc[(slice(None),rois[i]),:]\n",
    "    data_c = a_data.loc[(slice(None),rois[i]),:]\n",
    "    raw_c = a_raw.loc[(slice(None),rois[i]),:]\n",
    "    fig = plot_roi(spike_c, data_c, [['context'],['learning_epoch'],['licking'],['puffed']],\n",
    "                   title='ROI %d:\\n%s'%(i,rois[i]), div=centers)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = PdfPages(animal+'_avg2crit.pdf')\n",
    "for i in range(0,len(rois)):\n",
    "    spike_c = a_spike.loc[(slice(None),rois[i]),:]\n",
    "    data_c = a_data.loc[(slice(None),rois[i]),:]\n",
    "    raw_c = a_raw.loc[(slice(None),rois[i]),:]\n",
    "    fig = plot_roi(spike_c, data_c, [['learning_epoch','context'],['learning_epoch','licking'],['learning_epoch','puffed'],['context','licking'],['context','puffed'],['licking','puffed']], title='ROI %d:\\n%s'%(i,rois[i]))\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging over bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sections = np.arange(0,60,5)*FPS\n",
    "centers = (sections[1:]+sections[:-1])/2\n",
    "def myfun(x):\n",
    "    return func_over_intervals(np.nanmean, sections, np.array(x))\n",
    "\n",
    "b_spike = df_spike.apply(myfun, axis=1, raw=True)\n",
    "b_spike = pd.DataFrame(b_spike.tolist(), columns=centers.astype(str), index=b_spike.index)\n",
    "b_data = df_data.apply(myfun, axis=1, raw=True)\n",
    "b_data = pd.DataFrame(b_data.tolist(), columns=centers.astype(str), index=b_data.index)\n",
    "b_raw = raw_data.apply(myfun, axis=1, raw=True)\n",
    "b_raw = pd.DataFrame(b_raw.tolist(), columns=centers.astype(str), index=b_raw.index)\n",
    "b_lick = df_lick.apply(myfun, axis=1, raw=True)\n",
    "b_lick = pd.DataFrame(b_lick.tolist(), columns=centers.astype(str), index=b_lick.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_data = b_data.sort_index()\n",
    "b_raw = b_raw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = PdfPages(animal+'_bin1crit.pdf')\n",
    "for i in range(0,len(rois)):\n",
    "    spike_c = b_spike.loc[(slice(None),rois[i]),:]\n",
    "    data_c = b_data.loc[(slice(None),rois[i]),:]\n",
    "    raw_c = b_raw.loc[(slice(None),rois[i]),:]\n",
    "    fig = plot_roi(spike_c, data_c, [['context'],['learning_epoch'],['licking'],['puffed']],\n",
    "                   title='ROI %d:\\n%s'%(i,rois[i]), div=centers)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = PdfPages(animal+'_bin2crit.pdf')\n",
    "for i in range(0,len(rois)):\n",
    "    spike_c = b_spike.loc[(slice(None),rois[i]),:]\n",
    "    data_c = b_data.loc[(slice(None),rois[i]),:]\n",
    "    raw_c = b_raw.loc[(slice(None),rois[i]),:]\n",
    "    fig = plot_roi(spike_c, data_c, [['learning_epoch','context'],['learning_epoch','licking'],['learning_epoch','puffed'],['context','licking'],['context','puffed'],['licking','puffed']], title='ROI %d:\\n%s'%(i,rois[i]))\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine information\n",
    "ord1 = z_spike.join(experiment_traits, how='inner').drop('time', axis=1).reset_index().drop('time', axis=1).set_index(['roi_id','learning_epoch','context','licking','puffed','session_num']).sort_index()\n",
    "ord1.columns.name='Spike'\n",
    "print(ord1.shape)\n",
    "display(ord1.head())\n",
    "\n",
    "# Search for days that contain experiments with same traits and session_num\n",
    "# These entries would jeopardize unstacking\n",
    "et1 = experiment_traits.reset_index(drop=True).set_index(['learning_epoch','context','licking','puffed','session_num']).sort_index()\n",
    "second_occur = et1.index.duplicated()\n",
    "set1 = et1.loc[second_occur,'day_num'].unique()\n",
    "all_occur = et1.index.get_duplicates()\n",
    "set_all = et1.loc[all_occur,'day_num'].unique()\n",
    "set2 = np.array(list(set(set_all)-set(set1)))\n",
    "print(set1,set2)\n",
    "\n",
    "# Filter out set2\n",
    "ord1 = ord1[ord1.loc[:,'day_num'].apply(lambda x: x not in set2)]\n",
    "print(ord1.shape)\n",
    "\n",
    "# Reshape for correlation analysis\n",
    "comp = ord1['day_num'].astype(int).unstack().sort_index(axis=1)\n",
    "ord1 = ord1.drop(['day_num'], axis=1).unstack()\n",
    "display(comp.head())\n",
    "display(ord1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reorder\n",
    "ord2 = ord1.reset_index().set_index(['learning_epoch','context','licking','puffed','roi_id']).sort_index()\n",
    "print(ord2.shape)\n",
    "display(ord2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the pre-learning structure\n",
    "key_ref = ('Pre-Learning','CS+',True,False)\n",
    "sel = ord2.loc[key_ref+(slice(None),),:]\n",
    "print(sel.shape)\n",
    "\n",
    "# Correlate\n",
    "corr_df = sel.T.corr()\n",
    "corr_np = corr_df.fillna(0).values\n",
    "\n",
    "# Discard invalid series\n",
    "keep = (np.diag(corr_np) == 1.0)\n",
    "corr_np = corr_np[keep,:][:,keep]\n",
    "\n",
    "# Show\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].matshow(corr_df.values)\n",
    "ax[1].matshow(corr_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_correl.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define an ordering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "sq_dist = squareform(1.0-corr_np)\n",
    "corr_link = linkage(sq_dist, 'average')\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,6))\n",
    "fig.suptitle('Reference is presented here: '+(', '.join(np.array(key_ref))))\n",
    "dendo = dendrogram(corr_link, ax=ax[0], orientation='right')\n",
    "ax[0].set_title('Distance of firing patterns')\n",
    "corr_order = dendo['leaves']\n",
    "# Show reordered\n",
    "ax[1].matshow(corr_np[corr_order,:][:,corr_order], origin='lower')\n",
    "ax[1].set_title('Ordered correlation matrix')\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_plots = len(et.index)\n",
    "num_rows = int(np.ceil(num_plots/3.0))\n",
    "fig, ax = plt.subplots(num_rows,3, figsize=(18,6*num_rows))\n",
    "fig.suptitle('Correlation structure under different conditions: learning_epoch, context, licking, puffed')\n",
    "ax = np.ravel(ax)\n",
    "    \n",
    "for idx in range(0,num_plots):\n",
    "    # Find the pre-learning structure\n",
    "    key = et.index[idx]+(slice(None),)\n",
    "    sel = ord2.loc[key,:]\n",
    "    print(key,ord2.shape,sel.shape)\n",
    "    \n",
    "    # Correlata\n",
    "    corr_tmp = sel.T.corr()\n",
    "    corr_tmp = corr_tmp.fillna(0).values\n",
    "\n",
    "    # Discard invalid series\n",
    "    if len(corr_tmp):\n",
    "        ax[idx].matshow(corr_tmp[keep,:][:,keep][corr_order,:][:,corr_order])\n",
    "    ax[idx].set_title(et.index[idx])\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of spiking\n",
    "The first 1 second of the recording seems missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot all neural units in this experiment\n",
    "experiment_id = experiment_traits.ix[0,'time']\n",
    "ixt = transients_data.loc[experiment_id].index.unique()\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(0,len(ixt)):\n",
    "    unit = ixt[i]\n",
    "    firing = np.array(transients_data.loc[(experiment_id,unit),['start_frame', 'stop_frame']])\n",
    "    plt.plot(firing.T,i*np.ones_like(firing.T),c='k')\n",
    "    firing = transients_data.loc[(experiment_id,unit),'max_frame']\n",
    "    plt.plot(firing,i*np.ones_like(firing),'|',ms=5)\n",
    "for i in range(0,len(events)):\n",
    "    plt.axvline(x=events[i]*FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "plt.title('Transient peaks and durations')\n",
    "plt.xlabel('Camera frame')\n",
    "plt.ylabel('Unit ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some undocumented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint, pickle\n",
    "\n",
    "# Some undocumented info about the experiments\n",
    "pkl_file = open('../_share/Losonczi/msa0316_1/frame_fluor.pkl', 'rb')\n",
    "\n",
    "# Python 2.7\n",
    "data1 = pickle.load(pkl_file)\n",
    "\n",
    "# Python 3.5\n",
    "#u = pickle._Unpickler(pkl_file)\n",
    "#u.encoding = 'latin1'\n",
    "#data1 = u.load()\n",
    "    \n",
    "#pprint.pprint(data1)\n",
    "\n",
    "pprint.pprint(data1.keys())\n",
    "pprint.pprint(data1.values()[0]) # same as data1['2016-04-01-23h43m20s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
