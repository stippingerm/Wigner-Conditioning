{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reqirements\n",
    "* #### You need to install module future, manual importing from \\_\\_future\\_\\_ is at your convenience\n",
    "* #### For hdf data import you need pytables too which is not default installed with Anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from future.utils import PY3\n",
    "import future\n",
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "#from IPython.display import display\n",
    "import IPython.display as disp\n",
    "display = disp.display\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "zscore, describe = stats.mstats.zscore, stats.describe\n",
    "import warnings\n",
    "import datetime\n",
    "dt, td = datetime.datetime, datetime.timedelta\n",
    "import imp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ca_lib as la\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basedir = '../_share/Losonczi/'\n",
    "\n",
    "# Display database folders\n",
    "display(os.listdir(basedir))\n",
    "\n",
    "# Select animal\n",
    "#animal = 'msa1215_1'; FPS = 30\n",
    "#animal = 'msa0216_4'; FPS = 8\n",
    "#animal = 'msa0316_1'; FPS = 8\n",
    "#animal = 'msa0316_3'; FPS = 8\n",
    "animal = 'msa0316ag_1'; FPS = 8\n",
    "\n",
    "# List dir\n",
    "mydir = os.path.join(basedir,animal)\n",
    "os.listdir(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Available trials and ROIs\n",
    "data = la.load_files(mydir)\n",
    "print (data.raw.shape, '\\n', data.trials, '\\n', data.rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Post-Learning may repeat session_num therefore an additional index,\n",
    "# day_num is created. See msa0316_1.\n",
    "# It seems though that Pre-Learning and Learning treats session_num as documented.\n",
    "display(data.experiment_traits.head())\n",
    "display(data.experiment_traits[data.experiment_traits['day_leap']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment protocol configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et = data.experiment_traits.copy()\n",
    "et = la.df_epoch(et.groupby(la.display_learning).size().to_frame(name='count'))\n",
    "#et.to_clipboard()\n",
    "disp.display(disp.HTML('<font color=\"red\">ATTENTION, </font>for later conformity we store columns in a <b>different order</b>: %s !!!'%la.sort_learning))\n",
    "display(la.df_epoch(et))\n",
    "\n",
    "et = data.experiment_traits.copy()\n",
    "etc= et.groupby(la.sort_learning[1:]).size().to_frame(name='count')\n",
    "et = la.df_epoch(et.groupby(la.sort_learning).size().to_frame(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data = data.filtered\n",
    "df_raw = data.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See how many ROIs are available for which frames\n",
    "\n",
    "avail_sum = (~data.filtered.isnull()).sum() / len(data.trials)\n",
    "plt.plot(avail_sum)\n",
    "plt.xlabel('Camera frame within experiment')\n",
    "plt.ylabel('Available ROIs on average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See which ROI is available in which trial and for how many frames\n",
    "\n",
    "avail = ((~data.filtered.isnull()).sum(axis=1)).to_frame('nFrames').unstack()\n",
    "\n",
    "print(avail.shape)\n",
    "display(avail.head())\n",
    "display(avail.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create boolean DataFrame which ROI is spiking in which camera frame\n",
    "\n",
    "# create empty structure for cumsum\n",
    "df_template = pd.DataFrame(data=0,index=data.mirow,columns=data.icol)\n",
    "df_spike = df_template.copy()\n",
    "\n",
    "# select spike data\n",
    "spikes = data.transients.loc[data.transients['in_motion_period']==False,['start_frame','stop_frame']]\n",
    "spikes['count']=1\n",
    "\n",
    "# fill in spike start and stop points (rename column to keep columns.name in df_spike)\n",
    "sp = spikes[['start_frame','count']].rename(columns={'start_frame':'frame'}).pivot(columns='frame').fillna(0)\n",
    "df_spike = df_spike.add(sp['count'], fill_value=0)\n",
    "sp = spikes[['stop_frame','count']].rename(columns={'stop_frame':'frame'}).pivot(columns='frame').fillna(0)\n",
    "df_spike = df_spike.add(-sp['count'], fill_value=0)\n",
    "\n",
    "# cumulate, conversion to int is not adviced if using NaNs\n",
    "df_spike = df_spike.cumsum(axis=1).astype(int)\n",
    "df_spike = df_spike + data.time_roi_mask\n",
    "\n",
    "print('table shape', df_spike.shape, 'active frames*ROIs', df_spike.sum().sum())\n",
    "display(df_spike.head(25))\n",
    "display(df_spike.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create boolean DataFrame whether licking happens in camera frame\n",
    "\n",
    "# Check for valid data and calculate their frame\n",
    "print('All entries', data.behavior.shape)\n",
    "df_lick = data.behavior[data.behavior.loc[:,'stop_time']>data.behavior.loc[:,'start_time']].copy()\n",
    "print('Valid licks', df_lick.shape)\n",
    "df_lick['frame'] = (FPS*(df_lick['start_time']+df_lick['stop_time'])/2).apply(np.round).astype(int)\n",
    "display(df_lick.head())\n",
    "display(df_lick.tail())\n",
    "# Convert to a DataFrame like df_data or df_raw\n",
    "df_lick = df_lick[['lick_idx','frame']].reset_index()\n",
    "df_lick = df_lick.groupby(['time','frame']).count().unstack(fill_value=0)\n",
    "display(df_lick.head())\n",
    "df_lick = df_lick['lick_idx'].reindex(index=data.mirow.levels[0],columns=data.icol,fill_value=0)\n",
    "display(df_lick.head())\n",
    "# Number of remaining licks\n",
    "print('Remaining licks',df_lick.sum().sum())\n",
    "# Smoothen\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "df_lick = df_lick.apply(lambda x: gaussian_filter(x.astype(float)*data.FPS, sigma=0.25*data.FPS), axis=1, raw=True)\n",
    "display(df_lick.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_spike = la.pd_zscore_by_roi(df_spike, FPS, -2*FPS, axis=1)\n",
    "z_data = la.pd_zscore_by_roi(df_data, FPS, -2*FPS, axis=1)\n",
    "z_raw = la.pd_zscore_by_roi(df_raw, FPS, -2*FPS, axis=1)\n",
    "z_lick = la.pd_zscore_clip(df_lick, FPS, -2*FPS, axis=1)\n",
    "\n",
    "z_data = z_data.sort_index()\n",
    "z_raw = z_raw.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigger(data, threshold, rising=True, hold_off=None):\n",
    "    data = np.array(data)\n",
    "    if hold_off:\n",
    "        raise ValueError('Hold off period not implemented yet.')\n",
    "    if rising:\n",
    "        trig = (data[1:]>threshold) & (data[:-1]<=threshold)\n",
    "    else:\n",
    "        trig = (data[1:]<threshold) & (data[:-1]>=threshold)\n",
    "    trig = np.append([False],trig)\n",
    "    return trig\n",
    "\n",
    "def trigger_horizonal_pd(df, threshold, axis=1, hold_off=None):\n",
    "    triggers_rise = df.apply(lambda x: trigger(x,threshold, True), axis=axis)\n",
    "    triggers_rise[triggers_rise==0]=np.nan\n",
    "    triggers_fall = df.apply(lambda x: trigger(x,threshold, False), axis=axis)\n",
    "    triggers_fall[triggers_fall==0]=np.nan\n",
    "    \n",
    "    if axis==1:\n",
    "        triggers_rise = triggers_rise.stack()\n",
    "        triggers_fall = triggers_fall.stack()\n",
    "    elif axis==0:\n",
    "        triggers_rise = triggers_rise.T.stack().T\n",
    "        triggers_fall = triggers_fall.T.stack().T\n",
    "    else:\n",
    "        warnings.warn('Axis reduction not implemented for axis.')\n",
    "    triggers_rise.name='weight'\n",
    "    triggers_fall.name='weight'\n",
    "    return triggers_rise, triggers_fall\n",
    "\n",
    "def trigger_event_pd(df, start, stop):\n",
    "    mi = pd.MultiIndex.from_product((df.index.values, [start]), names=['time', 'frame'])\n",
    "    triggers_start = pd.Series(1.0, index=mi, name='weight')\n",
    "    mi = pd.MultiIndex.from_product((df.index.values, [stop]), names=['time', 'frame'])\n",
    "    triggers_stop = pd.Series(1.0, index=mi, name='weight')\n",
    "    mi = pd.MultiIndex.from_product((df.index.values, list(range(start,stop))), names=['time', 'frame'])\n",
    "    triggers_allow = pd.Series(1.0, index=mi, name='weight')\n",
    "\n",
    "    return triggers_start, triggers_stop, triggers_allow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_spike_threshold = 5.0/np.sqrt(len(data.rois))\n",
    "\n",
    "max_lik_rate = 20\n",
    "c,b = np.histogram(df_lick.values.ravel(),range=(0,max_lik_rate),bins=max_lik_rate)\n",
    "lick_threshold = (np.argmax(c[1:])+1.5)/2\n",
    "plt.hist(df_lick.values.ravel(),log=True,range=(0,max_lik_rate),bins=max_lik_rate)\n",
    "plt.plot(lick_threshold,2,'y*',ms=15)\n",
    "print(lick_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The histogram shape justifies putting the threshold at the half maximum\n",
    "lick_triggers_rise, lick_triggers_fall = trigger_horizonal_pd(df_lick, lick_threshold)\n",
    "print (lick_triggers_rise.shape,lick_triggers_fall.shape)\n",
    "print ('Port was present in %d trials.'%data.experiment_traits[data.experiment_traits['port']=='W+'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the boundaryof a p<0.005 set \n",
    "spike_triggers_rise, spike_triggers_fall = trigger_horizonal_pd(z_spike.mean(level=0), z_spike_threshold)\n",
    "print (spike_triggers_rise.shape,spike_triggers_fall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csp_triggers_rise, csp_triggers_fall, csp_triggers_allow = trigger_event_pd(\n",
    "    data.experiment_traits[data.experiment_traits['port']=='W+'],\n",
    "    la.events[1]*data.FPS, la.events[2]*data.FPS)\n",
    "csm_triggers_rise, csm_triggers_fall, csm_triggers_allow = trigger_event_pd(\n",
    "    data.experiment_traits[data.experiment_traits['port']=='W-'],\n",
    "    la.events[1]*data.FPS, la.events[2]*data.FPS)\n",
    "\n",
    "us_triggers_rise, us_triggers_fall, us_triggers_allow = trigger_event_pd(\n",
    "    data.experiment_traits[data.experiment_traits['puffed']=='A+'],\n",
    "    la.events[3]*data.FPS, la.events[4]*data.FPS)\n",
    "\n",
    "tra_triggers_rise, tra_triggers_fall, tra_triggers_allow = trigger_event_pd(\n",
    "    data.experiment_traits[data.experiment_traits['context']=='CS+'],\n",
    "    la.events[2]*data.FPS, la.events[3]*data.FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "class helpmultipage(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.isopen = False\n",
    "        self.open()\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "        \n",
    "    def savefig(self, dpi=None):\n",
    "        if self.isopen:\n",
    "            self.pp.savefig(dpi=dpi)\n",
    "\n",
    "    def open(self):\n",
    "        if (~self.isopen) and len(self.filename):\n",
    "            self.pp = PdfPages(self.filename)\n",
    "            self.isopen = True\n",
    "        \n",
    "    def close(self):\n",
    "        if self.isopen:\n",
    "            self.pp.close()\n",
    "        self.isopen = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanatory figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage('explanatory.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import PatchCollection\n",
    "center = FPS * (la.events[:-1]+la.events[1:]) /2\n",
    "left = FPS * la.events\n",
    "width = FPS * (la.events[1:]-la.events[:-1])\n",
    "vcenter = 0.0\n",
    "vstart = -0.5\n",
    "\n",
    "def label90(x,y,text):\n",
    "    ax.text(x, y, text, ha=\"center\", va=\"center\", family='sans-serif', size=14, rotation=90)\n",
    "\n",
    "fig, (empty, ax) = plt.subplots(2,1,figsize=(6,8))\n",
    "fig.tight_layout(pad=3)\n",
    "empty.axis('off')\n",
    "#ax = fig.gca()\n",
    "fig.suptitle('Explanatory figure')\n",
    "ax.set_xlabel('Camera frame')\n",
    "ax.set_ylabel('z-scored activity')\n",
    "ax.set_ylim(vstart,vstart+1)\n",
    "ax.plot(z_spike.mean(axis=0)+0.00, label=\"(CategoryA, True): #trials\", c=(1,1,0))\n",
    "ax.plot(z_spike.mean(axis=0)+0.02, label=\"(CategoryB, True): #trials\", c=(.5,1,.5))\n",
    "ax.plot(-z_spike.mean(axis=0)+0.00, label=\"(CategoryA, False): #trials\", c=(1,.8,1))\n",
    "ax.plot(-z_spike.mean(axis=0)+0.02, label=\"(CategoryB, False): #trials\", c=(.5,1,1))\n",
    "patches = []\n",
    "# mark delay\n",
    "label90(center[0], vcenter, 'excitation by\\nshowing water')\n",
    "# mark CS\n",
    "rect = mpatches.Rectangle((left[1],vstart), width[1], 1, ec=\"none\")\n",
    "patches.append(rect)\n",
    "label90(center[1], vcenter, 'CS± if tone\\n\"Baseline\" otherwise')\n",
    "# mark delay\n",
    "label90(center[2], vcenter, 'delay')\n",
    "# mark UC\n",
    "rect = mpatches.Rectangle((left[3],vstart), width[3], 1, ec=\"none\")\n",
    "patches.append(rect)\n",
    "label90(center[3], vcenter, 'UC if any')\n",
    "# mark water\n",
    "ax.text((left[0]+left[3])/2, vstart, \"water source present\\niff allowed to lick\",\n",
    "        ha=\"center\", va=\"bottom\", family='sans-serif', size=14, bbox=dict(boxstyle=\"DArrow\", pad=0.0, fc='c'))\n",
    "\n",
    "for i in range(0,len(la.events)):\n",
    "    ax.axvline(x=la.events[i]*FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "colors = np.linspace(0, 1, len(patches))\n",
    "collection = PatchCollection(patches, cmap=plt.cm.hsv, alpha=0.1)\n",
    "collection.set_array(np.array(colors))\n",
    "ax.add_collection(collection)\n",
    "\n",
    "leg = ax.legend(loc='lower center', title=\"Category name, Condition name\",\n",
    "               bbox_to_anchor=(0.5, 1.1))\n",
    "leg.get_title().set_fontsize('large')\n",
    "leg.get_title().set_fontweight('bold')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', UserWarning)\n",
    "    fig.show()\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_pop.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "la.plot_data(df_spike, df_data, df_lick, data.experiment_traits, FPS)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-scored spiking\n",
    "Spiking is \"True\" in the [intervals) given in transients_data.hc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bsections = np.arange(0,60,5)*FPS\n",
    "bcenters = (bsections[1:]+bsections[:-1])/2\n",
    "#mybfun = lambda x: la.func_over_intervals(np.nanmean, bsections, np.array(x))\n",
    "mybfun = pd.DataFrame.mean\n",
    "\n",
    "zb_spike = la.pd_aggr_col(z_spike, mybfun, bsections, bcenters.astype(str))\n",
    "zb_data = la.pd_aggr_col(z_data, mybfun, bsections, bcenters.astype(str))\n",
    "zb_raw = la.pd_aggr_col(z_raw, mybfun, bsections, bcenters.astype(str))\n",
    "zb_lick = la.pd_aggr_col(z_lick, mybfun, bsections, bcenters.astype(str))\n",
    "b_lick = la.pd_aggr_col(df_lick, mybfun, bsections, bcenters.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "asections = np.append(la.events,[60])*FPS\n",
    "acenters = (asections[1:]+asections[:-1])/2\n",
    "#myafun = lambda x: la.func_over_intervals(np.nanmean, asections, np.array(x))\n",
    "myafun = pd.DataFrame.mean\n",
    "\n",
    "za_spike = la.pd_aggr_col(z_spike, myafun, asections, acenters.astype(str))\n",
    "za_data = la.pd_aggr_col(z_data, myafun, asections, acenters.astype(str))\n",
    "za_raw = la.pd_aggr_col(z_raw, myafun, asections, acenters.astype(str))\n",
    "za_lick = la.pd_aggr_col(z_lick, myafun, asections, acenters.astype(str))\n",
    "a_lick = la.pd_aggr_col(df_lick, myafun, asections, acenters.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single criterion\n",
    "* comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grp = [['context'],['learning_epoch'],['port'],['puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two criteria\n",
    "* comments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = [['context','learning_epoch'],['context','port'],['context','puffed'],['learning_epoch','puffed'],['learning_epoch','port'],['port','puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three criteria\n",
    "* comments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = [['context','learning_epoch','port'],['context','learning_epoch','puffed'],['context','port','puffed'],['learning_epoch','port','puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All criteria\n",
    "* There is no increased population activity for CS+ without puffing. (For mouse 0216_4 the 1 trial with port displays increase during the trace period - why?)\n",
    "* During learning mouse 0216_4 shows incresed activity during the UC phase for CS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = [['context','port','puffed']]\n",
    "la.plot_epochs(z_spike, z_data, df_lick, data.experiment_traits, etc, FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_epochs(zb_spike, zb_data, b_lick, data.experiment_traits, etc, FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_epochs(za_spike, za_data, a_lick, data.experiment_traits, etc, FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities conditional on epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_by_epoch(epoch):\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = z_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    raw_c = z_raw.reindex(experiment_c.index, level='time')\n",
    "    lick_c = df_lick.reindex(experiment_c.index)\n",
    "    print (experiment_c.shape, z_spike.shape)\n",
    "    spike_ca = la.pd_aggr_col(spike_c, myafun, asections, acenters.astype(str))\n",
    "    data_ca = la.pd_aggr_col(data_c, myafun, asections, acenters.astype(str))\n",
    "    raw_ca = la.pd_aggr_col(raw_c, myafun, asections, acenters.astype(str))\n",
    "    lick_ca = la.pd_aggr_col(lick_c, myafun, asections, acenters.astype(str))\n",
    "    print (spike_c.shape, spike_ca.shape)\n",
    "\n",
    "    grp = [['context','port'],['context','puffed'],['port','puffed']]\n",
    "    la.plot_data(spike_c, data_c, lick_c, data.experiment_traits, FPS, grp, title=epoch)\n",
    "    pp.savefig()\n",
    "    la.plot_data(spike_ca, data_ca, lick_ca, data.experiment_traits, FPS, grp, title=epoch+' averaged over events', div=acenters)\n",
    "    pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Pre-Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Post-Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_phases.pdf')\n",
    "\n",
    "etmp = data.experiment_traits.reset_index(drop=True).set_index(la.sort_learning)\n",
    "\n",
    "for p,aggr in enumerate(za_data.columns):\n",
    "    nplot = len(et.index)\n",
    "    ncol = 12\n",
    "    nrow = int(np.ceil(len(et.index)/float(ncol)))\n",
    "    fig, ax = plt.subplots(nrow,ncol,figsize=(2*ncol,1+10*nrow),squeeze=False,sharey=True)\n",
    "    fig.tight_layout(pad=3, h_pad=3, rect=[0,0,1,0.8])\n",
    "    fig.suptitle('Phase: %s'%la.phases[p],fontsize=16)\n",
    "    for i, cond in enumerate(et.index):\n",
    "        col = i%ncol\n",
    "        row = int((i-col)/ncol)\n",
    "        sel = etmp.loc[cond,'timestr']\n",
    "        tmp = za_data.loc[sel.tolist(),aggr].unstack('time')\n",
    "        ax[row,col].matshow(tmp.values,origin='lower')\n",
    "        ax[row,col].xaxis.set_ticks_position('bottom')\n",
    "        ax[row,col].set_title('\\n'.join(cond))\n",
    "        ax[row,col].set_ylabel('Unit ID')\n",
    "        ax[row,col].set_xlabel('Trial')\n",
    "    pp.savefig()    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of spiking\n",
    "The first 1 second of the recording seems missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_transients(ax, transients, experiment_id, rois=None):\n",
    "    '''Plot transients with colored line and put a tic at the maxima'''\n",
    "    import itertools, matplotlib\n",
    "    ncolors = 10\n",
    "    color=itertools.cycle(plt.cm.rainbow(np.linspace(0,1,ncolors)))\n",
    "    # Plot all neural units in this experiment\n",
    "    if rois is None:\n",
    "        rois = transients.loc[experiment_id].index.unique()\n",
    "    colors=np.array(list(itertools.islice(color,len(rois))))\n",
    "    try:\n",
    "        firing = transients.loc[experiment_id,['start_frame', 'stop_frame', 'max_frame']].join(roi_df.set_index(['roi_id']), how='left')\n",
    "        # Reshape things so that we have a sequence of:\n",
    "        # [[(x0,y0),(x1,y1)],[(x0,y0),(x1,y1)],...]\n",
    "        # based on http://stackoverflow.com/questions/17240694/python-how-to-plot-one-line-in-different-colors\n",
    "        segments = firing[['start_frame', 'idx', 'stop_frame', 'idx']].values.reshape(-1,2,2)\n",
    "        coll = matplotlib.collections.LineCollection(segments, cmap=plt.cm.rainbow)\n",
    "        coll.set_array(firing['idx']%ncolors)\n",
    "        if len(firing):\n",
    "            #ax.plot(firing[['start_frame', 'stop_frame']].T,firing[['idx', 'idx']].T,c=colors[firing['idx']])\n",
    "            ax.add_collection(coll)\n",
    "            ax.autoscale_view()\n",
    "        if len(firing):\n",
    "            ax.plot(firing['max_frame'].T,firing['idx'].T,'|',ms=5,c='k')\n",
    "            #xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "            #ax.scatter(firing['max_frame'].T,firing['idx'].T,s=5,c='k',marker='|')\n",
    "            #ax.set_xlim(xlim), ax.set_ylim(ylim)\n",
    "    except:\n",
    "        pass\n",
    "    for i in range(0,len(la.events)):\n",
    "        ax.axvline(x=la.events[i]*FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "    ax.set_title('Transient peaks and durations ExID: '+experiment_id)\n",
    "    ax.set_xlabel('Camera frame')\n",
    "    ax.set_ylabel('Unit ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_levels(ax, data, experiment_id, rois=None, zoom=0.5, dist=1.0):\n",
    "    '''Plot transients with colored line and put a tic at the maxima'''\n",
    "    import itertools, matplotlib\n",
    "    ncolors = 10\n",
    "    color=itertools.cycle(plt.cm.rainbow(np.linspace(0,1,ncolors)))\n",
    "    # Plot all neural units in this experiment\n",
    "    if rois is None:\n",
    "        rois = data.loc[experiment_id].index.unique()\n",
    "    colors=np.array(list(itertools.islice(color,len(rois))))\n",
    "    try:\n",
    "        firing = (zoom*data.loc[experiment_id,:]).add(dist*roi_df.set_index(['roi_id']).loc[:,'idx'],axis=0)\n",
    "        if len(firing):\n",
    "            ax.plot(firing.T)#,c=colors)\n",
    "    except:\n",
    "        pass\n",
    "    for i in range(0,len(la.events)):\n",
    "        ax.axvline(x=la.events[i]*FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "    ax.set_title('Transient peaks and durations ExID: '+experiment_id)\n",
    "    ax.set_xlabel('Camera frame')\n",
    "    ax.set_ylabel('Unit ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_spiking_nan(ax, spiking, experiment_id, rois=None):\n",
    "    '''Mark unavailable data with a gray dot'''\n",
    "    import itertools, matplotlib\n",
    "    ncolors = 10\n",
    "    color=itertools.cycle(plt.cm.rainbow(np.linspace(0,1,ncolors)))\n",
    "    # Plot all neural units in this experiment\n",
    "    if rois is None:\n",
    "        rois = transients.loc[experiment_id].index.unique()\n",
    "    try:\n",
    "        firing = spiking.loc[experiment_id,:].join(roi_df.set_index(['roi_id']), how='left')\n",
    "        firing.columns.name='frame'\n",
    "        firing = firing.set_index('idx').stack(dropna=False)\n",
    "        firing = firing[firing.isnull()]\n",
    "        firing = firing.reset_index()\n",
    "        if len(firing):\n",
    "            #ax.scatter(firing.loc[:,'frame'],firing.loc[:,'idx'],s=1,c='lightgray',marker='.')\n",
    "            ax.plot(firing.loc[:,'frame'],firing.loc[:,'idx'],'.',ms=1,c='lightgray')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_triggers(ax, triggers, experiment_id, pos=0, ls='x', c='b', ms=8):\n",
    "    '''Plot trigger events'''\n",
    "    try:\n",
    "        if type(triggers) is not list:\n",
    "            triggers=[triggers]\n",
    "        for i, trig in enumerate(triggers):\n",
    "            x = trig.loc[experiment_id].index.values\n",
    "            x = x.reshape((1,-1))\n",
    "            if x.shape[1]>0:\n",
    "                ls1 = ls[i] if type(ls) is list else ls\n",
    "                c1 = c[i] if type(c) is list else c\n",
    "                ms1 = ms[i] if type(ms) is list else ms\n",
    "                ax.plot(x, pos, ls1, c=c1, ms=ms1)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def plot_behavior(ax, licks, experiment_id):\n",
    "    '''Plot individual licks'''\n",
    "    try:\n",
    "        i=-5\n",
    "        licking = np.array(licks.loc[experiment_id,['start_time', 'stop_time']])*FPS\n",
    "        if len(licking):\n",
    "            ax.plot(licking.T,i*np.ones_like(licking.T),c='b')\n",
    "        licking = np.array(licks.loc[experiment_id,['start_time', 'stop_time']].mean(axis=1))*FPS\n",
    "        if len(licking):\n",
    "            ax.plot(licking,i*np.ones_like(licking),'o',ms=5,c='k')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def plot_licking(ax, licking, experiment_id, pos=-20, zoom=1.0, c='b', threshold=None):\n",
    "    '''Plot licking rate'''\n",
    "    try:\n",
    "        ax.axhline(y=pos, xmin=0.0, xmax = 1.0, linewidth=1, color='k')\n",
    "        if threshold is not None:\n",
    "            ax.axhline(y=threshold*zoom+pos,c='lightgray')\n",
    "        licking = licking.loc[experiment_id,:].values\n",
    "        if len(licking):\n",
    "            ax.plot(licking*zoom+pos,c=c)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def plot_population(ax, data, experiment_id, pos=-20, zoom=10.0, c='r', threshold=None):\n",
    "    '''Plot population activity'''\n",
    "    try:\n",
    "        ax.axhline(y=pos, xmin=0.0, xmax = 1.0, linewidth=1, color='k')\n",
    "        if threshold is not None:\n",
    "            ax.axhline(y=threshold*zoom+pos,c='lightgray')\n",
    "        data = data.loc[experiment_id,:].mean(axis=0)\n",
    "        if len(data):\n",
    "            ax.plot(data*zoom+pos,c=c)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_conditions(ax, conditions, experiment_id, height=20):\n",
    "    '''Draw a table and write experimental conditions into it'''\n",
    "    import matplotlib\n",
    "    a = conditions.loc[[experiment_id],['learning_epoch','context','port','puffed','session_num','day_num']]\n",
    "    cw = np.concatenate((la.durations[1:]*data.FPS,np.array([0.5,0.5])*(ax.get_xlim()[1]-la.events[-1]*data.FPS)))\n",
    "\n",
    "    c = a.copy()\n",
    "    c.loc[:,:]='lightblue' if any(a['port'].isin(['W+',True])) else 'white'\n",
    "    replacement = [('context', 'CS-', 'lightgreen'), ('context', 'CS+', 'lightcoral'),\n",
    "                   ('context', 'Baseline', 'lightblue'),\n",
    "                   ('port', 'W+', 'lightblue'), ('puffed', 'A+', 'yellow'),\n",
    "                   ('port', True, 'lightblue'), ('puffed', True, 'yellow')]\n",
    "    for label, value, color in replacement:\n",
    "        c.loc[a[label]==value,label]=color\n",
    "    \n",
    "    ylim = ax.get_ylim()\n",
    "    #tab = pd.tools.plotting.table(ax, a, loc='lower center', fontsize=24, colWidths=cw/np.sum(cw))\n",
    "    tab = matplotlib.table.table(ax, cellText=a.values,\n",
    "                                   #rowLabels=rowLabels, colLabels=colLabels,\n",
    "                           loc='lower center', fontsize=24, colWidths=cw/np.sum(cw), bbox=[0,0,1,height/(ylim[1]-ylim[0])], cellLoc='center', cellColours=c.values)\n",
    "    # fontsize keyword is accepted but seems ineffective\n",
    "    tab.set_fontsize(24)\n",
    "    for key, cell in tab.get_celld().items():\n",
    "        cell.set_linewidth(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Order experiments by settings (deprecated)\n",
    "et3 = data.experiment_traits.copy().reset_index(drop=True)\n",
    "#et3.loc[:,'session_num'] = et3.loc[:,'session_num'].astype(int)\n",
    "et3 = et3.sort_values(['learning_epoch','context','port','puffed','session_num']).set_index(['learning_epoch','context','port','puffed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enumerate ROIs\n",
    "roi_df = pd.DataFrame(data.rois, columns=['roi_id']).reset_index().rename(columns={'index':'idx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Triggers\n",
    "trig_list_data = [lick_triggers_rise, lick_triggers_fall, spike_triggers_rise, spike_triggers_fall]\n",
    "trig_list_sign = ['o', 's', '^', 'v']\n",
    "trig_list_color = ['b', 'y', 'r', 'g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show an example\n",
    "idx = data.experiment_traits.index[9]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "plot_levels(ax, z_data, idx, data.rois.values)\n",
    "ax.set_ylim(ymin=-60,ymax=120)\n",
    "#plot_spiking_nan(ax, df_spike, idx, data.rois.values)\n",
    "#plot_behavior(ax, data.behavior, idx)\n",
    "plot_population(ax, z_data, idx, pos=-20, c='y')\n",
    "plot_population(ax, z_spike, idx, pos=-20, threshold=z_spike_threshold)\n",
    "plot_licking(ax, df_lick, idx, pos=-40, threshold=lick_threshold)\n",
    "plot_triggers(ax, trig_list_data, idx, -5, trig_list_sign, c=trig_list_color)\n",
    "plot_conditions(ax, data.experiment_traits, idx, height=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show an example\n",
    "idx = data.experiment_traits.index[9]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "plot_transients(ax, data.transients, idx, data.rois.values)\n",
    "ax.set_ylim(ymin=-60,ymax=len(data.rois)+1)\n",
    "plot_spiking_nan(ax, df_spike, idx, data.rois.values)\n",
    "#plot_behavior(ax, data.behavior, idx)\n",
    "plot_population(ax, z_data, idx, pos=-20, c='y')\n",
    "plot_population(ax, z_spike, idx, pos=-20, threshold=z_spike_threshold)\n",
    "plot_licking(ax, df_lick, idx, pos=-40, threshold=lick_threshold)\n",
    "plot_triggers(ax, trig_list_data, idx, -5, trig_list_sign, c=trig_list_color)\n",
    "plot_conditions(ax, data.experiment_traits, idx, height=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_firing.pdf')\n",
    "\n",
    "xmax = data.transients.loc[:,['stop_frame']].max().values\n",
    "\n",
    "for idx, val in data.experiment_traits.iterrows(): #et3.iterrows():\n",
    "    fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "    ax.set_xlim(xmax=xmax)\n",
    "    experiment_id = val['timestr']\n",
    "    #print (experiment_id)\n",
    "    fig.suptitle('learning_epoch, context, port, puffed: #context in epoch, #day\\n'+\n",
    "        '%s: session %s, day %s'%(idx,val['session_num'],val['day_num']))\n",
    "    plot_transients(ax, data.transients, idx, data.rois.values)\n",
    "    ax.set_ylim(ymin=-60,ymax=len(data.rois)+1)\n",
    "    #plot_spiking_nan(ax, df_spike, idx, data.rois.values)\n",
    "    plot_population(ax, z_data, idx, pos=-20, c='y')\n",
    "    plot_population(ax, z_spike, idx, pos=-20, threshold=z_spike_threshold)\n",
    "    plot_licking(ax, df_lick, idx, pos=-40, threshold=lick_threshold)\n",
    "    plot_triggers(ax, trig_list_data, idx, -5, trig_list_sign, c=trig_list_color)\n",
    "    plot_conditions(ax, data.experiment_traits, experiment_id, height=20)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peri-event averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def peri_event_avg(data, triggers, diameter=(-3*FPS, 3*FPS), allow=None):\n",
    "    window = np.arange(diameter[0],diameter[1])\n",
    "    count=0\n",
    "    ret = []\n",
    "    for idx, weight in triggers.iteritems():\n",
    "        experiment_id, frame = idx\n",
    "        if (experiment_id in data.index) and ((allow is None) or (idx in allow)):\n",
    "            tmp = data.loc[experiment_id,:].reindex(columns=frame+window)\n",
    "            tmp.columns = pd.MultiIndex.from_product([count,window],names=['id','frame'])\n",
    "            ret.append(tmp)\n",
    "            count += 1\n",
    "    if len(ret):\n",
    "        ret = pd.concat(ret,axis=1)\n",
    "        return ret, count\n",
    "    else:\n",
    "        return None, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_decay(time_range, rate):\n",
    "    rate = float(rate)\n",
    "    if type(time_range) is int:\n",
    "        time_points = np.arange(0,time_range)-0.5*time_range\n",
    "    elif len(time_range)==2:\n",
    "        time_points = np.arange(time_range[0],time_range[-1])\n",
    "    else:\n",
    "        time_points = time_range\n",
    "    decay = np.exp(-rate*np.power(time_points,2))\n",
    "    return decay/np.sum(decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rev_align(data, shape):\n",
    "    '''Align for broadcast to shape matching axes from the beginning (opposed to numpy convention)'''\n",
    "    data_dim = data.ndim\n",
    "    req_dim = len(shape)\n",
    "    new_axes = np.arange(data_dim,req_dim)\n",
    "    # TODO: using np.reshape is more efficient\n",
    "    ret = data\n",
    "    for axis in new_axes:\n",
    "        ret = np.expand_dims(data, axis=axis)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rev_broadcast(data, shape):\n",
    "    '''Broadcast to shape matching axes from the beginning (opposed to numpy convention)'''\n",
    "    ret = np.broadcast_to(rev_align(data,shape), shape)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match_pattern(data, pattern, std, decay, noise_level=0.1, detailed=False):\n",
    "    '''Match pattern with decaying strength along time axis (rows). Use any number of columns.\n",
    "    Pattern and std may be one (time points given, all columns equal) or two dimensional (matrix given).\n",
    "    Noise_level can be 0 to 2 dimensional, if it is one dimensional then it is understood\n",
    "    on the category axis (all rows equal), noise_level must be positive if there is any std==0.'''\n",
    "    diff = data-rev_align(pattern, data.shape)\n",
    "    scale = rev_align(decay, data.shape)/(noise_level+rev_align(std, data.shape))\n",
    "    ret = np.nanmean(diff*scale, axis=(0 if detailed else None))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rolling2D(df, func, window, min_periods=None, center=True):\n",
    "    '''Slice a DataFrame along index (rows) to apply 2D function'''\n",
    "    # This was a missing feature in pandas: one could previously correlate a single pattern\n",
    "    # along a selected axis of a 2D DataFrame.\n",
    "    window = int(window)\n",
    "    if window<1:\n",
    "        raise ValueError('window needs positive length')\n",
    "    if min_periods is None:\n",
    "        min_periods = window\n",
    "    else:\n",
    "        min_periods = int(min_periods)\n",
    "    if min_periods<1:\n",
    "        raise ValueError('min_periods needs to be positive')\n",
    "    start = min_periods-window # first point of first window is start, available points evaluate to [0, min_periods)\n",
    "    end = len(df)-min_periods # first point of last window is end, available points evaluate to [len-min_periods, len)\n",
    "    if center:\n",
    "        shift = int(np.floor(window/2))\n",
    "    else:\n",
    "        shift = 0\n",
    "    first = start\n",
    "    data = df.iloc[first:first+window,:]\n",
    "    tmp = func(data)\n",
    "    try:\n",
    "        if len(tmp)==len(df.columns):\n",
    "            ret = pd.DataFrame([], index=df.index, columns=df.columns)\n",
    "        else:\n",
    "            ret = pd.DataFrame([], index=df.index, columns=pd.Index(np.arange(0,len(tmp))))\n",
    "    except:\n",
    "        ret = pd.DataFrame([], index=df.index, columns=pd.Index([0]))\n",
    "    ret.iloc[first+shift,:]=tmp\n",
    "    for first in range(start+1,end+1):\n",
    "        data = df.iloc[first:first+window,:]\n",
    "        tmp = func(data)\n",
    "        ret.iloc[first+shift,:]=tmp\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Reduce index:\n",
    "# df_spike.loc['2016-03-25-20h34m52s',:]\n",
    "# Keep index:\n",
    "df_spike.loc[('2016-03-25-20h34m52s',slice(None)),:]\n",
    "\n",
    "df_spike.loc[(slice(None),'0001-0011-0094'),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: it is interesting to compare performance\n",
    "1. ROIs are inspected one-by-one using 'apply' on all trials then the results aggregated\n",
    "2. ROIs are inspected one at a time using 'rolling2D' with scalar pattern then the results aggregated\n",
    "3. Trials are inspecetd one at a time using 'rolling2D' with matrix pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time, cProfile\n",
    "time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This seems to be extremly slow to to the massive maount of function calls\n",
    "def method1():\n",
    "    ret1 = []\n",
    "    diam = (-3*FPS,3*FPS)\n",
    "    window = diam[1]-diam[0]\n",
    "    decay = get_decay(window,3.0/FPS)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_rise, diameter=diam)\n",
    "    p1 = dd.mean(axis=1, level=1)\n",
    "    s1 = dd.std(axis=1, level=1)\n",
    "    t1 = time.clock()\n",
    "    df_spike1 = df_spike.reset_index().set_index(['roi_id','time']).sort_index() # not much faster than .loc[(slice(None),roi),:]\n",
    "    func = (lambda x: match_pattern(x,p1.loc[roi].values,s1.loc[roi].values,decay=decay))\n",
    "    for roi in data.rois: #[0:3]:\n",
    "        tmp = df_spike1.loc[roi,:].rolling(window,window,center=True,axis=1).apply(func)\n",
    "        ret1.append(tmp)\n",
    "    ret1 = pd.concat(ret1).astype(float)\n",
    "    ret1 = ret1.mean(axis=0, level=0)\n",
    "    t1 = time.clock()-t1\n",
    "    print(ret1.shape,t1)\n",
    "    return ret1\n",
    "cProfile.run('ret1 = method1()')\n",
    "plt.plot(ret1.T)\n",
    "ret1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To be seen why this one is slow\n",
    "def method2():\n",
    "    ret2 = []\n",
    "    diam = (-3*FPS,3*FPS)\n",
    "    window = diam[1]-diam[0]\n",
    "    decay = get_decay(window,3.0/FPS)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_rise, diameter=diam)\n",
    "    p1 = dd.mean(axis=1, level=1)\n",
    "    s1 = dd.std(axis=1, level=1)\n",
    "    t2 = time.clock()\n",
    "    df_spike2 = df_spike.reset_index().set_index(['roi_id','time']).sort_index() # not much faster than .loc[(slice(None),roi),:]\n",
    "    func = (lambda x: match_pattern_testing(x.values,p1.loc[roi].values,s1.loc[roi].values,detailed=True,decay=decay))\n",
    "    for roi in data.rois: #[0:3]:\n",
    "        tmp = rolling2D(df_spike2.loc[roi,:].T,func,window,center=True).T\n",
    "        ret2.append(tmp)\n",
    "    # Need to cast explicitly (seem not liking numpy's output and inferring 'object')\n",
    "    ret2 = pd.concat(ret2).astype(float)\n",
    "    ret2 = ret2.mean(axis=0, level=0)\n",
    "    t2 = time.clock()-t2\n",
    "    print(ret2.shape,t2)\n",
    "    return ret2\n",
    "cProfile.run('ret2 = method2()')\n",
    "plt.plot(ret2.T)\n",
    "ret2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How can this be so fast even with largest memory requirement?\n",
    "def method3():\n",
    "    ret3 = []\n",
    "    diam = (-3*FPS,3*FPS)\n",
    "    window = diam[1]-diam[0]\n",
    "    decay = get_decay(window,3.0/FPS)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_rise, diameter=diam)\n",
    "    p1 = dd.mean(axis=1, level=1)\n",
    "    s1 = dd.std(axis=1, level=1)\n",
    "    t3 = time.clock()\n",
    "    func = (lambda x: match_pattern_testing(x.values,p1.T.values,s1.T.values,decay=decay))\n",
    "    for trial in data.trials: #[0:3]:\n",
    "        tmp = rolling2D(df_spike.loc[trial,:].T,func,window,center=True).T\n",
    "        tmp.index=[trial]\n",
    "        ret3.append(tmp)\n",
    "    ret3 = pd.concat(ret3)\n",
    "    t3 = time.clock()-t3\n",
    "    print(ret3.shape,t3)\n",
    "    return ret3\n",
    "cProfile.run('ret3 = method3()')\n",
    "plt.plot(ret3.T)\n",
    "ret3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_peri_event(ax, df, title=None, pos=-15, zoom=10.0, vmin=None, vmax=None):\n",
    "    extent = np.min(df.columns.values)-0.5, np.max(df.columns.values)+0.5, -0.5, len(df)+0.5\n",
    "    ax.set_xlim(extent[0:2])\n",
    "    ax.set_ylim((pos-zoom,extent[3]))\n",
    "    ret = ax.matshow(df, origin='lower', aspect='auto', extent=extent, vmin=vmin, vmax=vmax)\n",
    "    ax.axhline(y=pos,xmin=0.0,xmax=1.0,c='gray')\n",
    "    ax.plot(zoom*df.mean(axis=0)+pos)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xlabel('$\\Delta$frame')\n",
    "    ax.set_ylabel('Unit ID')\n",
    "    ax.set_xlim(extent[0:2])\n",
    "    ax.set_ylim((pos-zoom,extent[3]))\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_peri_us(df_spike, title='Spiking'):\n",
    "    fig, ax = plt.subplots(1, 12, figsize=(24,12), sharey=True)\n",
    "    fig.tight_layout(rect=(0,0,1,0.9), w_pad=2)\n",
    "    fig.suptitle(title)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_rise)\n",
    "    if c:\n",
    "        plot_peri_event(ax[0], dd.mean(axis=1, level=1), 'Lick rise: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[1], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_fall)\n",
    "    if c:\n",
    "        plot_peri_event(ax[2], dd.mean(axis=1, level=1), 'Lick fall: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[3], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_rise, allow=us_triggers_allow)\n",
    "    if c:\n",
    "        plot_peri_event(ax[4], dd.mean(axis=1, level=1), 'Lick rise US: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[5], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_fall, allow=us_triggers_allow)\n",
    "    if c:\n",
    "        plot_peri_event(ax[6], dd.mean(axis=1, level=1), 'Lick fall US: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[7], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    dd, c = peri_event_avg(df_spike, us_triggers_rise)\n",
    "    if c:\n",
    "        plot_peri_event(ax[8], dd.mean(axis=1, level=1), 'US start: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[9], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    dd, c = peri_event_avg(df_spike, us_triggers_fall)\n",
    "    if c:\n",
    "        plot_peri_event(ax[10], dd.mean(axis=1, level=1), 'US end: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[11], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_peri_csp(df_spike, title='Spiking'):\n",
    "    fig, ax = plt.subplots(1, 12, figsize=(24,12), sharey=True)\n",
    "    fig.tight_layout(rect=(0,0,1,0.9), w_pad=2)\n",
    "    fig.suptitle(title)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_rise)\n",
    "    if c:\n",
    "        plot_peri_event(ax[0], dd.mean(axis=1, level=1), 'Lick rise: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[1], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_fall)\n",
    "    if c:\n",
    "        plot_peri_event(ax[2], dd.mean(axis=1, level=1), 'Lick fall: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[3], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_rise, allow=csp_triggers_allow)\n",
    "    if c:\n",
    "        plot_peri_event(ax[4], dd.mean(axis=1, level=1), 'Lick rise CS+: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[5], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    dd, c = peri_event_avg(df_spike, lick_triggers_fall, allow=csp_triggers_allow)\n",
    "    if c:\n",
    "        plot_peri_event(ax[6], dd.mean(axis=1, level=1), 'Lick fall CS+: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[7], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    dd, c = peri_event_avg(df_spike, csp_triggers_rise)\n",
    "    if c:\n",
    "        plot_peri_event(ax[8], dd.mean(axis=1, level=1), 'CS+ start: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[9], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    dd, c = peri_event_avg(df_spike, csp_triggers_fall)\n",
    "    if c:\n",
    "        plot_peri_event(ax[10], dd.mean(axis=1, level=1), 'CS+ end: %d'%c, vmin=-1, vmax=1)\n",
    "        plot_peri_event(ax[11], dd.std(axis=1, level=1), '(sigma)', vmin=0, vmax=2)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_peri.pdf')\n",
    "for epoch in la.epochs.values:\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    fig=plot_peri_us(spike_c,'%s Spiking on US'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    fig=plot_peri_csp(spike_c,'%s Spiking on CS+'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "for epoch in la.epochs.values:\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    fig=plot_peri_us(data_c,'%s Ca-level on US'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    fig=plot_peri_csp(data_c,'%s Ca-level on CS+'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig=plot_peri_us(df_spike,'Spiking')\n",
    "fig=plot_peri_us(z_data,'Ca-level')\n",
    "fig=plot_peri_csp(df_spike,'Spiking')\n",
    "fig=plot_peri_csp(z_data,'Ca-level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual ROIs\n",
    "* since there are many of them, save figure to pdf\n",
    "* THIS WILL <font color=\"red\">TAKE A WHILE</font>, consider testing with a small range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roi(df_spike, df_data, filaname, grp, title_template, by_epoch=False, div=None):\n",
    "    pp = PdfPages(filaname)\n",
    "    for i in range(0,len(data.rois)):\n",
    "        spike_c = df_spike.loc[(slice(None),data.rois[i]),:]\n",
    "        data_c = df_data.loc[(slice(None),data.rois[i]),:]\n",
    "        #raw_c = df_raw.loc[(slice(None),data.rois[i]),:]\n",
    "        if by_epoch:\n",
    "            fig = la.plot_epochs(spike_c, data_c, None, data.experiment_traits, etc, FPS, grp, title=title_template%(i,data.rois[i]), div=div)\n",
    "        else:\n",
    "            fig = la.plot_data(spike_c, data_c, None, data.experiment_traits, FPS, grp, title=title_template%(i,data.rois[i]), div=div)\n",
    "        pp.savefig()\n",
    "        plt.close(fig)\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raise ValueError(\"You don't want to run this automatically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ca_lib as la\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roi1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roi2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roiAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging over intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intervals aligned to events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_spike = la.pd_aggr_col(df_spike, myafun, asections, acenters.astype(str))\n",
    "a_data = la.pd_aggr_col(df_data, myafun, asections, acenters.astype(str))\n",
    "a_raw = la.pd_aggr_col(df_raw, myafun, asections, acenters.astype(str))\n",
    "a_lick = la.pd_aggr_col(df_lick, myafun, asections, acenters.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_data = a_data.sort_index()\n",
    "a_raw = a_raw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avg1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s',div=acenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avg2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s',div=acenters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avgAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True,div=acenters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging over bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_spike = la.pd_aggr_col(df_spike, mybfun, bsections, bcenters.astype(str))\n",
    "b_data = la.pd_aggr_col(df_data, mybfun, bsections, bcenters.astype(str))\n",
    "b_raw = la.pd_aggr_col(df_raw, mybfun, bsections, bcenters.astype(str))\n",
    "b_lick = la.pd_aggr_col(df_lick, mybfun, bsections, bcenters.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_data = b_data.sort_index()\n",
    "b_raw = b_raw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roi(b_spike, b_data, animal+'_bin1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s',div=bcenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(a_spike, a_data, animal+'_bn2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s',div=bcenters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roi(a_spike, a_data, animal+'_binAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True,div=acenters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to ordinal, here we use indices that way\n",
    "et1 = experiment_traits.copy().drop('time', axis=1)\n",
    "et1[['session_num', 'day_num']] = et1[['session_num', 'day_num']].astype(int)\n",
    "ord1 = z_data.reindex(df_template.index, df_template.columns)\n",
    "ord1.columns = pd.Index(ord1.columns.values.astype(int), name=ord1.columns.name)\n",
    "\n",
    "# Combine information\n",
    "ord1 = ord1.join(et1, how='inner').reset_index().drop('time', axis=1).set_index(['roi_id','learning_epoch','context','port','puffed','session_num']).sort_index()\n",
    "ord1.columns.name='Spike'\n",
    "print(ord1.shape)\n",
    "display(ord1.head())\n",
    "\n",
    "# Search for days that contain experiments with same traits and session_num\n",
    "# These entries would jeopardize unstacking\n",
    "et2 = et1.reset_index(drop=True).set_index(['learning_epoch','context','port','puffed','session_num']).sort_index()\n",
    "second_occur = et2.index.duplicated()\n",
    "set1 = et2.loc[second_occur,'day_num'].unique()\n",
    "all_occur = et2.index.get_duplicates()\n",
    "set_all = et2.loc[all_occur,'day_num'].unique()\n",
    "set2 = np.array(list(set(set_all)-set(set1)))\n",
    "print(set1,set2)\n",
    "\n",
    "# Filter out second occurrences stored in set2\n",
    "if len(set2):\n",
    "    ord1 = ord1[ord1.loc[:,'day_num'].apply(lambda x: x not in set2)]\n",
    "print(ord1.shape)\n",
    "\n",
    "# Reshape for correlation analysis\n",
    "# some value get converted to float to be able to hold nan-s\n",
    "comp = ord1['day_num'].unstack().sort_index(axis=1)\n",
    "ord1 = ord1.drop(['day_num'], axis=1).unstack()\n",
    "ord1 = ord1.reset_index().set_index(['learning_epoch','context','port','puffed','roi_id']).sort_index()\n",
    "display(comp.head())\n",
    "display(ord1.head(10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Reorder\n",
    "#ord2 = ord1.reset_index().groupby(['learning_epoch','context','port','puffed','roi_id']).mean()\n",
    "ord2 = ord1.reset_index().set_index(['learning_epoch','context','port','puffed','roi_id'])\n",
    "# Change type for slicing\n",
    "ord2.columns = ord2.columns.values.astype(int)\n",
    "print(ord2.shape)\n",
    "display(ord2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the pre-learning structure, without airpuff\n",
    "key_ref = ('Pre-Learning','CS+',True,False)\n",
    "time_ref = np.array([15, 40])\n",
    "col_ref = slice(int(time_ref[0]*FPS),int(time_ref[1]*FPS))\n",
    "sel = ord1.loc[key_ref+(slice(None),),col_ref]\n",
    "print(sel.shape)\n",
    "\n",
    "# Correlate\n",
    "corr_df = sel.T.corr()\n",
    "corr_np = corr_df.fillna(0).values\n",
    "\n",
    "# Discard invalid series\n",
    "keep = (np.diag(corr_np) == 1.0)\n",
    "corr_np = corr_np[keep,:][:,keep]\n",
    "\n",
    "# Show\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].matshow(corr_df.values)\n",
    "ax[1].matshow(corr_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_correl.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define an ordering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "sq_dist = squareform(1.0-corr_np)\n",
    "corr_link = linkage(sq_dist, 'average')\n",
    "fig, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "fig.suptitle('Reference is presented here: '+(', '.join(np.array(key_ref)))+\n",
    "            ' and time '+('..'.join(time_ref.astype(str)))+'s')\n",
    "labels = sel.index.get_level_values(4).to_series().reset_index(drop=True)[keep]\n",
    "dendo = dendrogram(corr_link, ax=ax[1], labels=labels.values, leaf_font_size=2.5, orientation='left')\n",
    "ax[1].set_title('Distance of firing patterns')\n",
    "corr_order = dendo['leaves']\n",
    "# Show reordered\n",
    "cax = ax[0].matshow(corr_np[corr_order,:][:,corr_order], origin='lower', vmin=-0.8, vmax=1)\n",
    "ax[0].xaxis.set_ticks_position('bottom')\n",
    "ax[0].set_title('Ordered correlation matrix', y=1.0)\n",
    "fig.colorbar(cax)\n",
    "pp.savefig(dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_plots = len(et.index)\n",
    "num_rows = int(np.ceil(num_plots/3.0))\n",
    "fig, ax = plt.subplots(num_rows,3, figsize=(12,4.5*num_rows))\n",
    "fig.suptitle('Correlation structure under different conditions: learning_epoch, context, port, puffed\\n'+\n",
    "             '(small number of trials might lead to larger percieved correlation)')\n",
    "ax = np.ravel(ax)\n",
    "mx = {}\n",
    "ds = pd.DataFrame(columns=et.index)\n",
    "\n",
    "for idx in range(0,num_plots):\n",
    "    # Find the pre-learning structure\n",
    "    key = et.index[idx]\n",
    "    sel = ord1.loc[key+(slice(None),),col_ref]\n",
    "    print(key,ord1.shape,sel.shape)\n",
    "    \n",
    "    # Correlate\n",
    "    corr_tmp = sel.T.corr()\n",
    "    corr_tmp = corr_tmp.fillna(0).values\n",
    "\n",
    "    # Discard invalid series\n",
    "    #if len(corr_tmp):\n",
    "    corr_tmp = corr_tmp[keep,:][:,keep][corr_order,:][:,corr_order]\n",
    "    cax = ax[idx].matshow(corr_tmp, origin='lower', vmin=-0.8, vmax=1)\n",
    "    ax[idx].xaxis.set_ticks_position('bottom')\n",
    "        \n",
    "    mx[et.index[idx]] = corr_tmp\n",
    "    ds[et.index[idx]] = np.ravel(corr_tmp+np.diag(np.nan*np.diag(corr_tmp)))\n",
    "    ax[idx].set_title('%s: %d'%(et.index[idx],et.ix[idx]))\n",
    "pp.savefig(dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(num_rows,3, figsize=(12,4.5*num_rows))\n",
    "fig.suptitle('Distribution of the above correlation coefficients\\n(diagonals excluded)')\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "for idx in range(0,num_plots):\n",
    "    corr_tmp = mx[et.index[idx]]\n",
    "    corr_tmp = corr_tmp+np.diag(np.nan*np.diag(corr_tmp))\n",
    "    ax[idx].hist(np.ravel(corr_tmp),range=(-1,1),bins=20)\n",
    "    ax[idx].set_yscale('log')\n",
    "    ax[idx].set_title('%s: %d'%(et.index[idx],et.ix[idx]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#help(pd.tools.plotting.table)\n",
    "# FIXME index column toooo wide\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.suptitle('Statistics on the correlation coefficients')\n",
    "ax.axis('off')\n",
    "ax.set_position([.5, 0.2, 0.5, 0.6])\n",
    "a = df_epoch(np.round(ds.describe(),4).T)\n",
    "cw = np.ones((len(a.columns),))\n",
    "t = pd.tools.plotting.table(ax, a, loc='upper right', fontsize=12, colWidths=cw/np.sum(cw))\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#help(pd.tools.plotting.table)\n",
    "# FIXME index column toooo wide\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.suptitle('Statistics on the absolute value of correlation coefficients')\n",
    "ax.axis('off')\n",
    "ax.set_position([.5, 0.2, 0.5, 0.6])\n",
    "a = df_epoch(np.round(np.abs(ds).describe(),4).T)\n",
    "cw = np.ones((len(a.columns),))\n",
    "t = pd.tools.plotting.table(ax, a, loc='upper right', fontsize=12, colWidths=cw/np.sum(cw))\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "change = np.zeros((num_plots,num_plots))\n",
    "for idx1 in range(0,num_plots):\n",
    "    for idx2 in range(0,num_plots):\n",
    "        change[idx1,idx2] = np.linalg.norm(np.ravel(mx[et.index[idx1]]-mx[et.index[idx2]])/np.size(mx[et.index[idx2]]),2)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "fig.tight_layout(rect=[0.4,0,0.95,0.55])\n",
    "#fig = plt.figure()\n",
    "#ax = fig.gca()\n",
    "cax = ax.matshow(change+np.diag(np.nan*np.diag(change)), cmap=plt.get_cmap('rainbow'))\n",
    "\n",
    "fig.suptitle('Difference between test cases (RMS distance)\\n'+', '.join(et.index.names))\n",
    "ax.set_xticks(np.array(range(0,len(et.index))))\n",
    "ax.set_xticklabels(et.index.values.tolist(),rotation=90)\n",
    "ax.set_yticks(np.array(range(0,len(et.index))))\n",
    "ax.set_yticklabels(et.index.values.tolist())\n",
    "\n",
    "# without set_yticks\n",
    "# ax.set_yticklabels([tuple()]+et.index.values.tolist())\n",
    "fig.colorbar(cax)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
