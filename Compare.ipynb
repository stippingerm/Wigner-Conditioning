{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reqirements\n",
    "* #### You need to install module future, manual importing from \\_\\_future\\_\\_ is at your convenience\n",
    "* #### For hdf data import you need pytables too which is not default installed with Anaconda\n",
    "\n",
    "### Batch execution\n",
    "* #### ```batch_animal=msaxxyy_z jupyter nbconvert Stat.ipynb --to=html --execute --ExecutePreprocessor.timeout=-1 --output=xxyy_z_report.html```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from future.utils import PY3\n",
    "import future\n",
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, os, warnings, imp, itertools\n",
    "import IPython.display as disp\n",
    "display = disp.display\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "zscore, describe = stats.mstats.zscore, stats.describe\n",
    "import datetime\n",
    "dt, td = datetime.datetime, datetime.timedelta\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ca_lib as la\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "batch_animal = environ.get('batch_animal', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basedir = '../_share/Losonczi/'\n",
    "\n",
    "# Display database folders\n",
    "display(os.listdir(basedir))\n",
    "\n",
    "# Select animal\n",
    "if batch_animal is None:\n",
    "    #animal = 'msa0216_4'; FPS = 8\n",
    "    #animal = 'msa0316_1'; FPS = 8\n",
    "    #animal = 'msa0316_3'; FPS = 8\n",
    "    animal = 'msa0316ag_1'; FPS = 8\n",
    "    #animal = 'msa1215_1'; FPS = 30\n",
    "else:\n",
    "    FPS = None\n",
    "    animal = batch_animal\n",
    "\n",
    "print ('selecting',animal)\n",
    "\n",
    "# List dir\n",
    "mydir = os.path.join(basedir,animal)\n",
    "os.listdir(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Available trials and ROIs\n",
    "data = la.load_files(mydir)\n",
    "if (FPS is not None) and (data.FPS != FPS):\n",
    "    warnings.warn('FPS indication might be wrong.')\n",
    "print (data.raw.shape, '\\n', data.trials, '\\n', data.rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Post-Learning may repeat session_num therefore an additional index,\n",
    "# day_num is created. See msa0316_1.\n",
    "# It seems though that Pre-Learning and Learning treats session_num as documented.\n",
    "display(data.experiment_traits.head())\n",
    "display(data.experiment_traits[data.experiment_traits['day_leap']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment protocol configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def settings_summary(experiment_traits):\n",
    "    et = la.df_epoch(experiment_traits.groupby(la.display_learning).size().to_frame(name='count'))\n",
    "    #et.to_clipboard()\n",
    "    disp.display(disp.HTML('<font color=\"red\">ATTENTION, </font>for later conformity we store columns in a <b>different order</b>: %s !!!'%la.sort_learning))\n",
    "    display(la.df_epoch(et))\n",
    "\n",
    "    et = la.df_epoch(experiment_traits.groupby(la.sort_learning).size().to_frame(name='count'))\n",
    "    return et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et = settings_summary(data.experiment_traits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data = data.filtered\n",
    "df_raw = data.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See how many ROIs are available for which frames\n",
    "\n",
    "avail_sum = (~data.filtered.isnull()).sum() / len(data.trials)\n",
    "plt.plot(avail_sum)\n",
    "plt.xlabel('Camera frame within experiment')\n",
    "plt.ylabel('Available ROIs on average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See which ROI is available in which trial and for how many frames\n",
    "\n",
    "avail = ((~data.filtered.isnull()).sum(axis=1)).to_frame('nFrames').unstack(fill_value=0)\n",
    "\n",
    "print(avail.shape)\n",
    "display(avail.head())\n",
    "display(avail.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spikes_to_timeseries(data):\n",
    "    # Create boolean DataFrame which ROI is spiking in which camera frame\n",
    "\n",
    "    # create empty structure for cumsum\n",
    "    df_spike = pd.DataFrame(data=0,index=data.mirow,columns=data.icol)\n",
    "\n",
    "    # select spike data\n",
    "    spikes = data.transients.loc[data.transients['in_motion_period']==False,['start_frame','stop_frame']]\n",
    "    spikes['count']=1\n",
    "\n",
    "    # fill in spike start and stop points (rename column to keep columns.name in df_spike)\n",
    "    sp = spikes[['start_frame','count']].rename(columns={'start_frame':'frame'}).pivot(columns='frame').fillna(0)\n",
    "    df_spike = df_spike.add(sp['count'], fill_value=0)\n",
    "    sp = spikes[['stop_frame','count']].rename(columns={'stop_frame':'frame'}).pivot(columns='frame').fillna(0)\n",
    "    df_spike = df_spike.add(-sp['count'], fill_value=0)\n",
    "\n",
    "    # cumulate, conversion to int is not adviced if using NaNs\n",
    "    df_spike = df_spike.cumsum(axis=1).astype(int)\n",
    "    df_spike = df_spike + data.time_roi_mask\n",
    "\n",
    "    print('Table shape:', df_spike.shape, 'Active frames*ROIs:', df_spike.sum().sum())\n",
    "    return df_spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_spike = spikes_to_timeseries(data)\n",
    "display(df_spike.head(25))\n",
    "display(df_spike.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def licks_to_timeseries(data):\n",
    "    '''Create DataFrame how many licks happen in a given camera frame'''\n",
    "    # Check for valid data and calculate their frame\n",
    "    print('All entries', data.behavior.shape)\n",
    "    df_lick = data.behavior[data.behavior.loc[:,'stop_time']>data.behavior.loc[:,'start_time']].copy()\n",
    "    print('Valid licks', df_lick.shape)\n",
    "    df_lick['frame'] = (data.FPS*(df_lick['start_time']+df_lick['stop_time'])/2).apply(np.round).astype(int)\n",
    "    #display(df_lick.head())\n",
    "    #display(df_lick.tail())\n",
    "    \n",
    "    # Convert to a DataFrame like df_data or df_raw\n",
    "    df_lick = df_lick[['lick_idx','frame']].reset_index()\n",
    "    df_lick = df_lick.groupby(['time','frame']).count().unstack(fill_value=0)\n",
    "    #display(df_lick.head())\n",
    "    df_lick = df_lick['lick_idx'].reindex(index=data.mirow.levels[0],columns=data.icol,fill_value=0)\n",
    "    #display(df_lick.head())\n",
    "    \n",
    "    # Number of remaining licks\n",
    "    print('Remaining licks',df_lick.sum().sum())\n",
    "    # Smoothen\n",
    "    from scipy.ndimage.filters import gaussian_filter\n",
    "    df_lick = df_lick.apply(lambda x: gaussian_filter(x.astype(float)*data.FPS, sigma=0.25*data.FPS), axis=1, raw=True)\n",
    "    return df_lick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_lick = licks_to_timeseries(data)\n",
    "display(df_lick.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_spike = la.pd_zscore_by_roi(df_spike, data.FPS, -2*data.FPS, axis=1)\n",
    "z_data = la.pd_zscore_by_roi(df_data, data.FPS, -2*data.FPS, axis=1)\n",
    "z_raw = la.pd_zscore_by_roi(df_raw, data.FPS, -2*data.FPS, axis=1)\n",
    "z_lick = la.pd_zscore_clip(df_lick, data.FPS, -2*data.FPS, axis=1)\n",
    "\n",
    "z_data = z_data.sort_index()\n",
    "z_raw = z_raw.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigger(data, threshold, rising=True, hold_off=None):\n",
    "    '''Find threshold crossings along first axis'''\n",
    "    data = np.array(data)\n",
    "    trig = np.full(data.shape,False,dtype=bool)\n",
    "    if hold_off:\n",
    "        raise ValueError('Hold off period not implemented yet.')\n",
    "    if rising:\n",
    "        trig[1:] = (data[1:]>threshold) & (data[:-1]<=threshold)\n",
    "    else:\n",
    "        trig[1:] = (data[1:]<threshold) & (data[:-1]>=threshold)\n",
    "    return trig\n",
    "\n",
    "def trigger_find_pd(df, threshold, axis=1, hold_off=None):\n",
    "    '''Find threshold crossings in both directions in a DataFrame'''\n",
    "    triggers_rise = df.apply(lambda x: trigger(x,threshold, True), axis=axis)\n",
    "    triggers_rise[triggers_rise==0]=np.nan\n",
    "    triggers_fall = df.apply(lambda x: trigger(x,threshold, False), axis=axis)\n",
    "    triggers_fall[triggers_fall==0]=np.nan\n",
    "    \n",
    "    if axis==1:\n",
    "        triggers_rise = triggers_rise.stack()\n",
    "        triggers_fall = triggers_fall.stack()\n",
    "    elif axis==0:\n",
    "        triggers_rise = triggers_rise.T.stack().T\n",
    "        triggers_fall = triggers_fall.T.stack().T\n",
    "    else:\n",
    "        warnings.warn('Axis reduction not implemented for axis.')\n",
    "    triggers_rise.name='weight'\n",
    "    triggers_fall.name='weight'\n",
    "    return triggers_rise, triggers_fall\n",
    "\n",
    "def trigger_enable_pd(df, start, stop):\n",
    "    '''Create trigger enabled array based on a pair of switch on and off events'''\n",
    "    mi = pd.MultiIndex.from_product((df.index.values, [start]), names=['time', 'frame'])\n",
    "    triggers_start = pd.Series(1.0, index=mi, name='weight')\n",
    "    mi = pd.MultiIndex.from_product((df.index.values, [stop]), names=['time', 'frame'])\n",
    "    triggers_stop = pd.Series(1.0, index=mi, name='weight')\n",
    "    mi = pd.MultiIndex.from_product((df.index.values, list(range(start,stop))), names=['time', 'frame'])\n",
    "    triggers_allow = pd.Series(1.0, index=mi, name='weight')\n",
    "\n",
    "    return triggers_start, triggers_stop, triggers_allow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_spike_threshold = 5.0/np.sqrt(len(data.rois))\n",
    "\n",
    "max_lick_rate = 20\n",
    "c,b = np.histogram(df_lick.values.ravel(),range=(0,max_lick_rate),bins=max_lick_rate)\n",
    "lick_threshold = (np.argmax(c[1:])+1.5)/2\n",
    "plt.hist(df_lick.values.ravel(),log=True,range=(0,max_lick_rate),bins=max_lick_rate)\n",
    "plt.plot(lick_threshold,2,'y*',ms=15)\n",
    "print(lick_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The histogram shape justifies putting the threshold at the half maximum\n",
    "lick_triggers_rise, lick_triggers_fall = trigger_find_pd(df_lick, lick_threshold)\n",
    "print (lick_triggers_rise.shape,lick_triggers_fall.shape)\n",
    "print ('Port was present in %d trials.'%data.experiment_traits[data.experiment_traits['port']=='W+'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the boundaryof a p<0.005 set \n",
    "spike_triggers_rise, spike_triggers_fall = trigger_find_pd(z_spike.mean(level=0), z_spike_threshold)\n",
    "print (spike_triggers_rise.shape,spike_triggers_fall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csp_triggers_rise, csp_triggers_fall, csp_triggers_allow = trigger_enable_pd(\n",
    "    data.experiment_traits[data.experiment_traits['context']=='CS+'],\n",
    "    la.events[1]*data.FPS, la.events[2]*data.FPS)\n",
    "csm_triggers_rise, csm_triggers_fall, csm_triggers_allow = trigger_enable_pd(\n",
    "    data.experiment_traits[data.experiment_traits['context']=='CS-'],\n",
    "    la.events[1]*data.FPS, la.events[2]*data.FPS)\n",
    "\n",
    "us_triggers_rise, us_triggers_fall, us_triggers_allow = trigger_enable_pd(\n",
    "    data.experiment_traits[data.experiment_traits['puffed']=='A+'],\n",
    "    la.events[3]*data.FPS, la.events[4]*data.FPS)\n",
    "\n",
    "tra_triggers_rise, tra_triggers_fall, tra_triggers_allow = trigger_enable_pd(\n",
    "    data.experiment_traits[data.experiment_traits['context']!='Baseline'],\n",
    "    la.events[2]*data.FPS, la.events[3]*data.FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-scored spiking\n",
    "Spiking is \"True\" in the [intervals) given in transients_data.hc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymean = pd.DataFrame.mean\n",
    "mystd = pd.DataFrame.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging in 5\" bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsections = np.arange(0,60,5)*data.FPS\n",
    "bcenters = (bsections[1:]+bsections[:-1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zb_spike = la.pd_aggr_col(z_spike, mymean, bsections, bcenters.astype(str))\n",
    "zb_data = la.pd_aggr_col(z_data, mymean, bsections, bcenters.astype(str))\n",
    "zb_raw = la.pd_aggr_col(z_raw, mymean, bsections, bcenters.astype(str))\n",
    "zb_lick = la.pd_aggr_col(z_lick, mymean, bsections, bcenters.astype(str))\n",
    "\n",
    "zb_data = zb_data.sort_index()\n",
    "zb_raw = zb_raw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_spike = la.pd_aggr_col(df_spike, mymean, bsections, bcenters.astype(str))\n",
    "b_data = la.pd_aggr_col(df_data, mymean, bsections, bcenters.astype(str))\n",
    "b_raw = la.pd_aggr_col(df_raw, mymean, bsections, bcenters.astype(str))\n",
    "b_lick = la.pd_aggr_col(df_lick, mymean, bsections, bcenters.astype(str))\n",
    "\n",
    "b_data = b_data.sort_index()\n",
    "b_raw = b_raw.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging within phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asections = np.append(la.events,[60])*data.FPS\n",
    "acenters = (asections[1:]+asections[:-1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "za_spike = la.pd_aggr_col(z_spike, mymean, asections, acenters.astype(str))\n",
    "za_data = la.pd_aggr_col(z_data, mymean, asections, acenters.astype(str))\n",
    "za_raw = la.pd_aggr_col(z_raw, mymean, asections, acenters.astype(str))\n",
    "za_lick = la.pd_aggr_col(z_lick, mymean, asections, acenters.astype(str))\n",
    "\n",
    "za_data = za_data.sort_index()\n",
    "za_raw = za_raw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_spike = la.pd_aggr_col(df_spike, mymean, asections, acenters.astype(str))\n",
    "a_data = la.pd_aggr_col(df_data, mymean, asections, acenters.astype(str))\n",
    "a_raw = la.pd_aggr_col(df_raw, mymean, asections, acenters.astype(str))\n",
    "a_lick = la.pd_aggr_col(df_lick, mymean, asections, acenters.astype(str))\n",
    "\n",
    "a_data = a_data.sort_index()\n",
    "a_raw = a_raw.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Licking statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lick_rate_mean = la.pd_aggr_col(df_lick, mymean, asections, acenters.astype(str))\n",
    "lick_rate_std = la.pd_aggr_col(df_lick, mystd, asections, acenters.astype(str))\n",
    "lick_time_mean = la.pd_aggr_col((df_lick>lick_threshold).astype(float), mymean,\n",
    "                                asections, acenters.astype(str))\n",
    "lick_time_std = la.pd_aggr_col((df_lick>lick_threshold).astype(float), mystd,\n",
    "                               asections, acenters.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "class helpmultipage(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.isopen = False\n",
    "        self.open()\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "        \n",
    "    def savefig(self, dpi=None):\n",
    "        if self.isopen:\n",
    "            self.pp.savefig(dpi=dpi)\n",
    "\n",
    "    def open(self):\n",
    "        if (~self.isopen) and len(self.filename):\n",
    "            self.pp = PdfPages(self.filename)\n",
    "            self.isopen = True\n",
    "        \n",
    "    def close(self):\n",
    "        if self.isopen:\n",
    "            self.pp.close()\n",
    "        self.isopen = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanatory figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def explain_figures(data):\n",
    "    import matplotlib.patches as mpatches\n",
    "    from matplotlib.collections import PatchCollection\n",
    "    center = data.FPS * (la.events[:-1]+la.events[1:]) /2\n",
    "    left = data.FPS * la.events\n",
    "    width = data.FPS * (la.events[1:]-la.events[:-1])\n",
    "    vcenter = 0.0\n",
    "    vstart = -0.5\n",
    "\n",
    "    def label90(x,y,text):\n",
    "        ax.text(x, y, text, ha=\"center\", va=\"center\", family='sans-serif', size=14, rotation=90)\n",
    "\n",
    "    fig, (empty, ax) = plt.subplots(2,1,figsize=(6,8))\n",
    "    fig.suptitle('Explanatory figure',fontsize=16)\n",
    "    fig.tight_layout(pad=3)\n",
    "    empty.axis('off')\n",
    "    \n",
    "    ax.set_xlabel('Camera frame')\n",
    "    ax.set_ylabel('z-scored activity')\n",
    "    ax.set_ylim(vstart,vstart+1)\n",
    "    ax.plot(z_spike.mean(axis=0)+0.00, label=\"(CategoryA, True): #trials\", c=(1,1,0))\n",
    "    ax.plot(z_spike.mean(axis=0)+0.02, label=\"(CategoryB, True): #trials\", c=(.5,1,.5))\n",
    "    ax.plot(-z_spike.mean(axis=0)+0.00, label=\"(CategoryA, False): #trials\", c=(1,.8,1))\n",
    "    ax.plot(-z_spike.mean(axis=0)+0.02, label=\"(CategoryB, False): #trials\", c=(.5,1,1))\n",
    "    patches = []\n",
    "    # mark delay\n",
    "    label90(center[0], vcenter, 'excitation by\\nshowing water')\n",
    "    # mark CS\n",
    "    rect = mpatches.Rectangle((left[1],vstart), width[1], 1, ec=\"none\")\n",
    "    patches.append(rect)\n",
    "    label90(center[1], vcenter, 'CS± if tone\\n\"Baseline\" otherwise')\n",
    "    # mark delay\n",
    "    label90(center[2], vcenter, 'trace = delay')\n",
    "    # mark UC\n",
    "    rect = mpatches.Rectangle((left[3],vstart), width[3], 1, ec=\"none\")\n",
    "    patches.append(rect)\n",
    "    label90(center[3], vcenter, 'UC if any')\n",
    "    # mark water\n",
    "    ax.text((left[0]+left[3])/2, vstart, \"water port present\\niff allowed to lick\",\n",
    "            ha=\"center\", va=\"bottom\", family='sans-serif', size=14, bbox=dict(boxstyle=\"DArrow\", pad=0.0, fc='c'))\n",
    "\n",
    "    # show event boundaries\n",
    "    for i in range(0,len(la.events)):\n",
    "        ax.axvline(x=la.events[i]*data.FPS, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "    colors = np.linspace(0, 1, len(patches))\n",
    "    collection = PatchCollection(patches, cmap=plt.cm.hsv, alpha=0.1)\n",
    "    collection.set_array(np.array(colors))\n",
    "    ax.add_collection(collection)\n",
    "\n",
    "    # align legend\n",
    "    leg = ax.legend(loc='lower center', title=\"Category name, Condition name\",\n",
    "                   bbox_to_anchor=(0.5, 1.1))\n",
    "    leg.get_title().set_fontsize('large')\n",
    "    leg.get_title().set_fontweight('bold')\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', UserWarning)\n",
    "        fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_explanatory.pdf')\n",
    "fig = explain_figures(data)\n",
    "pp.savefig()\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learning_chart(data):\n",
    "    fig, ax = plt.subplots(len(data.trials),1,figsize=(10,0.6*len(data.trials)), sharex=True, sharey=True)\n",
    "    fig.tight_layout(h_pad=0.1)\n",
    "    ind = np.arange(0,5)\n",
    "    width, height, spacing = 1, 1.2, 10\n",
    "    label_df = data.experiment_traits.replace('Baseline','B.L.')\n",
    "    for i in range(0,len(data.trials)):\n",
    "        trial = data.trials[i]\n",
    "        sc = 2.0*lick_threshold\n",
    "        rects1 = ax[i].bar(ind+2*spacing, lick_rate_mean.loc[trial]/sc, width, color='r', yerr=lick_rate_std.loc[trial]/sc)\n",
    "        rects2 = ax[i].bar(ind+3*spacing, lick_time_mean.loc[trial], width, color='b')\n",
    "        ax[i].set_xlim(xmin=0)\n",
    "        ax[i].set_ylim(ymin=0, ymax=height)\n",
    "        ax[i].set_yticks([0,0.5,1])\n",
    "        la.draw_conditions(ax[i],label_df,trial,data.FPS,loc='lower left',screen_width=0.5, height=height, cw=[0.25, 0.15, 0.15, 0.15, 0.15, 0.15],fontsize=12)\n",
    "    ax[-1].set_xticks([spacing, 2.2*spacing, 3.2*spacing])\n",
    "    ax[-1].set_xticklabels(['Conditions', 'Licking rate', 'Licking time'])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_protocol.pdf')\n",
    "fig = learning_chart(data)\n",
    "pp.savefig()\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_pop.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "la.plot_data(df_spike, df_data, df_lick, data.experiment_traits, data.FPS)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single criterion\n",
    "* comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grp = [['context'],['learning_epoch'],['port'],['puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, data.FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, data.FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, data.FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two criteria\n",
    "* comments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = [['context','learning_epoch'],['context','port'],['context','puffed'],['learning_epoch','puffed'],['learning_epoch','port'],['port','puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, data.FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, data.FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, data.FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three criteria\n",
    "* comments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = [['context','learning_epoch','port'],['context','learning_epoch','puffed'],['context','port','puffed'],['learning_epoch','port','puffed']]\n",
    "la.plot_data(z_spike, z_data, df_lick, data.experiment_traits, data.FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(zb_spike, zb_data, b_lick, data.experiment_traits, data.FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(za_spike, za_data, a_lick, data.experiment_traits, data.FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All criteria\n",
    "* There is no increased population activity for CS+ without puffing. (For mouse 0216_4 the 1 trial with port displays increase during the trace period - why?)\n",
    "* During learning mouse 0216_4 shows incresed activity during the UC phase for CS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = [['context','port','puffed']]\n",
    "la.plot_epochs(z_spike, z_data, df_lick, data.experiment_traits, et.sum(level=(1,2,3)), data.FPS, grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_epochs(zb_spike, zb_data, b_lick, data.experiment_traits, et.sum(level=(1,2,3)), data.FPS, grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_epochs(za_spike, za_data, a_lick, data.experiment_traits, et.sum(level=(1,2,3)), data.FPS, grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities conditional on epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_by_epoch(epoch):\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = z_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    raw_c = z_raw.reindex(experiment_c.index, level='time')\n",
    "    lick_c = df_lick.reindex(experiment_c.index)\n",
    "    print (experiment_c.shape, z_spike.shape)\n",
    "    spike_ca = la.pd_aggr_col(spike_c, mymean, asections, acenters.astype(str))\n",
    "    data_ca = la.pd_aggr_col(data_c, mymean, asections, acenters.astype(str))\n",
    "    raw_ca = la.pd_aggr_col(raw_c, mymean, asections, acenters.astype(str))\n",
    "    lick_ca = la.pd_aggr_col(lick_c, mymean, asections, acenters.astype(str))\n",
    "    print (spike_c.shape, spike_ca.shape)\n",
    "\n",
    "    grp = [['context','port'],['context','puffed'],['port','puffed']]\n",
    "    la.plot_data(spike_c, data_c, lick_c, data.experiment_traits, data.FPS, grp, title=epoch)\n",
    "    pp.savefig()\n",
    "    la.plot_data(spike_ca, data_ca, lick_ca, data.experiment_traits, data.FPS, grp, title=epoch+' averaged over events', div=acenters)\n",
    "    pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Pre-Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_by_epoch('Post-Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity vector by phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_phases_sp.pdf')\n",
    "\n",
    "# trial IDs by condition (non-unique index)\n",
    "etmp = data.experiment_traits.reset_index(drop=True).set_index(la.sort_learning)\n",
    "\n",
    "nplot = len(et.index)\n",
    "ncol = 14\n",
    "nrow = int(np.ceil(len(et.index)/float(ncol)))\n",
    "\n",
    "for p,aggr in enumerate(a_spike.columns):\n",
    "    fig, ax = plt.subplots(nrow,ncol,figsize=(2*ncol,1+10*nrow),squeeze=False,sharey=True)\n",
    "    fig.tight_layout(pad=3, h_pad=3, rect=[0,0,1,0.8])\n",
    "    fig.suptitle('Spikes, Phase: %s'%la.phases[p],fontsize=16)\n",
    "    for i, cond in enumerate(et.index):\n",
    "        icol = i%ncol\n",
    "        irow = int((i-icol)/ncol)\n",
    "        sel = etmp.loc[cond,'timestr']\n",
    "        tmp = a_spike.loc[sel.tolist(),aggr].unstack('time')\n",
    "        img = ax[irow,icol].matshow(tmp.values,origin='lower',vmin=0,vmax=1)\n",
    "        ax[irow,icol].xaxis.set_ticks_position('bottom')\n",
    "        ax[irow,icol].set_title('\\n'.join(cond))\n",
    "        ax[irow,icol].set_ylabel('Unit ID')\n",
    "        ax[irow,icol].set_xlabel('Trial')\n",
    "    #cax,kw = mpl.colorbar.make_axes([axis for axis in ax.flat])\n",
    "    cax = ax[-1,-1]\n",
    "    plt.colorbar(img,ax=cax)#ax=cax,**kw)\n",
    "    pp.savefig()    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_phases_ca.pdf')\n",
    "\n",
    "# trial IDs by condition (non-unique index)\n",
    "etmp = data.experiment_traits.reset_index(drop=True).set_index(la.sort_learning)\n",
    "\n",
    "for p,aggr in enumerate(za_data.columns):\n",
    "    nplot = len(et.index)\n",
    "    ncol = 14\n",
    "    nrow = int(np.ceil(len(et.index)/float(ncol)))\n",
    "    fig, ax = plt.subplots(nrow,ncol,figsize=(2*ncol,1+10*nrow),squeeze=False,sharey=True)\n",
    "    fig.tight_layout(pad=3, h_pad=3, rect=[0,0,1,0.8])\n",
    "    fig.suptitle('Ca-Signal, Phase: %s'%la.phases[p],fontsize=16)\n",
    "    for i, cond in enumerate(et.index):\n",
    "        icol = i%ncol\n",
    "        irow = int((i-icol)/ncol)\n",
    "        sel = etmp.loc[cond,'timestr']\n",
    "        tmp = za_data.loc[sel.tolist(),aggr].unstack('time')\n",
    "        img = ax[irow,icol].matshow(tmp.values,origin='lower',vmin=-3,vmax=3)\n",
    "        ax[irow,icol].xaxis.set_ticks_position('bottom')\n",
    "        ax[irow,icol].set_title('\\n'.join(cond))\n",
    "        ax[irow,icol].set_ylabel('Unit ID')\n",
    "        ax[irow,icol].set_xlabel('Trial')\n",
    "    #cax,kw = mpl.colorbar.make_axes([axis for axis in ax.flat])\n",
    "    cax = ax[-1,-1]\n",
    "    plt.colorbar(img,ax=cax)#ax=cax,**kw)\n",
    "    pp.savefig()    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of spiking\n",
    "The first 1 second of the recording seems missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Order experiments by settings (deprecated)\n",
    "et3 = data.experiment_traits.copy().reset_index(drop=True)\n",
    "et3 = et3.sort_values(la.sort_learning+[str('session_num')]).set_index(la.sort_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Triggers\n",
    "trig_list_data = [lick_triggers_rise, lick_triggers_fall, spike_triggers_rise, spike_triggers_fall]\n",
    "trig_list_sign = ['o', 's', '^', 'v']\n",
    "trig_list_color = ['b', 'y', 'r', 'g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activity_plot(ax, data, idx, settings, seismic=False, show_nan=False, pos=-20):\n",
    "    experiment_id = settings['timestr']\n",
    "    fig.suptitle('%s: session %s, day %s\\n'%(idx,settings['session_num'],settings['day_num'])+\n",
    "                 ', '.join(la.sort_learning)+': #context in epoch, #day',fontsize=16)\n",
    "    if seismic:\n",
    "        la.draw_levels(ax, z_data, idx, data.FPS, data.roi_df)\n",
    "    else:\n",
    "        la.draw_transients(ax, data.transients, idx, data.FPS, data.roi_df)\n",
    "    if show_nan:\n",
    "        la.draw_spiking_nan(ax, df_spike, idx, data.rois.values)\n",
    "    la.draw_population(ax, z_data, idx, pos=pos, c='y', label='population Ca-signal')\n",
    "    la.draw_population(ax, z_spike, idx, pos=pos, threshold=z_spike_threshold, label='population z-spike count')\n",
    "    la.draw_licking(ax, df_lick, idx, pos=pos-20, threshold=lick_threshold, label='licking')\n",
    "    la.draw_triggers(ax, trig_list_data, idx, -5, trig_list_sign, c=trig_list_color)\n",
    "    la.draw_conditions(ax, data.experiment_traits, experiment_id, data.FPS, height=20)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show an example\n",
    "idx, settings = data.experiment_traits.index[9], data.experiment_traits.iloc[9,:]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "ax.set_ylim(ymin=-60,ymax=len(data.rois)+1)\n",
    "activity_plot(ax, data, idx, settings, True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show an example\n",
    "idx, settings = data.experiment_traits.index[9], data.experiment_traits.iloc[9,:]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "ax.set_ylim(ymin=-60,ymax=len(data.rois)+1)\n",
    "activity_plot(ax, data, idx, settings, False, True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_firing.pdf')\n",
    "\n",
    "xmax = data.transients.loc[:,['stop_frame']].max().values\n",
    "\n",
    "for idx, settings in data.experiment_traits.iterrows():\n",
    "    fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "    ax.set_xlim(xmax=xmax)\n",
    "    ax.set_ylim(ymin=-60,ymax=len(data.rois)+1)\n",
    "    activity_plot(ax, data, idx, settings)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prog_update = 1467888751\n",
    "print (\"%.0f\"%time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattdb_file = 'pattdb_'+animal+'.h5'\n",
    "if 'pattdb' in locals():\n",
    "    pattdb.close()\n",
    "    del pattdb\n",
    "if (not la.test_hdf(pattdb_file)) or (os.path.getmtime(pattdb_file)<prog_update):\n",
    "    with pd.HDFStore(pattdb_file, mode='w') as pattdb:\n",
    "        for method,sel in itertools.product(['match','correlate'],['sp','ca']):\n",
    "            print(method,sel)\n",
    "            df = df_spike if sel == 'sp' else z_data.reindex(data.mirow)\n",
    "            key = '/'.join((method,sel,'lick_rise_csp'))\n",
    "            pattdb[key] = la.search_pattern(df, lick_triggers_rise, data.trials,\n",
    "                                            data.FPS, trigger_allow=csp_triggers_allow)\n",
    "            key = '/'.join((method,sel,'lick_fall_csp'))\n",
    "            pattdb[key] = la.search_pattern(df, lick_triggers_fall, data.trials,\n",
    "                                            data.FPS, trigger_allow=csp_triggers_allow)\n",
    "            key = '/'.join((method,sel,'csp_rise'))\n",
    "            pattdb[key] = la.search_pattern(df, csp_triggers_rise, data.trials, data.FPS)\n",
    "            key = '/'.join((method,sel,'us_rise'))\n",
    "            pattdb[key] = la.search_pattern(df, us_triggers_rise, data.trials, data.FPS)\n",
    "pattdb = pd.HDFStore(pattdb_file, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_patt = {}\n",
    "for key in pattdb.keys():\n",
    "    if key[0] == '/':\n",
    "        key = key[1:]\n",
    "    z_patt[key] = la.nan_zscore(pattdb[key])\n",
    "pattdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_detections(ax, z_patt, method, sel, idx, ids, names, colors):\n",
    "    threshold = [-3, 3]\n",
    "    zoom = 3\n",
    "    for i, id1 in enumerate(ids):\n",
    "        la.draw_licking(ax, z_patt['/'.join((method,sel,id1))], idx, pos=-20, c=colors[i],\n",
    "                threshold=threshold, zoom=zoom, label='%s: %s'%(sel, names[i]))\n",
    "        threshold = None\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show an example\n",
    "method = 'match' # 'match', 'correlate'\n",
    "sel = 'ca' # 'ca', 'sp'\n",
    "idx, settings = data.experiment_traits.index[13], data.experiment_traits.iloc[13,:]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "ax.set_ylim(ymin=-80,ymax=len(data.rois)+1)\n",
    "show_detections(ax, z_patt, method, sel, idx, ['lick_rise_csp','lick_fall_csp','csp_rise','us_rise'],\n",
    "                ['CS+ lick start', 'CS+ lick end', 'CS+ start', 'US start'], ['g', 'c', 'orange', 'r'])\n",
    "activity_plot(ax, data, idx, settings, False, True, pos=-40)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for method,sel in itertools.product(['match','correlate'], ['sp','ca']):\n",
    "    print (method,sel)\n",
    "\n",
    "    pp = helpmultipage(animal+'_triggers_%s_%s.pdf'%(method,sel))\n",
    "    zoom = 4\n",
    "\n",
    "    xmax = data.transients.loc[:,['stop_frame']].max().values\n",
    "\n",
    "    for idx, val in data.experiment_traits.iterrows(): #et3.iterrows():\n",
    "        fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "        ax.set_xlim(xmax=xmax)\n",
    "        ax.set_ylim(ymin=-80,ymax=len(data.rois)+1)\n",
    "        show_detections(ax, z_patt, method, sel, idx, ['lick_rise_csp','lick_fall_csp','csp_rise','us_rise'],\n",
    "                ['CS+ lick start', 'CS+ lick end', 'CS+ start', 'US start'], ['g', 'c', 'orange', 'r'])\n",
    "        #la.draw_licking(ax, z_patt['/'.join((method,sel,'lick_rise_csp'))], idx, pos=-20, c='g',\n",
    "        #                threshold=[-3, 3], zoom=zoom, label='%s: CS+ lick start'%sel)\n",
    "        #la.draw_licking(ax, z_patt['/'.join((method,sel,'lick_fall_csp'))], idx, pos=-20, c='c',\n",
    "        #                threshold=None, zoom=zoom, label='%s: CS+ lick end'%sel)\n",
    "        #la.draw_licking(ax, z_patt['/'.join((method,sel,'csp_rise'))], idx, pos=-20, c='orange',\n",
    "        #                threshold=None, zoom=zoom, label='%s: CS+ start'%sel)\n",
    "        #la.draw_licking(ax, z_patt['/'.join((method,sel,'us_rise'))], idx, pos=-20, c='r',\n",
    "        #                threshold=None, zoom=zoom, label='%s: US start'%sel)\n",
    "        activity_plot(ax, data, idx, settings, False, True, pos=-40)\n",
    "        ax.legend()\n",
    "        pp.savefig()\n",
    "        plt.close(fig)\n",
    "\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peri-event plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matlab_tools as mt\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_peri_3a(df, title=None):\n",
    "    '''Plot collection: CS+ US'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    ret.append([df, data.rois, lick_triggers_rise, None, None, 'Lick rise'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, None, None, 'Lick fall'])\n",
    "    ret.append([df, data.rois, lick_triggers_rise, csp_triggers_allow, None, 'Lick rise CS+'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, csp_triggers_allow, None, 'Lick fall CS+'])\n",
    "    ret.append([df, data.rois, csp_triggers_rise, None, None, 'CS+ start'])\n",
    "    ret.append([df, data.rois, csp_triggers_fall, None, None, 'CS+ end'])\n",
    "    ret.append([df, data.rois, lick_triggers_rise, us_triggers_allow, None, 'Lick rise US'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, us_triggers_allow, None, 'Lick fall US'])\n",
    "    ret.append([df, data.rois, us_triggers_rise, None, None, 'US start'])\n",
    "    ret.append([df, data.rois, us_triggers_fall, None, None, 'US end'])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_peri_3b(df, title=None):\n",
    "    '''Plot collection: CS+ US'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    ret.append([df, data.rois, lick_triggers_rise, None, None, 'Lick rise'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, None, None, 'Lick fall'])\n",
    "    ret.append([df, data.rois, lick_triggers_rise, csp_triggers_allow, None, 'Lick rise CS+'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, csp_triggers_allow, None, 'Lick fall CS+'])\n",
    "    ret.append([df, data.rois, csp_triggers_rise, None, None, 'CS+ start'])\n",
    "    ret.append([df, data.rois, csp_triggers_fall, None, None, 'CS+ end'])\n",
    "    ret.append([df, data.rois, lick_triggers_rise, csm_triggers_allow, None, 'Lick rise CS-'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, csm_triggers_allow, None, 'Lick fall CS-'])\n",
    "    ret.append([df, data.rois, csm_triggers_rise, None, None, 'CS- start'])\n",
    "    ret.append([df, data.rois, csm_triggers_fall, None, None, 'CS- end'])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig=la.plot_peri_collection(list_peri_3a(df_spike),'Spiking',combine=False)\n",
    "fig=la.plot_peri_collection(list_peri_3a(df_spike),'Spiking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_peri1.pdf')\n",
    "for epoch in la.epochs.values:\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    fig=la.plot_peri_collection(list_peri_3a(spike_c),'%s Spiking on US'%epoch,combine=False)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    fig=la.plot_peri_collection(list_peri_3b(spike_c),'%s Spiking on CS+/-'%epoch,combine=False)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "for epoch in la.epochs.values:\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    fig=la.plot_peri_collection(list_peri_3a(data_c),'%s Ca-level on US'%epoch,combine=False)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    fig=la.plot_peri_collection(list_peri_3b(data_c),'%s Ca-level on CS+/-'%epoch,combine=False)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_peri2.pdf')\n",
    "for epoch in la.epochs.values:\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    fig=la.plot_peri_collection(list_peri_3a(spike_c),'%s Spiking on US'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    fig=la.plot_peri_collection(list_peri_3b(spike_c),'%s Spiking on CS+/-'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "for epoch in la.epochs.values:\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = z_data.reindex(experiment_c.index, level='time')\n",
    "    fig=la.plot_peri_collection(list_peri_3a(data_c),'%s Ca-level on US'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    fig=la.plot_peri_collection(list_peri_3b(data_c),'%s Ca-level on CS+/-'%epoch)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual ROIs\n",
    "* since there are many of them, save figure to pdf\n",
    "* THIS WILL <font color=\"red\">TAKE A WHILE</font>, consider testing with a small range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roi(df_spike, df_data, filaname, grp, title_template, by_epoch=False, div=None, fill=None):\n",
    "    pp = PdfPages(filaname)\n",
    "    for i in range(0,len(data.rois)):\n",
    "        spike_c = df_spike.loc[(slice(None),data.rois[i]),:]\n",
    "        data_c = df_data.loc[(slice(None),data.rois[i]),:]\n",
    "        #raw_c = df_raw.loc[(slice(None),data.rois[i]),:]\n",
    "        if by_epoch:\n",
    "            fig = la.plot_epochs(spike_c, data_c, None, data.experiment_traits, et.sum(level=(1,2,3)), data.FPS, grp, title=title_template%(i,data.rois[i]), div=div, fill=fill)\n",
    "        else:\n",
    "            fig = la.plot_data(spike_c, data_c, None, data.experiment_traits, data.FPS, grp, title=title_template%(i,data.rois[i]), div=div, fill=fill)\n",
    "        pp.savefig()\n",
    "        plt.close(fig)\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if batch_animal is None:\n",
    "    raise ValueError(\"You don't want to run this automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roi1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roi2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "plot_roi(df_spike, df_data, animal+'_roiAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging over intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intervals aligned to events"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avg1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s',div=acenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avg2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s',div=acenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_roi(a_spike, a_data, animal+'_avgAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True,div=acenters, fill='err')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging over bins"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_roi(b_spike, b_data, animal+'_bin1crit.pdf',[['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s',div=bcenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(a_spike, a_data, animal+'_bn2crit.pdf',[['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s',div=bcenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_roi(a_spike, a_data, animal+'_binAcrit.pdf',[['context','port','puffed']],'ROI %d:\\n%s',True,div=acenters, fill='err')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_for_correlation(df, data):\n",
    "    # Combine information\n",
    "    ord1 = df.reindex(data.mirow, data.icol)\n",
    "    et1 = data.experiment_traits.copy().loc[:,la.sort_learning+['day_num','session_num']]\n",
    "    ord1 = ord1.join(et1, how='inner').reset_index().drop('time', axis=1).set_index(la.sort_learning+['roi_id', 'session_num']).sort_index()\n",
    "    ord1.columns.name='Spike'\n",
    "    #display(ord1.head())\n",
    "\n",
    "    # Search for days that contain experiments with same traits and session_num\n",
    "    # These entries would jeopardize unstacking\n",
    "    et2 = et1.reset_index(drop=True).set_index(la.sort_learning+['session_num']).sort_index()\n",
    "    second_occur = et2.index.duplicated()\n",
    "    set1 = et2.loc[second_occur,'day_num'].unique()\n",
    "    all_occur = et2.index.get_duplicates()\n",
    "    set_all = et2.loc[all_occur,'day_num'].unique()\n",
    "    set2 = np.array(list(set(set_all)-set(set1)))\n",
    "    print('Days repeating settings:',set1,'All days with conflicting settings:',set2)\n",
    "\n",
    "    # Filter out second occurrences stored in set2\n",
    "    if len(set2):\n",
    "        ord1 = ord1[ord1.loc[:,'day_num'].apply(lambda x: x not in set2)]\n",
    "    print('Filtered data:',ord1.shape)\n",
    "\n",
    "    # Reshape for correlation analysis\n",
    "    # integer values get converted to float if needed to hold NaN-s\n",
    "    calendar = ord1['day_num'].unstack(fill_value=0)\n",
    "    ord1 = ord1.drop(['day_num'], axis=1).unstack()\n",
    "    print('Concatenated data:',ord1.shape)\n",
    "    return ord1, calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ord1, calendar = concat_for_correlation(z_data, data)\n",
    "display(calendar.head())\n",
    "display(ord1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the pre-learning structure, without airpuff\n",
    "key_ref = ('Post-Learning','CS+','W+','A+')\n",
    "time_ref = np.array([15, 40])\n",
    "col_ref = slice(int(time_ref[0]*data.FPS),int(time_ref[1]*data.FPS))\n",
    "sel = ord1.loc[key_ref+(slice(None),),col_ref]\n",
    "print(key_ref,time_ref,col_ref,sel.shape)\n",
    "\n",
    "# Correlate\n",
    "corr_df = sel.T.corr()\n",
    "corr_np = corr_df.fillna(0).values\n",
    "\n",
    "# Discard invalid series\n",
    "keep = (np.diag(corr_np) == 1.0)\n",
    "corr_np = corr_np[keep,:][:,keep]\n",
    "\n",
    "# Show\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "img = ax[0].matshow(corr_df.values)\n",
    "img = ax[1].matshow(corr_np)\n",
    "fig.colorbar(img, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage(animal+'_correl.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define an ordering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "sq_dist = squareform(1.0-corr_np)\n",
    "corr_link = linkage(sq_dist, 'average')\n",
    "fig, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "fig.suptitle('Reference is presented here: '+(', '.join(np.array(key_ref)))+\n",
    "            ' and time '+('..'.join(time_ref.astype(str)))+'s',fontsize=16)\n",
    "labels = sel.index.get_level_values(4).to_series().reset_index(drop=True)[keep]\n",
    "dendo = dendrogram(corr_link, ax=ax[1], labels=labels.values, leaf_font_size=2.5, orientation='left')\n",
    "ax[1].set_title('Distance of firing patterns')\n",
    "corr_order = dendo['leaves']\n",
    "# Show reordered\n",
    "img = ax[0].matshow(corr_np[corr_order,:][:,corr_order], origin='lower', vmin=-0.8, vmax=1)\n",
    "ax[0].xaxis.set_ticks_position('bottom')\n",
    "ax[0].set_title('Ordered correlation matrix', y=1.0)\n",
    "fig.colorbar(img)\n",
    "pp.savefig(dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phase_start = data.event_frames+data.FPS\n",
    "phase_end = data.event_frames[1:]-data.FPS\n",
    "\n",
    "num_phases = 3\n",
    "num_rows = len(et.index)\n",
    "num_cols = num_phases\n",
    "fig, ax = plt.subplots(num_rows,num_cols, figsize=(5*num_cols,5*num_rows))\n",
    "fig.suptitle('Correlation structure under different conditions: learning_epoch, context, port, puffed\\n'+\n",
    "             '(small number of trials might lead to larger percieved correlation)\\n'+\n",
    "             '(in phases Ready, CS, Trace the conditions A+ and A- should be very similar)',fontsize=16)\n",
    "#ax = np.ravel(ax)\n",
    "mx = {}\n",
    "mi = pd.DataFrame([], index=pd.Index(la.phases[0:num_phases],name='phase'), columns = et.index).unstack().index\n",
    "ds = pd.DataFrame(columns=mi)\n",
    "\n",
    "for row,col in itertools.product(range(0,num_rows),range(0,num_cols)):\n",
    "    # Find the pre-learning structure\n",
    "    key = et.index[row]\n",
    "    phase = la.phases[col]\n",
    "    count = et.ix[row]\n",
    "    col_sel = slice(int(phase_start[col]),int(phase_end[col]))\n",
    "    sel = ord1.loc[key+(slice(None),),col_sel]\n",
    "    print(key,phase,ord1.shape,sel.shape)\n",
    "    \n",
    "    # Correlate\n",
    "    corr_tmp = sel.T.corr()\n",
    "    corr_tmp = corr_tmp.fillna(0).values\n",
    "\n",
    "    # Discard invalid series\n",
    "    #if len(corr_tmp):\n",
    "    corr_tmp = corr_tmp[keep,:][:,keep][corr_order,:][:,corr_order]\n",
    "    img = ax[row,col].matshow(corr_tmp, origin='lower', vmin=-0.8, vmax=1)\n",
    "    ax[row,col].xaxis.set_ticks_position('bottom')\n",
    "        \n",
    "    mx[key+(phase,)] = corr_tmp\n",
    "    ds[key+(phase,)] = np.ravel(corr_tmp+np.diag(np.nan*np.diag(corr_tmp)))\n",
    "    ax[row,col].set_title('%s, %s: %d'%(key,phase,count))\n",
    "pp.savefig(dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of the correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_rows = len(et.index)\n",
    "num_cols = num_phases\n",
    "\n",
    "fig, ax = plt.subplots(num_rows,num_cols, figsize=(5*num_cols,5*num_rows))\n",
    "fig.suptitle('Distribution of the above correlation coefficients\\n(diagonals excluded)',fontsize=16)\n",
    "#ax = np.ravel(ax)\n",
    "\n",
    "for row,col in itertools.product(range(0,num_rows),range(0,num_cols)):\n",
    "    key = et.index[row]\n",
    "    phase = la.phases[col]\n",
    "    count = et.ix[row]\n",
    "    col_sel = slice(int(phase_start[col]),int(phase_end[col]))\n",
    "    sel = ord1.loc[key+(slice(None),),col_sel]\n",
    "    print(key,phase,ord1.shape,sel.shape)\n",
    "\n",
    "    corr_tmp = mx[key+(phase,)]\n",
    "    corr_tmp = corr_tmp+np.diag(np.nan*np.diag(corr_tmp))\n",
    "    ax[row,col].hist(np.ravel(corr_tmp),range=(-1,1),bins=20)\n",
    "    ax[row,col].set_yscale('log')\n",
    "    ax[row,col].set_title('%s, %s: %d'%(key,phase,count))\n",
    "    \n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oraculum = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare correlation coefficient distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def describe_correlation(data, title, has_oraculum):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(12,16))\n",
    "    fig.suptitle(title,fontsize=16)\n",
    "    ax.axis('off')\n",
    "    if oraculum:\n",
    "        stat = np.round(data.describe(),4).T\n",
    "    else:\n",
    "        stat = np.round(data.stack(level=3).describe(),4).T\n",
    "    ordered = la.df_epoch(stat)\n",
    "    stat = stat.sort_index()\n",
    "    cw = np.ones((len(ordered.columns),))\n",
    "    tab = mpl.table.table(ax, cellText=ordered.values,\n",
    "             rowLabels=[', '.join(x) for x in ordered.index.values],\n",
    "             colLabels=ordered.columns.values.astype(str),\n",
    "             loc='upper right', fontsize=20, colWidths=0.6*cw/np.sum(cw),\n",
    "             bbox=[0.3,0,0.7,1], cellLoc='center')\n",
    "    return stat, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_correlation(stat, title, has_oraculum):\n",
    "    lmi = pd.DataFrame([], index=pd.Index(la.phases[0:num_phases],name='phase'),\n",
    "            columns = la.legal_conditions if oraculum else la.short_conditions).unstack().index\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(12,16))\n",
    "    fig.suptitle(title,fontsize=16)\n",
    "    ax.axis('off')\n",
    "    cellcolor = np.vectorize(lambda x: 'lightcoral' if x>0.5 else (\n",
    "                            'lightblue' if x<-0.4 else 'white'))\n",
    "    c = np.sqrt(stat.mean().loc['count'])\n",
    "    diff = []\n",
    "    for epoch1, epoch2 in [('Learning','Pre-Learning'),\n",
    "                           ('Post-Learning','Pre-Learning'),('Post-Learning','Learning')]:\n",
    "        d = (stat.loc[epoch1,'mean']-stat.loc[epoch2,'mean'])/(\n",
    "             stat.loc[epoch1,'std']+stat.loc[epoch2,'std'])*2\n",
    "        d = d.to_frame(name='  -  '.join((epoch1,epoch2)).replace('-Learning','-L'))\n",
    "        diff.append(d)\n",
    "    diff = np.round(pd.concat(diff,axis=1),4).reindex(lmi)\n",
    "    cw = np.ones((3,))\n",
    "    tab = mpl.table.table(ax, cellText=diff.values,\n",
    "             cellColours=cellcolor(diff.values),\n",
    "             rowLabels=[', '.join(x) for x in diff.index.values],\n",
    "             rowColours=np.repeat(la.legal_colors if oraculum else la.short_colors,num_phases),\n",
    "             colLabels=diff.columns.values.astype(str),\n",
    "             loc='upper right', fontsize=32, colWidths=0.6*cw/np.sum(cw),\n",
    "             bbox=[0.3,0,0.7,1], cellLoc='center')\n",
    "    tab.set_fontsize(32)\n",
    "    return diff, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_correlation_bars(stat, title, has_oraculum):\n",
    "    num_rows = num_phases\n",
    "    num_cols = len(la.epochs)\n",
    "    # We don't use sharex on purpose: we want to set different tick labels in the subplot columns\n",
    "    fig, ax = plt.subplots(num_rows,num_cols, figsize=(5*num_cols,5*num_rows), sharey=True)\n",
    "    fig.suptitle(title,fontsize=16)\n",
    "    cat = len(la.legal_conditions if has_oraculum else la.short_conditions)\n",
    "    bars = stat.reset_index().set_index(['phase']+la.sort_learning[0:(2 if has_oraculum else 3)])\n",
    "    for (irow,row), (icol,col) in itertools.product(enumerate(la.phases),enumerate(la.epochs)):\n",
    "        try:\n",
    "            bar = bars.loc[(row, col),:].reindex(la.legal_conditions if has_oraculum else la.short_conditions)\n",
    "            if has_oraculum:\n",
    "                lab = et.loc[col,:].reindex(la.legal_conditions, fill_value=0)\n",
    "            else:\n",
    "                lab = et.loc[col,:].sum(level=(0,1)).reindex(la.short_conditions, fill_value=0)\n",
    "            ax[irow,icol].set_title(col)\n",
    "            ax[irow,icol].set_ylabel(row)\n",
    "            low, high = [0]+bar['25%'].fillna(0).tolist(),[0]+bar['75%'].fillna(0).tolist()\n",
    "            ax[irow,icol].fill_between(np.arange(0,cat+1), low, high, alpha=0.1, interpolate=False, color='grey', edgecolor=None, step='pre')\n",
    "            ax[irow,icol].bar(range(0,cat),bar['mean'],1,yerr=bar['std'],color=la.legal_colors if has_oraculum else la.short_colors)\n",
    "            ax[irow,icol].set_xticks(np.arange(0,cat)+0.5)\n",
    "            if irow+1==num_rows:\n",
    "                labels = [('%s: %d'%(', '.join(idx),count['count'])) for idx,count in lab.iterrows()]\n",
    "            else:\n",
    "                labels = [count['count'] for idx,count in lab.iterrows()]\n",
    "            ax[irow,icol].set_xticklabels(labels, rotation='vertical')\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat, fig = describe_correlation(ds, 'Statistics on the correlation coefficients', oraculum)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "# count corresponds to the number of elemenets in the correlation matrix\n",
    "la.df_epoch(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff, fig = compare_correlation(stat, 'Difference of the above correlation coefficients\\n'+\n",
    "                 'in stdev. units', oraculum)\n",
    "pp.savefig()\n",
    "#plt.close(fig)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_correlation_bars(stat, 'Distribution of the above correlation coefficients\\n(diagonals excluded)', oraculum)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat, fig = describe_correlation(ds, 'Statistics on the absolut value\\nof the correlation coefficients', oraculum)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "# count corresponds to the number of elemenets in the correlation matrix\n",
    "la.df_epoch(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff, fig = compare_correlation(stat, 'Difference of the absolute value of the correlation coefficients\\n'+\n",
    "                 'in stdev. units', oraculum)\n",
    "pp.savefig()\n",
    "#plt.close(fig)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_correlation_bars(stat, 'Distribution of the absolute value of the correlation coefficients\\n(diagonals excluded)', oraculum)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity of correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_rows = len(et.index)\n",
    "num_cols = num_phases\n",
    "\n",
    "change = np.zeros((num_cols,num_rows,num_rows))\n",
    "for col in range(0,num_cols):\n",
    "    phase = la.phases[col]\n",
    "    for row1 in range(0,num_rows):\n",
    "        key1 = et.index[row1]\n",
    "        count1 = et.ix[row1]\n",
    "        for row2 in range(0,num_rows):\n",
    "            key2 = et.index[row2]\n",
    "            count2 = et.ix[row2]\n",
    "            change[col,row1,row2] = np.linalg.norm(np.ravel(mx[key1+(phase,)]-mx[key2+(phase,)])/np.size(mx[key2+(phase,)]),2)\n",
    "\n",
    "for col in range(0,num_cols):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "    fig.tight_layout(rect=[0.4,0,0.95,0.55])\n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.gca()\n",
    "    img = ax.matshow(change[col]+np.diag(np.nan*np.diag(change[col])), cmap=plt.get_cmap('rainbow'))\n",
    "\n",
    "    fig.suptitle('Difference between test cases (RMS distance)\\nPhase: '\n",
    "                 +la.phases[col],fontsize=16)\n",
    "    ax.set_xticks(np.array(range(0,len(et.index))))\n",
    "    ax.set_xticklabels(et.index.values.tolist(),rotation=90)\n",
    "    ax.set_yticks(np.array(range(0,len(et.index))))\n",
    "    ax.set_yticklabels(et.index.values.tolist())\n",
    "\n",
    "    # without set_yticks\n",
    "    # ax.set_yticklabels([tuple()]+et.index.values.tolist())\n",
    "    fig.colorbar(img)\n",
    "    pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
