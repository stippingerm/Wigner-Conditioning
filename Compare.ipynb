{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reqirements\n",
    "* #### You need to install module future, manual importing from \\_\\_future\\_\\_ is at your convenience\n",
    "* #### For hdf data import you need pytables too which is not default installed with Anaconda\n",
    "\n",
    "### Batch execution\n",
    "* #### ```batch_animal=msaxxyy_z jupyter nbconvert Stat.ipynb --to=html --execute --ExecutePreprocessor.timeout=-1 --output=xxyy_z_report.html```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from future.utils import PY3\n",
    "import future\n",
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, os, warnings, imp, itertools\n",
    "import IPython.display as disp\n",
    "display = disp.display\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "zscore, describe = stats.mstats.zscore, stats.describe\n",
    "import datetime\n",
    "dt, td = datetime.datetime, datetime.timedelta\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ca_lib as la\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "batch_animal = environ.get('batch_animal', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basedir = '../_share/Losonczi/'\n",
    "animals = ['msa0216_4','msa0316_1','msa0316_3','msa0316ag_1',\n",
    "           'msa0915_1','msa0915_2','msa1215_1']\n",
    "\n",
    "# Display database folders\n",
    "display(os.listdir(basedir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load files\n",
    "data = {}\n",
    "bayes = {}\n",
    "for animal in animals:\n",
    "    mydir = os.path.join(basedir,animal)\n",
    "    #data[animal] = la.read_from_hdf('anidb_'+animal+'.h5', la.Bunch())\n",
    "    bayes[animal] = la.read_from_hdf('baydb_'+animal+'.h5', la.Bunch())\n",
    "    #print (animal, data[animal].raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment protocol configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def settings_summary(data):\n",
    "    et_store, et_disp = [], []\n",
    "    for animal, db in data.iteritems():\n",
    "        et = db.et\n",
    "        et_disp.append(et.reset_index().set_index(la.display_learning))\n",
    "        et_store.append(et)\n",
    "    et_disp = pd.concat(et_disp,axis=1,names='animal').fillna('-')\n",
    "    et_store = pd.concat(et_store,axis=1,names='animal')\n",
    "    disp.display(disp.HTML('<font color=\"red\">ATTENTION, </font>for later conformity we store columns in a <b>different order</b>: %s !!!'%la.sort_learning))\n",
    "    display(la.df_epoch(et_disp))\n",
    "    return et_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et = settings_summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bayes_summary(data):\n",
    "    bt_store = []\n",
    "    for animal, db in data.iteritems():\n",
    "        bt = db.constellations\n",
    "        bt_store.append(bt)\n",
    "    bt_store = pd.concat(bt_store,axis=1,names='animal')\n",
    "    return bt_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bt = bayes_summary(bayes).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "lab = pd.DataFrame(bt.index.tolist(), columns=bt.index.names)\n",
    "for col in lab.columns:\n",
    "    lab[col]=lab[col].apply(lambda x: col if x else '')\n",
    "lab = lab.apply(lambda x: ' '.join(x).replace('  ',' '), axis=1).str.strip()\n",
    "lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bt2 = bt.copy()\n",
    "bt2.index=lab.values\n",
    "bt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging (integrating)\n",
    "Spiking is \"True\" in the [intervals) given in transients_data.hc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymean = pd.DataFrame.mean\n",
    "mystd = pd.DataFrame.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "class helpmultipage(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.isopen = False\n",
    "        self.open()\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "        \n",
    "    def savefig(self, dpi=None):\n",
    "        if self.isopen:\n",
    "            self.pp.savefig(dpi=dpi)\n",
    "\n",
    "    def open(self):\n",
    "        if (~self.isopen) and len(self.filename):\n",
    "            self.pp = PdfPages(self.filename)\n",
    "            self.isopen = True\n",
    "        \n",
    "    def close(self):\n",
    "        if self.isopen:\n",
    "            self.pp.close()\n",
    "        self.isopen = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanatory figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def explain_figures(data):\n",
    "    import matplotlib.patches as mpatches\n",
    "    from matplotlib.collections import PatchCollection\n",
    "    center = (data.event_frames[1:]+data.event_frames[:-1]) /2\n",
    "    left = data.event_frames\n",
    "    width = data.event_frames[1:]-data.event_frames[:-1]\n",
    "    vcenter = 0.0\n",
    "    vstart = -0.5\n",
    "\n",
    "    def label90(x,y,text):\n",
    "        ax.text(x, y, text, ha=\"center\", va=\"center\", family='sans-serif', size=14, rotation=90)\n",
    "\n",
    "    fig, (empty, ax) = plt.subplots(2,1,figsize=(6,8))\n",
    "    fig.suptitle('Explanatory figure',fontsize=16)\n",
    "    fig.tight_layout(pad=3)\n",
    "    empty.axis('off')\n",
    "    \n",
    "    ax.set_xlabel('Camera frame')\n",
    "    ax.set_ylabel('z-scored activity')\n",
    "    ax.set_ylim(vstart,vstart+1)\n",
    "    ax.plot(data.z_spike.mean(axis=0)+0.00, label=\"(CategoryA, True): #trials\", c=(1,1,0))\n",
    "    ax.plot(data.z_spike.mean(axis=0)+0.02, label=\"(CategoryB, True): #trials\", c=(.5,1,.5))\n",
    "    ax.plot(-data.z_spike.mean(axis=0)+0.00, label=\"(CategoryA, False): #trials\", c=(1,.8,1))\n",
    "    ax.plot(-data.z_spike.mean(axis=0)+0.02, label=\"(CategoryB, False): #trials\", c=(.5,1,1))\n",
    "    patches = []\n",
    "    # mark delay\n",
    "    label90(center[0], vcenter, 'excitation by\\nshowing water')\n",
    "    # mark CS\n",
    "    rect = mpatches.Rectangle((left[1],vstart), width[1], 1, ec=\"none\")\n",
    "    patches.append(rect)\n",
    "    label90(center[1], vcenter, 'CSÂ± if tone\\n\"Baseline\" otherwise')\n",
    "    # mark delay\n",
    "    label90(center[2], vcenter, 'trace = delay')\n",
    "    # mark UC\n",
    "    rect = mpatches.Rectangle((left[3],vstart), width[3], 1, ec=\"none\")\n",
    "    patches.append(rect)\n",
    "    label90(center[3], vcenter, 'UC if any')\n",
    "    # mark water\n",
    "    ax.text((left[0]+left[3])/2, vstart, \"water port present\\niff allowed to lick\",\n",
    "            ha=\"center\", va=\"bottom\", family='sans-serif', size=14, bbox=dict(boxstyle=\"DArrow\", pad=0.0, fc='c'))\n",
    "\n",
    "    # show event boundaries\n",
    "    for sep in data.event_frames[:-1]:\n",
    "        ax.axvline(x=sep, ymin=0.0, ymax = 1.0, linewidth=1, color='k')\n",
    "    colors = np.linspace(0, 1, len(patches))\n",
    "    collection = PatchCollection(patches, cmap=plt.cm.hsv, alpha=0.1)\n",
    "    collection.set_array(np.array(colors))\n",
    "    ax.add_collection(collection)\n",
    "\n",
    "    # align legend\n",
    "    leg = ax.legend(loc='lower center', title=\"Category name, Condition name\",\n",
    "                   bbox_to_anchor=(0.5, 1.1))\n",
    "    leg.get_title().set_fontsize('large')\n",
    "    leg.get_title().set_fontweight('bold')\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', UserWarning)\n",
    "        fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pp = helpmultipage('all_explanatory.pdf')\n",
    "fig = explain_figures(data.values[0])\n",
    "pp.savefig()\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learning_chart(data):\n",
    "    fig, ax = plt.subplots(len(data.trials),1,figsize=(10,0.6*len(data.trials)), sharex=True, sharey=True)\n",
    "    fig.tight_layout(h_pad=0.1)\n",
    "    ind = np.arange(0,5)\n",
    "    width, height, spacing = 1, 1.2, 10\n",
    "    label_df = data.experiment_traits.replace('Baseline','B.L.')\n",
    "    for i, trial in enumerate(data.trials):\n",
    "        pos = ind+2*spacing\n",
    "        unit = 2.0*data.lick_threshold\n",
    "        # need to use .values because integer colummn indices cause confusion\n",
    "        mea, err = data.lick_rate_mean.loc[trial].values/unit, data.lick_rate_std.loc[trial].values/unit\n",
    "        rects1 = ax[i].bar(pos, mea, width, color='r', yerr=err)\n",
    "        pos = ind+3*spacing\n",
    "        mea = data.lick_time_mean.loc[trial].values\n",
    "        rects2 = ax[i].bar(pos, mea, width, color='b')\n",
    "        pos = ind[0:2]+2.65*spacing\n",
    "        mea = 0.2 * np.array([len(data.lick_triggers_rise[trial]), len(data.spike_triggers_rise[trial])])\n",
    "        rects3 = ax[i].bar(pos, mea, width, color='g')\n",
    "        ax[i].set_xlim(xmin=0)\n",
    "        ax[i].set_ylim(ymin=0, ymax=height)\n",
    "        ax[i].set_yticks([0,0.5,1])\n",
    "        la.draw_conditions(ax[i],label_df,trial,data.FPS,loc='lower left',screen_width=0.5, height=height, cw=[0.25, 0.15, 0.15, 0.15, 0.15, 0.15],fontsize=12)\n",
    "    ax[-1].set_xticks([spacing, 2.2*spacing, 2.75*spacing, 3.2*spacing])\n",
    "    ax[-1].set_xticklabels(['Conditions', 'Licking rate', 'Lick rise, Pop. rise', 'Licking time'])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage('all_protocol.pdf')\n",
    "for animal in animals:\n",
    "    fig = learning_chart(data[animal])\n",
    "    fig.suptitle(animal)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population averages"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pp = helpmultipage(animal+'_pop.pdf')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "la.plot_data(data, [data.spike, data.filtered, data.lick],\n",
    "             ['Spiking', 'Ca-levels', 'Licking'])\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single criterion\n",
    "* comments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "grp = [['context'],['learning_epoch'],['port'],['puffed']]\n",
    "la.plot_data(data, [data.z_spike, data.z_filtered, data.lick], \n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(data, [data.zb_spike, data.zb_filtered, data.b_lick],\n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(data, [data.za_spike, data.za_filtered, data.a_lick],\n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two criteria\n",
    "* comments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = [['context','learning_epoch'],['context','port'],['context','puffed'],\n",
    "       ['learning_epoch','puffed'],['learning_epoch','port'],['port','puffed']]\n",
    "la.plot_data(data, [data.z_spike, data.z_filtered, data.lick], \n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(data, [data.zb_spike, data.zb_filtered, data.b_lick],\n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(data, [data.za_spike, data.za_filtered, data.a_lick],\n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three criteria\n",
    "* comments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = [['context','learning_epoch','port'],['context','learning_epoch','puffed'],\n",
    "       ['context','port','puffed'],['learning_epoch','port','puffed']]\n",
    "la.plot_data(data, [data.z_spike, data.z_filtered, data.lick], \n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_data(data, [data.zb_spike, data.zb_filtered, data.b_lick],\n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_data(data, [data.za_spike, data.za_filtered, data.a_lick],\n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All criteria\n",
    "* There is no increased population activity for CS+ without puffing. (For mouse 0216_4 the 1 trial with port displays increase during the trace period - why?)\n",
    "* During learning mouse 0216_4 shows incresed activity during the UC phase for CS-"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "grp = ['context','port','puffed']\n",
    "la.plot_epochs(data, [data.z_spike, data.z_filtered, data.lick], \n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity')\n",
    "pp.savefig()\n",
    "la.plot_epochs(data, [data.zb_spike, data.zb_filtered, data.b_lick],\n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity binned', div=bcenters)\n",
    "pp.savefig()\n",
    "la.plot_epochs(data, [data.za_spike, data.za_filtered, data.a_lick],\n",
    "             ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "             grp, title='Population activity averaged over events', div=acenters)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities conditional on epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_by_epoch(epoch):\n",
    "    experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "    spike_c = data.z_spike.reindex(experiment_c.index, level='time')\n",
    "    data_c = data.z_filtered.reindex(experiment_c.index, level='time')\n",
    "    raw_c = data.z_raw.reindex(experiment_c.index, level='time')\n",
    "    lick_c = data.lick.reindex(experiment_c.index)\n",
    "    print (experiment_c.shape, spike_c.shape)\n",
    "    spike_ca = la.pd_aggr_col(spike_c, mymean, asections, acenters)\n",
    "    data_ca = la.pd_aggr_col(data_c, mymean, asections, acenters)\n",
    "    raw_ca = la.pd_aggr_col(raw_c, mymean, asections, acenters)\n",
    "    lick_ca = la.pd_aggr_col(lick_c, mymean, asections, acenters)\n",
    "    print (spike_c.shape, spike_ca.shape)\n",
    "\n",
    "    grp = [['context','port'],['context','puffed'],['port','puffed']]\n",
    "    la.plot_data(data, [spike_c, data_c, lick_c],\n",
    "                 ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "                 grp, title=epoch)\n",
    "    pp.savefig()\n",
    "    la.plot_data(data, [spike_ca, data_ca, lick_ca],\n",
    "                 ['z-scored Spiking', 'z-scored Ca-levels', 'Licking'],\n",
    "                 grp, title=epoch+' averaged over events', div=acenters)\n",
    "    pp.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_by_epoch('Pre-Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_by_epoch('Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Learning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_by_epoch('Post-Learning')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity vector by phases"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def plot_activity_vectors(data, df, title, **kwarg):\n",
    "    # provide trial IDs by condition (non-unique index)\n",
    "    etmp = data.experiment_traits.reset_index(drop=True).set_index(la.sort_learning)\n",
    "\n",
    "    nplot = len(data.et.index)\n",
    "    ncol = 14\n",
    "    nrow = int(np.ceil(len(data.et.index)/float(ncol)))\n",
    "    \n",
    "    fig, ax = plt.subplots(nrow,ncol,figsize=(2*ncol,1+10*nrow),squeeze=False,sharey=True)\n",
    "    fig.tight_layout(pad=3, h_pad=3, rect=[0,0,1,0.8])\n",
    "    fig.suptitle(title,fontsize=16)\n",
    "    for i, cond in enumerate(data.et.index):\n",
    "        icol = i%ncol\n",
    "        irow = int((i-icol)/ncol)\n",
    "        sel = etmp.loc[cond,'timestr']\n",
    "        tmp = df.loc[sel.tolist(),aggr].unstack('time')\n",
    "        img = ax[irow,icol].matshow(tmp.values,origin='lower', **kwarg)\n",
    "        ax[irow,icol].xaxis.set_ticks_position('bottom')\n",
    "        ax[irow,icol].set_title('\\n'.join(cond))\n",
    "        ax[irow,icol].set_ylabel('Unit ID')\n",
    "        ax[irow,icol].set_xlabel('Trial')\n",
    "    #cax,kw = mpl.colorbar.make_axes([axis for axis in ax.flat])\n",
    "    cax = ax[-1,-1]\n",
    "    plt.colorbar(img,ax=cax)#ax=cax,**kw)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "pp = helpmultipage(animal+'_activation_sp.pdf')\n",
    "\n",
    "for p,aggr in enumerate(data.a_spike.columns):\n",
    "    title='Spikes, Phase: %s'%la.phases[p]\n",
    "    plot_activity_vectors(data, data.a_spike, title,vmin=0,vmax=1)\n",
    "    pp.savefig()\n",
    "\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pp = helpmultipage(animal+'_activation_ca.pdf')\n",
    "\n",
    "for p,aggr in enumerate(data.za_filtered.columns):\n",
    "    title = 'Ca-Signal, Phase: %s'%la.phases[p]\n",
    "    plot_activity_vectors(data, data.za_filtered, title, vmin=-3, vmax=3)\n",
    "    pp.savefig()    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of spiking\n",
    "The first 1 second of the recording seems missing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Triggers\n",
    "trig_list_data = [data.lick_triggers_rise, data.lick_triggers_fall,\n",
    "                  data.spike_triggers_rise, data.spike_triggers_fall]\n",
    "trig_list_sign = ['o', 's', '^', 'v']\n",
    "trig_list_color = ['b', 'y', 'r', 'g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_firing(ax, data, idx, settings, seismic=False, show_nan=False, pos=-20):\n",
    "    #experiment_id = settings['timestr']\n",
    "    fig.suptitle('%s: session %s, day %s\\n'%(idx,settings['session_num'],settings['day_num'])+\n",
    "                 ', '.join(la.sort_learning)+': #context in epoch, #day',fontsize=16)\n",
    "    if seismic:\n",
    "        la.draw_levels(ax, data.z_filtered, idx, data.FPS, data.roi_df)\n",
    "    else:\n",
    "        la.draw_transients(ax, data.transients, idx, data.FPS, data.roi_df)\n",
    "    if show_nan:\n",
    "        la.draw_spiking_nan(ax, data.spike, idx, data.rois.values)\n",
    "\n",
    "def draw_signals(ax, data, idx, settings, seismic=False, show_nan=False, pos=-20):\n",
    "    experiment_id = settings['timestr']\n",
    "    la.draw_population(ax, data.z_filtered, idx, pos=pos, c='y', label='population Ca-signal')\n",
    "    la.draw_population(ax, data.z_spike, idx, pos=pos, threshold=data.z_spike_threshold, label='population z-spike count')\n",
    "    la.draw_licking(ax, data.lick, idx, pos=pos-20, threshold=data.lick_threshold, label='licking')\n",
    "    la.draw_triggers(ax, trig_list_data, idx, -5, trig_list_sign, c=trig_list_color)\n",
    "    la.draw_conditions(ax, data.experiment_traits, experiment_id, data.FPS, height=20)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Show an example\n",
    "idx, settings = data.experiment_traits.index[9], data.experiment_traits.iloc[9,:]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "ax.set_ylim(ymin=-60,ymax=len(data.rois)+1)\n",
    "draw_firing(ax, data, idx, settings, True)\n",
    "draw_signals(ax, data, idx, settings, True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "# Show an example\n",
    "idx, settings = data.experiment_traits.index[9], data.experiment_traits.iloc[9,:]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "ax.set_ylim(ymin=-60,ymax=len(data.rois)+1)\n",
    "draw_firing(ax, data, idx, settings, False, True)\n",
    "draw_signals(ax, data, idx, settings, False, True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "pp = helpmultipage(animal+'_firing.pdf')\n",
    "\n",
    "xmax = data.transients.loc[:,['stop_frame']].max().values\n",
    "\n",
    "for idx, settings in data.experiment_traits.iterrows():\n",
    "    fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "    ax.set_xlim(xmax=xmax)\n",
    "    ax.set_ylim(ymin=-60,ymax=len(data.rois)+1)\n",
    "    draw_firing(ax, data, idx, settings)\n",
    "    draw_signals(ax, data, idx, settings)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern matching"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "prog_update = 1468579493\n",
    "print (\"%.0f\"%time.time())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pattdb_file = 'pattdb_'+animal+'.h5'\n",
    "if 'pattdb' in locals():\n",
    "    pattdb.close()\n",
    "    del pattdb\n",
    "if (not la.test_hdf(pattdb_file)) or (os.path.getmtime(pattdb_file)<prog_update):\n",
    "    with pd.HDFStore(pattdb_file, mode='w') as pattdb:\n",
    "        for method,sel in itertools.product(['match','correlate'],['sp','ca']):\n",
    "            print(method,sel)\n",
    "            df = data.spike if sel == 'sp' else data.z_filtered.reindex(data.mirow)\n",
    "            key = '/'.join((method,sel,'lick_rise_csp'))\n",
    "            pattdb[key] = la.search_pattern(df, data.lick_triggers_rise, data.trials,\n",
    "                                            data.FPS, trigger_allow=data.csp_triggers_allow)\n",
    "            key = '/'.join((method,sel,'lick_fall_csp'))\n",
    "            pattdb[key] = la.search_pattern(df, data.lick_triggers_fall, data.trials,\n",
    "                                            data.FPS, trigger_allow=data.csp_triggers_allow)\n",
    "            key = '/'.join((method,sel,'csp_rise'))\n",
    "            pattdb[key] = la.search_pattern(df, data.csp_triggers_rise, data.trials,\n",
    "                                            data.FPS, trigger_allow=data.csp_triggers_allow)\n",
    "            key = '/'.join((method,sel,'us_rise'))\n",
    "            pattdb[key] = la.search_pattern(df, data.us_triggers_rise, data.trials, data.FPS)\n",
    "pattdb = pd.HDFStore(pattdb_file, mode='r')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "data.z_patt = {}\n",
    "for key in pattdb.keys():\n",
    "    if key[0] == '/':\n",
    "        key = key[1:]\n",
    "    data.z_patt[key] = la.nan_zscore(pattdb[key])\n",
    "pattdb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def show_detections(ax, z_patt, method, sel, idx, ids, names, colors):\n",
    "    threshold = [-3, 3]\n",
    "    zoom = 3\n",
    "    for i, id1 in enumerate(ids):\n",
    "        la.draw_licking(ax, z_patt['/'.join((method,sel,id1))], idx, pos=-20, c=colors[i],\n",
    "                threshold=threshold, zoom=zoom, label='%s: %s'%(sel, names[i]))\n",
    "        threshold = None\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "# Show an example\n",
    "method = 'match' # 'match', 'correlate'\n",
    "sel = 'ca' # 'ca', 'sp'\n",
    "idx, settings = data.experiment_traits.index[13], data.experiment_traits.iloc[13,:]\n",
    "fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "ax.set_ylim(ymin=-80,ymax=len(data.rois)+1)\n",
    "draw_firing(ax, data, idx, settings, False, True, pos=-40)\n",
    "show_detections(ax, data.z_patt, method, sel, idx, ['lick_rise_csp','lick_fall_csp','csp_rise','us_rise'],\n",
    "                ['CS+ lick start', 'CS+ lick end', 'CS+ start', 'US start'], ['g', 'c', 'orange', 'r'])\n",
    "draw_signals(ax, data, idx, settings, False, True, pos=-40)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for method,sel in itertools.product(['match','correlate'], ['sp','ca']):\n",
    "    print (method,sel)\n",
    "\n",
    "    pp = helpmultipage(animal+'_triggers_%s_%s.pdf'%(method,sel))\n",
    "    zoom = 4\n",
    "\n",
    "    xmax = data.transients.loc[:,['stop_frame']].max().values\n",
    "\n",
    "    for idx, settings in data.experiment_traits.iterrows(): #et3.iterrows():\n",
    "        fig, ax = plt.subplots(1,1,figsize=(16,10))\n",
    "        ax.set_xlim(xmax=xmax)\n",
    "        ax.set_ylim(ymin=-80,ymax=len(data.rois)+1)\n",
    "        draw_firing(ax, data, idx, settings, False, True, pos=-40)\n",
    "        show_detections(ax, data.z_patt, method, sel, idx, ['lick_rise_csp','lick_fall_csp','csp_rise','us_rise'],\n",
    "                ['CS+ lick start', 'CS+ lick end', 'CS+ start', 'US start'], ['g', 'c', 'orange', 'r'])\n",
    "        draw_signals(ax, data, idx, settings, False, True, pos=-40)\n",
    "        ax.legend()\n",
    "        pp.savefig()\n",
    "        plt.close(fig)\n",
    "\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peri-event plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matlab_tools as mt\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_peri_3a(df, title=None):\n",
    "    '''Plot collection: CS+ US'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    ret.append([df, data.rois, lick_triggers_rise, None, None, 'Lick rise'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, None, None, 'Lick fall'])\n",
    "    ret.append([df, data.rois, lick_triggers_rise, csp_triggers_allow, None, 'Lick rise CS+'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, csp_triggers_allow, None, 'Lick fall CS+'])\n",
    "    ret.append([df, data.rois, csp_triggers_rise, None, None, 'CS+ start'])\n",
    "    ret.append([df, data.rois, csp_triggers_fall, None, None, 'CS+ end'])\n",
    "    ret.append([df, data.rois, lick_triggers_rise, us_triggers_allow, None, 'Lick rise US'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, us_triggers_allow, None, 'Lick fall US'])\n",
    "    ret.append([df, data.rois, us_triggers_rise, None, None, 'US start'])\n",
    "    ret.append([df, data.rois, us_triggers_fall, None, None, 'US end'])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_peri_3b(df, title=None):\n",
    "    '''Plot collection: CS+ US'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    ret.append([df, data.rois, lick_triggers_rise, None, None, 'Lick rise'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, None, None, 'Lick fall'])\n",
    "    ret.append([df, data.rois, lick_triggers_rise, csp_triggers_allow, None, 'Lick rise CS+'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, csp_triggers_allow, None, 'Lick fall CS+'])\n",
    "    ret.append([df, data.rois, csp_triggers_rise, None, None, 'CS+ start'])\n",
    "    ret.append([df, data.rois, csp_triggers_fall, None, None, 'CS+ end'])\n",
    "    ret.append([df, data.rois, lick_triggers_rise, csm_triggers_allow, None, 'Lick rise CS-'])\n",
    "    ret.append([df, data.rois, lick_triggers_fall, csm_triggers_allow, None, 'Lick fall CS-'])\n",
    "    ret.append([df, data.rois, csm_triggers_rise, None, None, 'CS- start'])\n",
    "    ret.append([df, data.rois, csm_triggers_fall, None, None, 'CS- end'])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_peri_1a(data, df, title=None):\n",
    "    '''Plot collection: Lick'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].lick_triggers_rise, None, None, '%s\\nLick rise'%animal])\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].lick_triggers_fall, None, None, '%s\\nLick fall'%animal])\n",
    "    return ret\n",
    "def list_peri_1b(data, df, title=None):\n",
    "    '''Plot collection: Lick CS+'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].lick_triggers_rise, data[animal].csp_triggers_allow, None, '%s\\nLick rise CS+'%animal])\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].lick_triggers_fall, data[animal].csp_triggers_allow, None, '%s\\nLick fall CS+'%animal])\n",
    "    return ret\n",
    "def list_peri_1c(data, df, title=None):\n",
    "    '''Plot collection: Lick CS-'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].lick_triggers_rise, data[animal].csm_triggers_allow, None, '%s\\nLick rise CS-'%animal])\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].lick_triggers_fall, data[animal].csm_triggers_allow, None, '%s\\nLick fall CS-'%animal])\n",
    "    return ret\n",
    "def list_peri_1d(data, df, title=None):\n",
    "    '''Plot collection: CS+'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].csp_triggers_rise, None, None, '%s\\nCS+ start'%animal])\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].csp_triggers_fall, None, None, '%s\\nCS+ end'%animal])\n",
    "    return ret\n",
    "def list_peri_1e(data, df, title=None):\n",
    "    '''Plot collection: CS-'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].csm_triggers_rise, None, None, '%s\\nCS- start'%animal])\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].csm_triggers_fall, None, None, '%s\\nCS- end'%animal])\n",
    "    return ret\n",
    "def list_peri_1f(data, df, title=None):\n",
    "    '''Plot collection: US'''\n",
    "    ret = [] # df, trig, allow, disable, title\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].us_triggers_rise, None, None, '%s\\nUS start'%animal])\n",
    "    for animal in animals:\n",
    "        ret.append([data[animal][df], data[animal].rois, data[animal].us_triggers_fall, None, None, '%s\\nUS end'%animal])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num_rois = 0\n",
    "for animal in animals:\n",
    "    num_rois = np.max((num_rois, len(data[animal].rois)))\n",
    "print (num_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rois = 250\n",
    "peri_range=(-16,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show an example\n",
    "fig=la.plot_peri_collection(list_peri_1a(data, 'spike'),'Spiking',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage('all_peri1.pdf')\n",
    "#experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "#spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "#data_c = z_filtered.reindex(experiment_c.index, level='time')\n",
    "fig=la.plot_peri_collection(list_peri_1a(data, 'spike'),'Spiking on Lick',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1b(data, 'spike'),'Spiking on Lick CS+',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1c(data, 'spike'),'Spiking on Lick CS-',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1d(data, 'spike'),'Spiking on CS+',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1e(data, 'spike'),'Spiking on CS-',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1f(data, 'spike'),'Spiking on US',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1a(data, 'z_filtered'),'z-scored Ca-level on Lick',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1b(data, 'z_filtered'),'z-scored Ca-level on Lick CS+',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1c(data, 'z_filtered'),'z-scored Ca-level on Lick CS-',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1d(data, 'z_filtered'),'z-scored Ca-level on CS+',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1e(data, 'z_filtered'),'z-scored Ca-level on CS-',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1f(data, 'z_filtered'),'z-scored Ca-level on US',peri_range,combine=False)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage('all_peri2.pdf')\n",
    "#experiment_c = data.experiment_traits[data.experiment_traits.loc[:,'learning_epoch']==epoch]\n",
    "#spike_c = df_spike.reindex(experiment_c.index, level='time')\n",
    "#data_c = z_filtered.reindex(experiment_c.index, level='time')\n",
    "fig=la.plot_peri_collection(list_peri_1a(data, 'spike'),'Spiking on Lick',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1b(data, 'spike'),'Spiking on Lick CS+',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1c(data, 'spike'),'Spiking on Lick CS-',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1d(data, 'spike'),'Spiking on CS+',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1e(data, 'spike'),'Spiking on CS-',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1f(data, 'spike'),'Spiking on US',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1a(data, 'z_filtered'),'z-scored Ca-level on Lick',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1b(data, 'z_filtered'),'z-scored Ca-level on Lick CS+',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1c(data, 'z_filtered'),'z-scored Ca-level on Lick CS-',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1d(data, 'z_filtered'),'z-scored Ca-level on CS+',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1e(data, 'z_filtered'),'z-scored Ca-level on CS-',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "fig=la.plot_peri_collection(list_peri_1f(data, 'z_filtered'),'z-scored Ca-level on US',peri_range)\n",
    "fig.gca().set_ylim(ymax=num_rois)\n",
    "pp.savefig()\n",
    "plt.close(fig)\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual ROIs\n",
    "* since there are many of them, save figure to pdf\n",
    "* THIS WILL <font color=\"red\">TAKE A WHILE</font>, consider testing with a small range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roi(filename, data, dfs, names, grp, title_template, by_epoch=False, div=None, fill=None):\n",
    "    pp = PdfPages(filename)\n",
    "    for i in range(0,len(data.rois)):\n",
    "        dfc = []\n",
    "        for df in dfs:\n",
    "            dfc.append(df.loc[(slice(None),data.rois[i]),:])\n",
    "        if by_epoch:\n",
    "            fig = la.plot_epochs(data, dfc, names, grp, title=title_template%(i,data.rois[i]), div=div, fill=fill)\n",
    "        else:\n",
    "            fig = la.plot_data(data, dfc, names, grp, title=title_template%(i,data.rois[i]), div=div, fill=fill)\n",
    "        pp.savefig()\n",
    "        plt.close(fig)\n",
    "    pp.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if batch_animal is None:\n",
    "    raise ValueError(\"You don't want to run this automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_roi(animal+'_roi1crit.pdf', data, [data.spike, data.filtered],\n",
    "         ['Spiking', 'Ca-level'], [['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(animal+'_roi2crit.pdf', data, [data.spike, data.filtered],\n",
    "         ['Spiking', 'Ca-level'], [['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "plot_roi(animal+'_roiAcrit.pdf', data, [data.spike, data.filtered],\n",
    "         ['Spiking', 'Ca-level'], ['context','port','puffed'],'ROI %d:\\n%s',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging over intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intervals aligned to events"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "plot_roi(animal+'_avg1crit.pdf', data, [data.a_spike, data.a_data],\n",
    "         ['Spiking', 'Ca-level'], [['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s',div=acenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(animal+'_avg2crit.pdf', data, [data.a_spike, data.a_data],\n",
    "         ['Spiking', 'Ca-level'], [['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s',div=acenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_roi(animal+'_avgAcrit.pdf', data, [data.a_spike, data.a_data],\n",
    "         ['Spiking', 'Ca-level'], ['context','port','puffed'],'ROI %d:\\n%s',True,div=acenters, fill='err')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging over bins"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_roi(animal+'_bin1crit.pdf', data, [data.b_spike, data.b_data],\n",
    "         ['Spiking', 'Ca-level'], [['context'],['learning_epoch'],['port'],['puffed']],'ROI %d:\\n%s',div=bcenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_roi(animal+'_bn2crit.pdf', data, [data.b_spike, data.b_data],\n",
    "         ['Spiking', 'Ca-level'], [['learning_epoch','context'],['learning_epoch','port'],['learning_epoch','puffed'],['context','port'],['context','puffed'],['port','puffed']],'ROI %d:\\n%s',div=bcenters)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plot_roi(animal+'_binAcrit.pdf', data, [data.b_spike, data.b_data],\n",
    "         ['Spiking', 'Ca-level'], ['context','port','puffed'],'ROI %d:\\n%s',True,div=acenters, fill='err')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Whether to average trials (assuming identical timing) or rather concatenate them\n",
    "concatenate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_for_correlation(df, data):\n",
    "    # Combine information\n",
    "    ordered = df.reindex(data.mirow, data.icol)\n",
    "    et1 = data.experiment_traits[data.experiment_traits.loc[:,'session_num']>=0]\n",
    "    et1 = et1.loc[:,la.sort_learning+['day_num','session_num']]\n",
    "    ordered = ordered.join(et1, how='inner').reset_index().drop('time', axis=1) # keep roi_id\n",
    "    ordered = ordered.set_index(la.sort_learning+['roi_id', 'session_num']).sort_index()\n",
    "    ordered.columns.name='Spike'\n",
    "    #display(ordered.head())\n",
    "\n",
    "    # Search for days that contain experiments with same traits and session_num\n",
    "    # These entries would jeopardize unstacking\n",
    "    et2 = et1.reset_index(drop=True).set_index(la.sort_learning+['session_num']).sort_index()\n",
    "    second_occur = et2.index.duplicated()\n",
    "    set_second = et2.loc[second_occur,'day_num'].unique()\n",
    "    all_occur = et2.index.get_duplicates()\n",
    "    set_all = et2.loc[all_occur,'day_num'].unique()\n",
    "    set_first = np.array(list(set(set_all)-set(set_second)))\n",
    "    print('Days repeating settings: %s, all conflicted: %s, to be kept: %s'%\n",
    "          (set_second,set_all,set_first))\n",
    "\n",
    "    # Filter out second occurrences stored in set2\n",
    "    if len(set_first):\n",
    "        ordered = ordered[ordered.loc[:,'day_num'].apply(lambda x: x not in set_first)]\n",
    "    print('Filtered data:',ordered.shape)\n",
    "\n",
    "    # Reshape for correlation analysis\n",
    "    # integer values get converted to float if needed to hold NaN-s\n",
    "    calendar = ordered['day_num'].unstack(fill_value=0)\n",
    "    ordered = ordered.drop(['day_num'], axis=1).unstack()\n",
    "    print('Concatenated data:',ordered.shape)\n",
    "    return ordered, calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_for_correlation(df, data):\n",
    "    # Combine information\n",
    "    ordered = df.reindex(data.mirow, data.icol)\n",
    "    et1 = data.experiment_traits[data.experiment_traits.loc[:,'session_num']>=0]\n",
    "    et1 = et1.loc[:,la.sort_learning+['day_num','session_num']]\n",
    "    ordered = ordered.join(et1, how='inner').reset_index().drop('time', axis=1) # keep roi_id\n",
    "    ordered = ordered.set_index(la.sort_learning+['roi_id', 'session_num']).sort_index()\n",
    "    ordered.columns.name='Spike'\n",
    "    #display(ordered.head())\n",
    "\n",
    "    # Reshape for correlation analysis\n",
    "    # integer values get converted to float if needed to hold NaN-s\n",
    "    calendar = ordered['day_num'].unstack(fill_value=0)\n",
    "    avg_labels = list(ordered.index.names)\n",
    "    avg_labels.remove('session_num')\n",
    "    print (avg_labels)\n",
    "    ordered = ordered.drop(['day_num'], axis=1).mean(level=avg_labels)\n",
    "    compatibility_index_level =  pd.Index([1], name='session_num')\n",
    "    ordered.columns = pd.MultiIndex.from_product((ordered.columns, compatibility_index_level),\n",
    "                                              names=(ordered.columns.name,compatibility_index_level.name))\n",
    "    print('Averaged data:',ordered.shape)\n",
    "    return ordered, calendar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for animal in animals:\n",
    "    data[animal][ord1], data[animal].calendar = concat_for_correlation(data[animal].z_filtered, data[animal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if concatenate:\n",
    "    ord1 = 'ord_correl'\n",
    "    corr_method = 'concatenated'\n",
    "else:\n",
    "    ord1 = 'ord_tr_avg'\n",
    "    corr_method = 'trial-averaged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set a reference for ordering elements in the matrix\n",
    "\n",
    "for animal in animals:\n",
    "    key_ref = data[animal].key_ref # default ('Post-Learning','CS+','W+','A+')\n",
    "    FPS = data[animal].FPS\n",
    "    time_ref = np.array([15, 40])\n",
    "    #data[animal].col_ref = slice(int(time_ref[0]*FPS),int(time_ref[1]*FPS))\n",
    "    sel = data[animal][ord1].loc[data[animal].key_ref+(slice(None),),data[animal].col_ref]\n",
    "    print(key_ref,time_ref,data[animal].col_ref,sel.shape)\n",
    "\n",
    "    # Correlate\n",
    "    corr_df = sel.T.corr()\n",
    "    corr_np = data[animal].corr_np\n",
    "\n",
    "    # Discard invalid series\n",
    "    #data[animal].keep = (np.diag(corr_np) == 1.0)\n",
    "    #data[animal].corr_np = corr_np[data[animal].keep,:][:,data[animal].keep]\n",
    "\n",
    "    # Show\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "    img = ax[0].matshow(corr_df.values)\n",
    "    img = ax[1].matshow(corr_np)\n",
    "    fig.colorbar(img, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage('all_correl_'+corr_method+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define an ordering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "for animal in animals:\n",
    "    sq_dist = squareform(1.0-data[animal].corr_np)\n",
    "    corr_link = linkage(sq_dist, 'average')\n",
    "    sel = data[animal][ord1].loc[data[animal].key_ref+(slice(None),),data[animal].col_ref]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(18,8))\n",
    "    fig.suptitle('Reference for '+animal+' is presented here: '+(', '.join(np.array(key_ref)))+\n",
    "                ' and time '+('..'.join(time_ref.astype(str)))+'s',fontsize=16)\n",
    "    labels = sel.index.get_level_values(4).to_series().reset_index(drop=True)[data[animal].keep]\n",
    "    dendo = dendrogram(corr_link, ax=ax[1], labels=labels.values, leaf_font_size=2.5, orientation='left')\n",
    "    ax[1].set_title('Distance of firing patterns')\n",
    "    #data[animal].corr_order = dendo['leaves']\n",
    "    # Show reordered\n",
    "    img = ax[0].matshow(data[animal].corr_np[data[animal].corr_order,:][:,data[animal].corr_order], origin='lower', vmin=-0.8, vmax=1)\n",
    "    ax[0].xaxis.set_ticks_position('bottom')\n",
    "    ax[0].set_title('Ordered correlation matrix', y=1.0)\n",
    "    fig.colorbar(img)\n",
    "    pp.savefig(dpi=600)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calculate under different conditions\n",
    "phase_start = data.event_frames+data.FPS\n",
    "phase_end = data.event_frames[1:]-data.FPS\n",
    "\n",
    "data.mx = {}\n",
    "data.mi = pd.DataFrame([], index = la.phases, columns = data.et.index).unstack().index\n",
    "data.ds = pd.DataFrame(columns = data.mi)\n",
    "\n",
    "keep = data.keep\n",
    "corr_order = data.corr_order\n",
    "\n",
    "for (irow,key),(icol,phase) in itertools.product(enumerate(data.et.index),enumerate(la.phases)):\n",
    "    # Find the pre-learning structure\n",
    "    col_sel = slice(int(phase_start[icol]),int(phase_end[icol]))\n",
    "    try:\n",
    "        sel = data[ord1].loc[key+(slice(None),),col_sel]\n",
    "        #print(key,phase,data[ord1].shape,sel.shape)\n",
    "\n",
    "        # Correlate\n",
    "        corr_tmp = sel.T.corr()\n",
    "        corr_tmp = corr_tmp.fillna(0).values\n",
    "    except KeyError:\n",
    "        corr_tmp = []\n",
    "\n",
    "    # Discard invalid series\n",
    "    if len(corr_tmp):\n",
    "        corr_tmp = corr_tmp[keep,:][:,keep][corr_order,:][:,corr_order]\n",
    "    else:\n",
    "        corr_tmp = np.nan * np.ones((len(corr_order),len(corr_order)))\n",
    "\n",
    "    data.mx[key+(phase,)] = corr_tmp\n",
    "    data.ds[key+(phase,)] = np.ravel(corr_tmp+np.diag(np.nan*np.diag(corr_tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show under different conditions\n",
    "num_phases = 3\n",
    "num_rows = len(et.index)\n",
    "num_cols = num_phases\n",
    "\n",
    "for animal in animals:\n",
    "    print (animal)\n",
    "    phase_start = data[animal].event_frames+data[animal].FPS\n",
    "    phase_end = data[animal].event_frames[1:]-data[animal].FPS\n",
    "\n",
    "    fig, ax = plt.subplots(num_rows,num_cols, figsize=(5*num_cols,5*num_rows))\n",
    "    fig.suptitle('Correlation structure under different conditions: learning_epoch, context, port, puffed\\n'+\n",
    "                 '(small number of trials might lead to larger percieved correlation)\\n'+\n",
    "                 '(in phases Ready, CS, Trace the conditions A+ and A- should be very similar)',fontsize=16)\n",
    "    #ax = np.ravel(ax)\n",
    "\n",
    "    keep = data[animal].keep\n",
    "    corr_order = data[animal].corr_order\n",
    "\n",
    "    for (irow,key),(icol,phase) in itertools.product(enumerate(et.index),enumerate(la.phases[:num_cols])):\n",
    "        # Find the pre-learning structure\n",
    "        count = np.nan_to_num(et.loc[key,animal])\n",
    "        try:\n",
    "            corr_tmp = data[animal].mx[key+(phase,)]\n",
    "        except KeyError:\n",
    "            corr_tmp = []\n",
    "\n",
    "        # Discard invalid series\n",
    "        if len(corr_tmp):\n",
    "            img = ax[irow,icol].matshow(corr_tmp, origin='lower', vmin=-0.8, vmax=1)\n",
    "        ax[irow,icol].xaxis.set_ticks_position('bottom')\n",
    "        ax[irow,icol].set_title('%s, %s: %d'%(key,phase,count))\n",
    "    pp.savefig(dpi=600)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of the correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_rows = len(et.index)\n",
    "num_cols = num_phases\n",
    "\n",
    "for animal in animals:\n",
    "    print (animal)\n",
    "\n",
    "    fig, ax = plt.subplots(num_rows,num_cols, figsize=(5*num_cols,5*num_rows))\n",
    "    fig.suptitle('Distribution of the above correlation coefficients\\n'+\n",
    "                 'for '+animal+' (diagonals excluded)',fontsize=16)\n",
    "    #ax = np.ravel(ax)\n",
    "\n",
    "    for (irow,key),(icol,phase) in itertools.product(enumerate(et.index),enumerate(la.phases[:num_cols])):\n",
    "        count = np.nan_to_num(et.loc[key,animal])\n",
    "        try:\n",
    "            corr_tmp = data[animal].mx[key+(phase,)]\n",
    "            corr_tmp = corr_tmp+np.diag(np.nan*np.diag(corr_tmp))\n",
    "        except KeyError:\n",
    "            corr_tmp = []\n",
    "            \n",
    "        if len(corr_tmp) and np.sum(corr_tmp>-1.0):\n",
    "            ax[irow,icol].hist(np.ravel(corr_tmp),range=(-1,1),bins=20)\n",
    "            ax[irow,icol].set_yscale('log')\n",
    "        ax[irow,icol].set_title('%s, %s: %d'%(key,phase,count))\n",
    "\n",
    "    pp.savefig()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oraculum = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare correlation coefficient distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def describe_correlation(data, title, has_oraculum):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(12,16))\n",
    "    fig.suptitle(title,fontsize=16)\n",
    "    ax.axis('off')\n",
    "    if oraculum:\n",
    "        stat = np.round(data.describe(),4).T\n",
    "    else:\n",
    "        stat = np.round(data.stack(level=3).describe(),4).T\n",
    "    ordered = la.df_epoch(stat)\n",
    "    stat = stat.sort_index()\n",
    "    cw = np.ones((len(ordered.columns),))\n",
    "    tab = mpl.table.table(ax, cellText=ordered.values,\n",
    "             rowLabels=[', '.join(x) for x in ordered.index.values],\n",
    "             colLabels=ordered.columns.values.astype(str),\n",
    "             loc='upper right', fontsize=20, colWidths=0.6*cw/np.sum(cw),\n",
    "             bbox=[0.3,0,0.7,1], cellLoc='center')\n",
    "    return stat, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_correlation(stat, title, has_oraculum):\n",
    "    lmi = pd.DataFrame([], index=la.phases[0:num_phases],\n",
    "            columns = la.legal_conditions if oraculum else la.short_conditions).unstack().index\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(12,16))\n",
    "    fig.suptitle(title,fontsize=16)\n",
    "    ax.axis('off')\n",
    "    cellcolor = np.vectorize(lambda x: 'lightcoral' if x>0.5 else (\n",
    "                            'lightblue' if x<-0.4 else 'white'))\n",
    "    c = np.sqrt(stat.mean().loc['count'])\n",
    "    diff = []\n",
    "    for epoch1, epoch2 in [('Learning','Pre-Learning'),\n",
    "                           ('Post-Learning','Pre-Learning'),('Post-Learning','Learning')]:\n",
    "        try:\n",
    "            d = (stat.loc[epoch1,'mean']-stat.loc[epoch2,'mean'])/(\n",
    "                 stat.loc[epoch1,'std']+stat.loc[epoch2,'std'])*2\n",
    "        except KeyError:\n",
    "            d = pd.Series([]).reindex(index=lmi)\n",
    "        d = d.to_frame(name='  -  '.join((epoch1,epoch2)).replace('-Learning','-L'))\n",
    "        diff.append(d)\n",
    "    diff = np.round(pd.concat(diff,axis=1),4).reindex(lmi)\n",
    "    cw = np.ones((3,))\n",
    "    tab = mpl.table.table(ax, cellText=diff.values,\n",
    "             cellColours=cellcolor(diff.values),\n",
    "             rowLabels=[', '.join(x) for x in diff.index.values],\n",
    "             rowColours=np.repeat(la.legal_colors if oraculum else la.short_colors,num_phases),\n",
    "             colLabels=diff.columns.values.astype(str),\n",
    "             loc='upper right', fontsize=32, colWidths=0.6*cw/np.sum(cw),\n",
    "             bbox=[0.3,0,0.7,1], cellLoc='center')\n",
    "    tab.set_fontsize(32)\n",
    "    return diff, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_correlation_bars(stat, title, et, has_oraculum):\n",
    "    num_rows = num_phases\n",
    "    num_cols = len(la.epochs)\n",
    "    # We don't use sharex on purpose: we want to set different tick labels in the subplot columns\n",
    "    fig, ax = plt.subplots(num_rows, num_cols, figsize=(5*num_cols,5*num_rows), sharey=True)\n",
    "    fig.suptitle(title,fontsize=16)\n",
    "    cat = len(la.legal_conditions if has_oraculum else la.short_conditions)\n",
    "    bars = stat.reset_index().set_index(['phase']+la.sort_learning[0:(4 if has_oraculum else 3)])\n",
    "    for (irow,phase), (icol,epoch) in itertools.product(enumerate(la.phases[:num_phases]),enumerate(la.epochs)):\n",
    "        try:\n",
    "            bar = bars.loc[(phase, epoch),:].reindex(la.legal_conditions if has_oraculum else la.short_conditions)\n",
    "            if has_oraculum:\n",
    "                lab = et.loc[epoch].reindex(la.legal_conditions, fill_value=0)\n",
    "            else:\n",
    "                lab = et.loc[epoch].sum(level=('context','port')).reindex(la.short_conditions, fill_value=0)\n",
    "            ax[irow,icol].set_title(epoch)\n",
    "            ax[irow,icol].set_ylabel(phase)\n",
    "            low, high = [0]+bar['25%'].fillna(0).tolist(),[0]+bar['75%'].fillna(0).tolist()\n",
    "            ax[irow,icol].fill_between(np.arange(0,cat+1), low, high, alpha=0.1, interpolate=False, color='grey', edgecolor=None, step='pre')\n",
    "            ax[irow,icol].bar(range(0,cat),bar['mean'],1,yerr=bar['std'],color=la.legal_colors if has_oraculum else la.short_colors)\n",
    "            ax[irow,icol].set_xticks(np.arange(0,cat)+0.5)\n",
    "            if irow+1==num_rows:\n",
    "                labels = [('%s: %d'%(', '.join(idx),np.nan_to_num(count))) for idx,count in lab.iteritems()]\n",
    "            else:\n",
    "                labels = ['%d'%np.nan_to_num(count) for idx,count in lab.iteritems()]\n",
    "            ax[irow,icol].set_xticklabels(labels, rotation='vertical')\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for animal in animals:\n",
    "    stat1, fig = describe_correlation(data[animal].ds, 'Statistics on the correlation coefficients', oraculum)\n",
    "    #pp.savefig()\n",
    "    plt.close(fig)\n",
    "    # count corresponds to the number of elemenets in the correlation matrix\n",
    "    #display(la.df_epoch(data[animal].stat))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for animal in animals:\n",
    "    diff1, fig = compare_correlation(data[animal].stat, 'Difference of the above correlation coefficients\\n'+\n",
    "                     'in stdev. units', oraculum)\n",
    "    #pp.savefig()\n",
    "    plt.close(fig)\n",
    "    #display(data[animal].diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for animal in animals:\n",
    "    plot_correlation_bars(data[animal].stat, 'Distribution of the above coefficients\\n'\n",
    "                          'for '+animal+' (diagonals excluded)', et.loc[:,animal], oraculum)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for animal in animals:\n",
    "    data[animal].astat, fig = describe_correlation(np.abs(data[animal].ds), 'Statistics on the absolut value\\nof the correlation coefficients', oraculum)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    # count corresponds to the number of elemenets in the correlation matrix\n",
    "    #display(la.df_epoch(stat))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for animal in animals:\n",
    "    data[animal].adiff, fig = compare_correlation(data[animal].astat, 'Difference of the absolute value of the correlation coefficients\\n'+\n",
    "                     'in stdev. units', oraculum)\n",
    "    pp.savefig()\n",
    "    plt.close(fig)\n",
    "    #display(data[animal].adiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for animal in animals:\n",
    "    plot_correlation_bars(data[animal].astat, 'Distribution of the absolute value of the correlation coefficients\\n'\n",
    "                          'for '+animal+'(diagonals excluded)', et.loc[:,animal], oraculum)\n",
    "    pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_conditions = 2\n",
    "list_conditions = [('CS+','W+','A+'),('CS-','W+','A-')]\n",
    "num_kinds = 2\n",
    "list_kinds = ['stat', 'astat']\n",
    "name_kinds = ['real value', 'absolute value']\n",
    "def plot_correlation_comparison(data, phase, title, has_oraculum):\n",
    "    num_rows = num_conditions\n",
    "    num_cols = num_kinds\n",
    "    fig, ax = plt.subplots(num_rows,num_cols, figsize=(5*num_cols,5*num_rows), sharex=True, sharey=True)\n",
    "    fig.suptitle(title,fontsize=16)\n",
    "    #cat = len(la.legal_conditions if has_oraculum else la.short_conditions)\n",
    "    #bars = stat.reset_index().set_index(['phase']+la.sort_learning[0:(4 if has_oraculum else 3)])\n",
    "    cat = np.array([1,2,3])\n",
    "    for (irow,cond), (icol,kind) in itertools.product(enumerate(list_conditions),enumerate(list_kinds)):\n",
    "        mean, std = [], []\n",
    "        for iani, animal in enumerate(animals):\n",
    "            try:\n",
    "                m = data[animal][kind].loc[(slice(None),)+cond+(phase,),'mean']\n",
    "                s = data[animal][kind].loc[(slice(None),)+cond+(phase,),'std']\n",
    "                m = m.reset_index(['context','port','puffed','phase'],drop=True).reindex(la.epochs)\n",
    "                s = s.reset_index(['context','port','puffed','phase'],drop=True).reindex(la.epochs)\n",
    "                ax[irow,icol].set_title(name_kinds[icol])\n",
    "                ax[irow,icol].set_ylabel(', '.join(cond))\n",
    "                #low, high = [0]+bar['25%'].fillna(0).tolist(),[0]+bar['75%'].fillna(0).tolist()\n",
    "                #ax[irow,icol].fill_between(np.arange(0,cat+1), low, high, alpha=0.1, interpolate=False, color='grey', edgecolor=None, step='pre')\n",
    "                ax[irow,icol].errorbar(cat+0.1*iani,m,yerr=s,label=animal)\n",
    "                #ax[irow,icol].set_xticks(np.arange(0,cat)+0.5)\n",
    "                #if irow+1==num_rows:\n",
    "                #    labels = [('%s: %d'%(', '.join(idx),np.nan_to_num(count))) for idx,count in lab.iteritems()]\n",
    "                #else:\n",
    "                #    labels = ['%d'%np.nan_to_num(count) for idx,count in lab.iteritems()]\n",
    "                #ax[irow,icol].set_xticklabels(labels, rotation='vertical')\n",
    "            except KeyError:\n",
    "                pass\n",
    "        ax[irow,icol].set_xlim(cat[0],cat[-1]+0.1*len(animals))\n",
    "        ax[irow,icol].set_xticks(cat+0.05*len(animals))\n",
    "        ax[irow,icol].set_xticklabels(la.epochs.values) #, rotation='vertical')\n",
    "    #ax[-1,-1].legend()\n",
    "    h, l = ax[0,0].get_legend_handles_labels()\n",
    "    fig.legend(h,l,'lower center',mode='expand',ncol=int((len(animals)+1)/2.0))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage('all_compare.pdf')\n",
    "\n",
    "#pp = helpmultipage('all_compare.pdf')\n",
    "fig = plot_correlation_comparison(data, 'Ready', 'Phase Ready', True)\n",
    "pp.savefig()\n",
    "fig = plot_correlation_comparison(data, 'CS', 'Phase CS', True)\n",
    "pp.savefig()\n",
    "fig = plot_correlation_comparison(data, 'Trace', 'Phase Trace', True)\n",
    "pp.savefig()\n",
    "\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity of correlation matrices"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "num_rows = len(et.index)\n",
    "num_cols = num_phases\n",
    "\n",
    "change = np.zeros((num_cols,num_rows,num_rows))\n",
    "for icol, phase in enumerate(la.phases[:num_phases]):\n",
    "    for irow1, key1 in enumerate(data.et.index):\n",
    "        count1 = data.et.loc[key1,animal]\n",
    "        for irow2, key2 in enumerate(data.et.index):\n",
    "            count2 = data.et.loc[key2,animal]\n",
    "            change[icol,irow1,irow2] = np.linalg.norm(np.ravel(\n",
    "                    data.mx[key1+(phase,)]-data.mx[key2+(phase,)])/np.size(data.mx[key2+(phase,)]),2)\n",
    "\n",
    "for icol, phase in enumerate(la.phases[:num_phases]):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "    fig.tight_layout(rect=[0.4,0,0.95,0.55])\n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.gca()\n",
    "    img = ax.matshow(change[icol]+np.diag(np.nan*np.diag(change[icol])),\n",
    "                     cmap=plt.get_cmap('rainbow'))\n",
    "\n",
    "    fig.suptitle('Difference between test cases (RMS distance)\\nPhase: '\n",
    "                 +phase,fontsize=16)\n",
    "    ax.set_xticks(np.array(range(0,num_rows)))\n",
    "    ax.set_xticklabels(data.et.index.tolist(),rotation=90)\n",
    "    ax.set_yticks(np.array(range(0,num_rows)))\n",
    "    ax.set_yticklabels(data.et.index.tolist())\n",
    "\n",
    "    # without set_yticks\n",
    "    # ax.set_yticklabels([tuple()]+et.index.values.tolist())\n",
    "    fig.colorbar(img)\n",
    "    pp.savefig()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
