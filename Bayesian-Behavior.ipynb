{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A Non-Parametric Bayesian Method for Inferring Hidden Causes\n",
    "<a href=\"http://cocosci.berkeley.edu/tom/papers/ibpuai.pdf\">F., Griffiths, T.L., Ghahramani, Z., 2006.<br />\n",
    "Presented at the Proceedings of the Conference on Uncertainty in Artificial Intelligence.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reqirements\n",
    "* #### You need to install module future, manual importing from \\_\\_future\\_\\_ is at your convenience\n",
    "* #### For hdf data import you need pytables too which is not default installed with Anaconda\n",
    "\n",
    "### Batch execution\n",
    "* #### ```batch_animal=msaxxyy_z jupyter nbconvert Bayesian.ipynb --to=html --execute --ExecutePreprocessor.timeout=-1 --output=xxyy_z_report.html```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from future.utils import PY3\n",
    "import future\n",
    "from __future__ import (absolute_import, division,\n",
    "                        print_function) #, unicode_literals)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, os, warnings, imp, itertools\n",
    "import IPython.display as disp\n",
    "display = disp.display\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "zscore, describe = stats.mstats.zscore, stats.describe\n",
    "import datetime\n",
    "dt, td = datetime.datetime, datetime.timedelta\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ca_lib as la\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "batch_animal = environ.get('batch_animal', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basedir = '../_share/Losonczi/'\n",
    "\n",
    "# Display database folders\n",
    "display(os.listdir(basedir))\n",
    "\n",
    "# Select animal\n",
    "if batch_animal is None:\n",
    "    animal = 'msa0216_4'; FPS = 8\n",
    "    #animal = 'msa0316_1'; FPS = 8\n",
    "    #animal = 'msa0316_3'; FPS = 8\n",
    "    #animal = 'msa0316ag_1'; FPS = 8\n",
    "    #animal = 'msa0915_1'; FPS = 30\n",
    "    #animal = 'msa0915_2'; FPS = 30\n",
    "    #animal = 'msa1215_1'; FPS = 30\n",
    "else:\n",
    "    FPS = None\n",
    "    animal = batch_animal\n",
    "\n",
    "print ('selecting',animal)\n",
    "\n",
    "# List dir\n",
    "mydir = os.path.join(basedir,animal)\n",
    "os.listdir(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Available trials and ROIs\n",
    "data = la.load_files(mydir)\n",
    "if (FPS is not None) and (data.FPS != FPS):\n",
    "    warnings.warn('FPS indication might be wrong.')\n",
    "print (data.raw.shape, '\\n', data.trials, '\\n', data.rois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Post-Learning may repeat session_num therefore an additional index,\n",
    "# day_num is created. See msa0316_1.\n",
    "# It seems though that Pre-Learning and Learning treats session_num as documented.\n",
    "display(data.experiment_traits.head())\n",
    "display(data.experiment_traits[data.experiment_traits['day_leap']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(data.experiment_traits.to_records()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ndarray == np.recarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "def cellarray(df, index, dropna_axis=None, fillna_axis=None, fillna_method=None):\n",
    "    '''Split a DataFrame with MultiIndex into a 1D cellarray'''\n",
    "    import warnings\n",
    "    ca = np.empty(shape=len(index), dtype=np.ndarray)\n",
    "    for i, key in enumerate(index):\n",
    "        tmp = df.loc[key]\n",
    "        if dropna_axis is not None:\n",
    "            tmp = tmp.dropna(axis=dropna_axis, how='all')\n",
    "        if fillna_axis is not None:\n",
    "            tmp = tmp.fillna(axis=fillna_axis, method=fillna_method).fillna(value=0)\n",
    "        if (type(tmp.index) is pd.MultiIndex) or (type(tmp.columns) is pd.MultiIndex):\n",
    "            warnings.warn('Matrix in a cell has multiindex.')\n",
    "        ca[i] = tmp.values\n",
    "        #print (tmp.shape, tmp.isnull().sum().sum())\n",
    "    return ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Select acitve ROIs and prepare them for output\n",
    "# trial ID\n",
    "ix = data.mirow.levels[0]\n",
    "# fill rate of spiking (this is a full df)\n",
    "mea = data.spike.unstack('time',fill_value=0).mean(axis=1)\n",
    "# present in almost all frames of almost ll trials & active\n",
    "keep = data.mask_roi & (mea>0.02)\n",
    "# extract ROIs to keep\n",
    "rois = data.mask_roi[keep].index\n",
    "# statistics\n",
    "print ('Keep %d ROIs out of %d.'%(len(rois),len(data.mask_roi)))\n",
    "ref = pd.MultiIndex.from_product((data.mirow.levels[0],(rois)))\n",
    "def prep(df, fill_value=None):\n",
    "    '''Reindex (fill in the gaps) and split DataFrame to cellarray'''\n",
    "    df = df.reindex(fill_value=None, index=ref, columns=data.icol)\n",
    "    ret = cellarray(df, ix, dropna_axis=1, fillna_axis=0, fillna_method='ffill')\n",
    "    return ret\n",
    "\n",
    "w = {'transients': prep(data.spike),\n",
    "     'filtered': prep(data.filtered),\n",
    "     'raw': prep(data.raw),\n",
    "     'mask': prep(data.mask),\n",
    "     'trials':data.mirow.levels[0].values.astype(str),\n",
    "     'rois':rois.values.astype(str),\n",
    "     'frames':data.icol.values}\n",
    "sio.savemat(animal+'.mat',w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include_w = True\n",
    "# categoric feature: column, value\n",
    "if include_w:\n",
    "    cat_features = [('context', 'CS+'), ('context', 'CS-'), ('port', 'W+'), ('puffed', 'A+')]\n",
    "else:\n",
    "    cat_features = [('context', 'CS+'), ('context', 'CS-'), ('puffed', 'A+')]\n",
    "# ordinal feature: column, list of allowed values\n",
    "ord_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_features(cat_list, list_ord, data):\n",
    "    col = 0\n",
    "    # features = pd.DataFrame(index=data.index, columns=[])\n",
    "    features = []\n",
    "    for column, criterion in cat_list:\n",
    "        feat = data.loc[:,column] == criterion\n",
    "        feat.name = '%d_%s' % (col, column)\n",
    "        features.append(feat)\n",
    "        col += 1\n",
    "    features = pd.concat(features, axis=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "e = Counter(data.experiment_traits['learning_epoch'])\n",
    "ev = [0, e['Pre-Learning'], e['Learning'], e['Post-Learning']]\n",
    "ev = np.cumsum(ev)\n",
    "e, ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cf = create_features(cat_features,ord_features,data.experiment_traits)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = np.mean(cf.values)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import BayesianHiddenCause as bc\n",
    "imp.reload(bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bba = bc.BernoulliBetaAssumption(p, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bba.observe(cf.astype(int).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bba.Gibbs_prepare(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = bc.plot_matrix_product('i (observabes)',bba.Z,'Z','t (trials)',bba.Y,'Y','k (causes)',bba.Px(),'X estimated')\n",
    "fig.suptitle('Estimate')\n",
    "fig = bc.plot_matrix_product('i (observabes)',np.array([[]]),'Z','t (trials)',np.array([[]]),'Y','k (causes)',cf.values.astype(int).T,'X observed')\n",
    "fig.suptitle('Original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,100):\n",
    "    bba.Gibbs_iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links = []\n",
    "for i in range(0,1000):\n",
    "    for i in range(0,10):\n",
    "        bba.Gibbs_iterate()\n",
    "    links.extend([tuple(col) for col in bba.Z.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(links)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate(learner, test_samples, given_i):\n",
    "    '''Simulate the learners response to the test samples\n",
    "       taking into account only the features marked true in given_i'''\n",
    "    # Initialize\n",
    "    cum, totp = 0, 0\n",
    "    # Test all possible latent states\n",
    "    a=([0,1],)*learner.K\n",
    "    for Y1 in itertools.product(*a):\n",
    "        Y1 = np.array(Y1)\n",
    "        # The probability of the given latent state in the model\\US\n",
    "        logpy = learner.logP_y_XZ(Y1, X=test_samples, given_i=given_i)\n",
    "        py = np.exp(logpy)\n",
    "        # The Bernoulli parameters for the observables\n",
    "        px = learner.P_x_YZ(Y=Y1[:,np.newaxis])\n",
    "        # The animal's response\n",
    "        behav = px[~given_i]\n",
    "        #print (Y1, behav)\n",
    "        # Cumulate\n",
    "        totp += py\n",
    "        cum += py * behav\n",
    "    # The animal's average response for the test samples would be\n",
    "    return (cum/totp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given variables: all but US\n",
    "given_i = np.array(map(lambda x: x[0]!='puffed', cat_features))\n",
    "# Decay of past experiences\n",
    "decay_time=np.inf\n",
    "\n",
    "# Define a well established set of samples where we want to know the behavior\n",
    "# V0\n",
    "#test_samples = None\n",
    "# V1 (CS+, W+), same, (CS+, W-), same, (CS-, W+), same\n",
    "#test_samples = np.array([[1,0,1,1],[1,0,1,0],[1,0,0,1],[1,0,0,0],[0,1,1,0],[0,1,1,1]]).T\n",
    "#test_names = ['CS+, W+', 'same', 'CS+, W-', 'same', 'CS-, W+', 'same']\n",
    "# V2 (CS+, W+), (CS+, W-), (CS-, W+), (CS-, W-) OR (CS+), (CS-)\n",
    "if include_w:\n",
    "    test_samples = np.array([[1,0,1,1],[1,0,0,1],[0,1,1,0],[0,1,0,1]]).T\n",
    "    test_names = ['CS+, W+', 'CS+, W-', 'CS-, W+', 'CS-, W-']\n",
    "else:\n",
    "    test_samples = np.array([[1,0,1],[0,1,1]]).T\n",
    "    test_names = ['CS+', 'CS-']\n",
    "\n",
    "responses = [] # np.empty(shape=(0,len(test_samples)))\n",
    "# Train learner with first ntrial trials (equivalent weights) and see response\n",
    "for ntrials in range(1,len(cf)):\n",
    "    learner = bc.BernoulliBetaAssumption(p, 3, decay_time=decay_time)\n",
    "    learner.observe(cf.astype(int).T.iloc[:,:ntrials])\n",
    "    learner.Gibbs_prepare(5)\n",
    "    for i in range(0,100):\n",
    "        learner.Gibbs_iterate()\n",
    "    resp = simulate(learner, test_samples, given_i)\n",
    "    responses.append(resp)\n",
    "    print(ntrials, resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot whether the animal should expect the US based on its previous experiences\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "lines = ax.plot(list(range(0,len(responses))),np.concatenate(responses))\n",
    "ax.set_xlabel('Trial ID')\n",
    "ax.set_ylabel('P(expect airpuff)')\n",
    "ax.vlines(ev, 0, 1)\n",
    "plt.legend(test_names, loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert and save most frequent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "constellations = pd.DataFrame(c, index=[animal]).T\n",
    "constellations.index.names = [b for a,b in cat_features]\n",
    "constellations.index = pd.MultiIndex.from_arrays(np.array(constellations.index.tolist()).astype(bool).T,\n",
    "                                                 names = [b for a,b in cat_features])\n",
    "constellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = {'constellations':constellations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "la.store_to_hdf('baydb_'+animal+'.h5', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
