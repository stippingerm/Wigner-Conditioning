{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A Non-Parametric Bayesian Method for Inferring Hidden Causes\n",
    "<a href=\"http://cocosci.berkeley.edu/tom/papers/ibpuai.pdf\">F., Griffiths, T.L., Ghahramani, Z., 2006.<br />\n",
    "Presented at the Proceedings of the Conference on Uncertainty in Artificial Intelligence.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reqirements\n",
    "* #### You need to install module future, manual importing from \\_\\_future\\_\\_ is at your convenience\n",
    "* #### For hdf data import you need pytables too which is not default installed with Anaconda\n",
    "\n",
    "### Batch execution\n",
    "* #### ```batch_animal=msaxxyy_z jupyter nbconvert Bayesian.ipynb --to=html --execute --ExecutePreprocessor.timeout=-1 --output=xxyy_z_report.html```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from future.utils import PY3\n",
    "import future\n",
    "from __future__ import (absolute_import, division,\n",
    "                        print_function) #, unicode_literals)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, os, warnings, imp, itertools\n",
    "import IPython.display as disp\n",
    "display = disp.display\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "zscore, describe = stats.mstats.zscore, stats.describe\n",
    "import datetime\n",
    "dt, td = datetime.datetime, datetime.timedelta\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ca_lib as la\n",
    "imp.reload(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "batch_animal = environ.get('batch_animal', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basedir = '../_share/Losonczi/'\n",
    "\n",
    "# Display database folders\n",
    "display(os.listdir(basedir))\n",
    "\n",
    "# Select animal\n",
    "if batch_animal is None:\n",
    "    #animal = 'msa0216_4'; FPS = 8\n",
    "    #animal = 'msa0316_1'; FPS = 8\n",
    "    #animal = 'msa0316_3'; FPS = 8\n",
    "    animal = 'msa0316ag_1'; FPS = 8\n",
    "    #animal = 'msa0915_1'; FPS = 30\n",
    "    #animal = 'msa0915_2'; FPS = 30\n",
    "    #animal = 'msa1215_1'; FPS = 30\n",
    "else:\n",
    "    FPS = None\n",
    "    animal = batch_animal\n",
    "\n",
    "print ('selecting',animal)\n",
    "\n",
    "# List dir\n",
    "mydir = os.path.join(basedir,animal)\n",
    "os.listdir(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Available trials and ROIs\n",
    "data = la.load_files(mydir)\n",
    "processed = la.read_from_hdf('anidb_'+animal+'.h5', la.Bunch())\n",
    "a_lick, b_lick, lick_threshold = processed['a_lick'], processed['b_lick'], processed['lick_threshold']\n",
    "del processed\n",
    "\n",
    "if (FPS is not None) and (data.FPS != FPS):\n",
    "    warnings.warn('FPS indication might be wrong.')\n",
    "print (data.raw.shape, '\\n', data.trials, '\\n', data.rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "behavior = {}\n",
    "# Motivation\n",
    "behavior['motivation'] = a_lick.iloc[:,0] > lick_threshold\n",
    "# Fear\n",
    "behavior['fear'] = a_lick.iloc[:,2] < lick_threshold\n",
    "# Sensibility\n",
    "behavior['sensibility'] = a_lick.iloc[:,3] < lick_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "la.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "340/data.FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "behavior['fear2'] = b_lick.iloc[:,8] < lick_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "behavior['fear2'][behavior['fear2'] != behavior['fear']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Post-Learning may repeat session_num therefore an additional index,\n",
    "# day_num is created. See msa0316_1.\n",
    "# It seems though that Pre-Learning and Learning treats session_num as documented.\n",
    "display(data.experiment_traits.head())\n",
    "display(data.experiment_traits[data.experiment_traits['day_leap']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(data.experiment_traits.to_records()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ndarray == np.recarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "def cellarray(df, index, dropna_axis=None, fillna_axis=None, fillna_method=None):\n",
    "    '''Split a DataFrame with MultiIndex into a 1D cellarray'''\n",
    "    import warnings\n",
    "    ca = np.empty(shape=len(index), dtype=np.ndarray)\n",
    "    for i, key in enumerate(index):\n",
    "        tmp = df.loc[key]\n",
    "        if dropna_axis is not None:\n",
    "            tmp = tmp.dropna(axis=dropna_axis, how='all')\n",
    "        if fillna_axis is not None:\n",
    "            tmp = tmp.fillna(axis=fillna_axis, method=fillna_method).fillna(value=0)\n",
    "        if (type(tmp.index) is pd.MultiIndex) or (type(tmp.columns) is pd.MultiIndex):\n",
    "            warnings.warn('Matrix in a cell has multiindex.')\n",
    "        ca[i] = tmp.values\n",
    "        #print (tmp.shape, tmp.isnull().sum().sum())\n",
    "    return ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Select acitve ROIs and prepare them for output\n",
    "# trial ID\n",
    "ix = data.mirow.levels[0]\n",
    "# fill rate of spiking (this is a full df)\n",
    "mea = data.spike.unstack('time',fill_value=0).mean(axis=1)\n",
    "# present in almost all frames of almost ll trials & active\n",
    "keep = data.mask_roi & (mea>0.02)\n",
    "# extract ROIs to keep\n",
    "rois = data.mask_roi[keep].index\n",
    "# statistics\n",
    "print ('Keep %d ROIs out of %d.'%(len(rois),len(data.mask_roi)))\n",
    "ref = pd.MultiIndex.from_product((data.mirow.levels[0],(rois)))\n",
    "def prep(df, fill_value=None):\n",
    "    '''Reindex (fill in the gaps) and split DataFrame to cellarray'''\n",
    "    df = df.reindex(fill_value=None, index=ref, columns=data.icol)\n",
    "    ret = cellarray(df, ix, dropna_axis=1, fillna_axis=0, fillna_method='ffill')\n",
    "    return ret\n",
    "\n",
    "w = {'transients': prep(data.spike),\n",
    "     'filtered': prep(data.filtered),\n",
    "     'raw': prep(data.raw),\n",
    "     'mask': prep(data.mask),\n",
    "     'trials':data.mirow.levels[0].values.astype(str),\n",
    "     'rois':rois.values.astype(str),\n",
    "     'frames':data.icol.values}\n",
    "sio.savemat(animal+'.mat',w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include_w = True\n",
    "# categoric feature: column, value\n",
    "if include_w:\n",
    "    cat_features = [('context', 'CS+'), ('context', 'CS-'), ('port', 'W+'), ('puffed', 'A+')]\n",
    "else:\n",
    "    cat_features = [('context', 'CS+'), ('context', 'CS-'), ('puffed', 'A+')]\n",
    "# ordinal feature: column, list of allowed values\n",
    "ord_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_features(cat_list, list_ord, data):\n",
    "    '''Create the features to be learnt'''\n",
    "    col = 0\n",
    "    # features = pd.DataFrame(index=data.index, columns=[])\n",
    "    features = []\n",
    "    for column, criterion in cat_list:\n",
    "        feat = data.loc[:,column] == criterion\n",
    "        feat.name = '%d_%s' % (col, column)\n",
    "        features.append(feat)\n",
    "        col += 1\n",
    "    features = pd.concat(features, axis=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Measure the length ofthe epochs\n",
    "from collections import Counter\n",
    "e = Counter(data.experiment_traits['learning_epoch'])\n",
    "ev = [0, e['Pre-Learning'], e['Learning'], e['Post-Learning']]\n",
    "ev = np.cumsum(ev)\n",
    "e, ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.experiment_traits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cf = create_features(cat_features,ord_features,data.experiment_traits)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = np.mean(cf.values)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import BayesianHiddenCause as bc\n",
    "imp.reload(bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bba = bc.BernoulliBetaAssumption(p, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bba.observe(cf.astype(int).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bba.Gibbs_prepare(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = bc.plot_matrix_product('i (observabes)',bba.Z,'Z','t (trials)',bba.Y,'Y','k (causes)',bba.P_x_YZ(),'X estimated')\n",
    "fig.suptitle('Estimate')\n",
    "fig = bc.plot_matrix_product('i (observabes)',np.array([[]]),'Z','t (trials)',np.array([[]]),'Y','k (causes)',cf.values.astype(int).T,'X observed')\n",
    "fig.suptitle('Original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate to get most likely constellations of observed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,100):\n",
    "    bba.Gibbs_iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links = []\n",
    "for i in range(0,1000):\n",
    "    for i in range(0,10):\n",
    "        bba.Gibbs_iterate()\n",
    "    links.extend([tuple(col) for col in bba.Z.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(links)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate response to pre-defined samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate(learner, test_samples, given_i):\n",
    "    '''Simulate the learners response to the test samples\n",
    "       taking into account only the features marked true in given_i'''\n",
    "    # Initialize\n",
    "    cum, totp = 0, 0\n",
    "    # Test all possible latent states\n",
    "    a=([0,1],)*learner.K\n",
    "    for Y1 in itertools.product(*a):\n",
    "        Y1 = np.array(Y1)\n",
    "        # The probability of the given latent state in the model\\US\n",
    "        logpy = learner.logP_y_XZ(Y1, X=test_samples, given_i=given_i)\n",
    "        py = np.exp(logpy)\n",
    "        # The Bernoulli parameters for the observables\n",
    "        px = learner.P_x_YZ(Y=Y1[:,np.newaxis])\n",
    "        # The animal's response\n",
    "        behav = px[~given_i]\n",
    "        #print (Y1, behav)\n",
    "        # Cumulate\n",
    "        totp += py\n",
    "        cum += py * behav\n",
    "    # The animal's average response for the test samples would be\n",
    "    return (cum/totp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Give a hint for defining tests\n",
    "print('The %d features are:\\n%s' % (len(cat_features), cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given variables: all but US\n",
    "given_i = np.array(map(lambda x: x[0]!='puffed', cat_features))\n",
    "\n",
    "### Define a well established set of samples where we want to know the behavior\n",
    "\n",
    "### V0: original protocol questions with current knowledge\n",
    "#test_samples = None\n",
    "\n",
    "### V1 (CS+, W+), same, (CS+, W-), same, (CS-, W+), same OR (CS+), same, (CS-), same:\n",
    "### verify that puffed deosn't count\n",
    "#if include_w:\n",
    "#    test_samples = np.array([[1,0,1,1],[1,0,1,0],[1,0,0,1],[1,0,0,0],[0,1,1,0],[0,1,1,1]]).T\n",
    "#    test_names = ['CS+, W+', 'same', 'CS+, W-', 'same', 'CS-, W+', 'same']\n",
    "#    test_colors = ['magenta','magenta', 'red','red', 'cyan','cyan', 'lime','lime']\n",
    "#else:\n",
    "#    test_samples = np.array([[1,0,1],[1,0,0],[0,1,0],[0,1,1]]).T\n",
    "#    test_names = ['CS+, W+', 'same', 'CS+, W-', 'same', 'CS-, W+', 'same']\n",
    "#    test_colors = ['red','red', 'lime','lime']\n",
    "\n",
    "### V2 (BL, W+), (CS+, W+), (CS+, W-), (CS-, W+), (CS-, W-) OR (BL), (CS+), (CS-)\n",
    "if include_w:\n",
    "    test_samples = np.array([[0,0,1,0],[1,0,1,1],[1,0,0,1],[0,1,1,0],[0,1,0,1]]).T\n",
    "    test_names = ['BL, W+', 'CS+, W+', 'CS+, W-', 'CS-, W+', 'CS-, W-']\n",
    "    test_colors = ['y', 'magenta', 'red', 'cyan', 'lime'] # ca.short_colors\n",
    "else:\n",
    "    test_samples = np.array([[0,0,1],[1,0,1],[0,1,1]]).T\n",
    "    test_names = ['BL', 'CS+', 'CS-']\n",
    "    test_colors = ['y', 'red', 'lime']\n",
    "    \n",
    "test_samples = pd.DataFrame(test_samples, columns=test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_test(learner, sampler, data, test_samples, given_i, available_from=0, start_trial=None, end_trial=None):\n",
    "    '''Do forecast using (and changing the state) of learner with the specific sampling\n",
    "       The interval for training starts at available from and its endpoint slides from start_trial to end_trial.\n",
    "       The returned time labels correspond to the point where the outcome of the trial is not yet known.'''\n",
    "    # data: n_features x n_trials\n",
    "    # test_samples: n_features x n_samples\n",
    "    # given_i: bool (n_features)\n",
    "    opinions = [] # np.empty(shape=(0,len(test_samples)))\n",
    "    expectation = []\n",
    "    try:\n",
    "        row_names = data.columns.append([['end']])\n",
    "    except:\n",
    "        row_names = None\n",
    "    try:\n",
    "        column_names = test_samples.columns\n",
    "    except:\n",
    "        column_names = None\n",
    "    data = np.array(data)\n",
    "    test_samples = np.array(test_samples)\n",
    "    \n",
    "    available_from = int(available_from)\n",
    "    end_trial = len(data.T) if end_trial is None else int(end_trial)\n",
    "    start_trial = available_from if start_trial is None else int(start_trial)\n",
    "    \n",
    "    assert (available_from >= 0) and (available_from <= start_trial)\n",
    "    assert (start_trial >= 0) and (start_trial < end_trial)\n",
    "    assert (end_trial > 0) and (end_trial <= len(data.T))\n",
    "    \n",
    "    print('before','<opinions>','<K>')\n",
    "    # Train learner with first ntrial trials (equivalent weights) and see response\n",
    "    rows = list(range(start_trial,end_trial+1))\n",
    "    for available_to in rows:\n",
    "        learner.clear()\n",
    "        learner.observe(data[:,available_from:available_to])\n",
    "        cum, K = 0, 0\n",
    "        opi, exp = np.zeros((1,test_samples.shape[1])), 0\n",
    "        for p in sampler(learner):            \n",
    "            cum += p\n",
    "            K += p * learner.K\n",
    "            opi += p * simulate(learner, test_samples, given_i)\n",
    "            try:\n",
    "                exp += p * simulate(learner, data[:,[available_to]], given_i)\n",
    "            except IndexError:\n",
    "                exp = np.nan\n",
    "        cum = float(cum)\n",
    "        opinions.append(opi / cum)\n",
    "        expectation.append(exp / cum)\n",
    "        print(available_to, opinions[-1], K / cum)\n",
    "    index = None if row_names is None else row_names[np.array(rows)]\n",
    "    opinions = pd.DataFrame(np.row_stack(opinions),\n",
    "                            index=index, columns=column_names)\n",
    "    expectation = pd.Series(np.ravel(np.row_stack(expectation)),\n",
    "                               index=index, name='expect_US').dropna()\n",
    "    return opinions, expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decay time of past experiences\n",
    "decay_time = np.inf\n",
    "# Start larning at\n",
    "start = 0 # 0, ev[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The response according to the last model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_one(learner):\n",
    "    learner.Gibbs_prepare(5)\n",
    "    for i in range(0,100):\n",
    "        learner.Gibbs_iterate()\n",
    "    yield 1\n",
    "\n",
    "learner = bc.BernoulliBetaAssumption(p, 3, decay_time=decay_time)\n",
    "opinions, expectation = do_test(learner,\n",
    "        sample_one, cf.astype(int).T, test_samples, given_i, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The response according to a population of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_models = 50\n",
    "def sample_Gibbs(learner, n_models):\n",
    "    learner.Gibbs_prepare(5)\n",
    "    for i in range(0,100):\n",
    "        learner.Gibbs_iterate()\n",
    "    for m in range(0,n_models):\n",
    "        for i in range(0,10):\n",
    "            learner.Gibbs_iterate()\n",
    "        yield 1\n",
    "        \n",
    "learner = bc.BernoulliBetaAssumption(p, 3, decay_time=decay_time)\n",
    "opinions, expectation = do_test(learner,\n",
    "                                lambda l: sample_Gibbs(l, n_models), cf.astype(int).T,\n",
    "                                test_samples, given_i, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The response integrating over all models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "n_caus = 4\n",
    "def sample_all(learner, n_caus):\n",
    "    n_feat, n_trials = learner.N, learner.T\n",
    "    Y = np.zeros((n_caus, n_trials))\n",
    "    for Z in bc.lof_iterator((n_feat, n_caus)):\n",
    "        learner.Gibbs_load(Y, Z)\n",
    "        pz = np.exp(learner.logP_Z_X(Z))\n",
    "        yield pz\n",
    "\n",
    "learner = bc.BernoulliBetaAssumption(p, 3, decay_time=decay_time)\n",
    "opinions, expectation = do_test(learner,\n",
    "                                lambda l: sample_all(l, n_caus),\n",
    "                                cf.astype(int).T, test_samples, given_i, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The response based on randomly chosen matrices"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_models = 30\n",
    "def sample_rnd(learner, n_caus):\n",
    "    n_feat, n_trials = learner.N, learner.T\n",
    "    for j in range(0,30):\n",
    "        Z = learner.IBP(n_feat)\n",
    "        n_caus = Z.shape[1]\n",
    "        Y = np.zeros((n_caus, n_trials))\n",
    "        learner.Gibbs_load(Y, Z)\n",
    "        pz = np.exp(learner.logP_Z_X(Z))\n",
    "        yield pz\n",
    "\n",
    "learner = bc.BernoulliBetaAssumption(p, 3, decay_time=decay_time)\n",
    "opinions, expectation = do_test(learner,\n",
    "                                lambda l: sample_rnd(l, n_models),\n",
    "                                cf.astype(int).T, test_samples, given_i, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "class helpmultipage(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.isopen = False\n",
    "        self.open()\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "        \n",
    "    def savefig(self, dpi=None):\n",
    "        if self.isopen:\n",
    "            self.pp.savefig(dpi=dpi)\n",
    "\n",
    "    def open(self):\n",
    "        if (~self.isopen) and len(self.filename):\n",
    "            self.pp = PdfPages(self.filename)\n",
    "            self.isopen = True\n",
    "        \n",
    "    def close(self):\n",
    "        if self.isopen:\n",
    "            self.pp.close()\n",
    "        self.isopen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = helpmultipage('Bayesian_%s.pdf'%animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "# Plot whether the animal should expect the US based on its previous experiences\n",
    "t = data['experiment_traits']['idx'].reindex(\n",
    "    opinions.index).fillna(len(data['experiment_traits']))\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.gca()\n",
    "ax.set_title(animal)\n",
    "#lines = ax.plot(t,opinions)\n",
    "# something similar to (conn[line_id][point_id_in_line] is tuple of length 2 or 3 for xyz)\n",
    "#conn = []\n",
    "#for time_series in np.array(opinions, ndmin=2).T:\n",
    "#    conn.append(np.column_stack((t,time_series)))\n",
    "#line_segments = LineCollection(conn, colors=test_colors)\n",
    "#ax.add_collection(line_segments)\n",
    "### finally you get to create an extra Line2D object for all symbols in the legend\n",
    "for idx, time_series in enumerate(np.array(opinions, ndmin=2).T):\n",
    "    ax.plot(t, time_series, color=test_colors[idx])\n",
    "ax.set_xlabel('Trial ID')\n",
    "ax.set_ylabel('P(expect airpuff)')\n",
    "ax.vlines(ev-0.5, 0, 1, color='orange')\n",
    "ax.hlines([0.5], 0, ev[-1], color='grey', linestyles='--')\n",
    "ax.set_xlim(ev[[0,-1]])\n",
    "plt.legend(test_names, loc='upper left', title='Ideal learner', fontsize=10)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "mask = behavior['motivation'] # & behavior['sensibility']\n",
    "mask = mask[mask].index\n",
    "resp = behavior['fear']\n",
    "ttype = data['experiment_traits']['context'][mask]\n",
    "t = data['experiment_traits'].loc[mask,'idx']\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.gca()\n",
    "ax.set_title(animal)\n",
    "lines1 = ax.scatter(t,resp[mask].astype(int),c='b',marker='s',s=32,label='observed (during trace)')\n",
    "lines2 = ax.scatter(t,expectation[mask],c='orange',marker='o',s=32,label='calculated (ideal)')\n",
    "# something similar to (conn[line_id][point_id_in_line] is tuple of length 2 or 3 for xyz)\n",
    "conn = np.zeros((len(t),2,2))\n",
    "conn[:,:,0] = t[:,np.newaxis]\n",
    "conn[:,0,1] = expectation[mask]\n",
    "conn[:,1,1] = resp[mask].astype(int)\n",
    "color = ttype.replace('Baseline','y').replace('CS+','magenta').replace('CS-','cyan')\n",
    "line_segments = LineCollection(conn, colors=color)\n",
    "ax.add_collection(line_segments)\n",
    "ax.set_xlabel('Trial ID')\n",
    "ax.set_ylabel('P(expect airpuff)')\n",
    "ax.vlines(ev-0.5, -0.1, 1.1, color='orange')\n",
    "ax.hlines([0.5], 0, ev[-1], color='grey', linestyles='--')\n",
    "ax.set_xlim(ev[[0,-1]])\n",
    "ax.set_ylim((-0.1,1.1))\n",
    "plt.legend(loc='upper left', title='Reference trials with licking', fontsize=10)\n",
    "pp.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert and save most frequent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "constellations = pd.DataFrame(c, index=[animal]).T\n",
    "constellations.index.names = [b for a,b in cat_features]\n",
    "constellations.index = pd.MultiIndex.from_arrays(np.array(constellations.index.tolist()).astype(bool).T,\n",
    "                                                 names = [b for a,b in cat_features])\n",
    "constellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = {'constellations':constellations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "la.store_to_hdf('baydb_'+animal+'.h5', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
